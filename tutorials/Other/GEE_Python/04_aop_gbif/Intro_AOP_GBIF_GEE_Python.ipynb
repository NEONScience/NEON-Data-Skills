{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: \n",
    "title: \"Exploring NEON AOP remote sensing and GBIF occurrence data in Google Earth Engine Python (geemap) to assess the impacts of a wildfire\"\n",
    "description: \"Explore AOP reflectance along with \"\n",
    "dateCreated: 2025-04-24\n",
    "authors: Kit Lewers\n",
    "contributors: Chandra Earl, Kelsey Yule, Bridget Hass\n",
    "estimatedTime: 1 hour\n",
    "packagesLibraries: earthengine-api, geemap, geopandas, pygbif, shapely, seaborn\n",
    "topics: biorepository, beetles, remote-sensing\n",
    "languagesTool: Python, Google Earth Engine\n",
    "dataProducts: DP3.30006.001, DP3.30006.002\n",
    "code1: https://github.com/NEONScience/NEON-Data-Skills/edit/main/tutorials/Other/GEE_Python/04_aop_gbif_gee_py/Intro_AOP_GBIF_GEE_Python.ipynb\n",
    "tutorialSeries: \n",
    "urlTitle: aop-gbif-gee-py\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring NEON AOP (Airborne Operations Platform) and Biorepository Data Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use NEON airborne hyperspectral data collected in 2016 and 2017 at the NEON <a href=\"https://www.neonscience.org/field-sites/grsm\" target=\"_blank\">GRSM (Great Smokey Mountains)</a> site to map the area affected by the <a href=\"https://www.neonscience.org/impact/observatory-blog/neons-great-smoky-mountains-data-will-capture-tennessee-fire-impacts-local\" target=\"_blank\">Chimney Tops Fire</a>. We will use the GEE (Google Earth Engine) Python API to explore the burn scar using the NBR (Normalized Burn Ratio) to set a threshold to identify burned and unburned areas. We will then use the <a href=\"https://pygbif.readthedocs.io/\" target=\"_blank\">pygbif</a> (Python Global Biodiversity Information Facility) library to pull records from the NEON Biorepository to see if and/or how Carabid beetle communities in the domain were impacted by the fires.\n",
    "\n",
    "This workflow illustrates how NEON’s open data products—airborne remote sensing and biodiversity occurrence records—can be integrated to explore species-level responses to spatially explicit disturbances. By overlaying mapped burn areas with species occurrence data, we can assess whether wildfire affected the composition or distribution of ground beetle communities. Beyond this specific case, the approach highlights the potential of combining ecological and remote sensing data to investigate landscape-scale disturbance impacts, recovery dynamics, and long-term changes in community structure.\n",
    "\n",
    "### Background\n",
    "#### NEON Airborne Observation Platform and Google Earth Engine\n",
    " <a href=\"https://www.neonscience.org/data-collection/airborne-remote-sensing\" target=\"_blank\">Airborne remote sensing</a> surveys are conducted over NEON field sites during peak greenness and provide quantitative information on land cover and changes to ecological structure and chemistry. The surveys are supported by the NEON Airborne Observation Platform (AOP), which collects regional-scale landscape information at the NEON field sites. The AOP maps areas where NEON's observational and instrumented sampling is occurring and allows relationships to be drawn between NEON's detailed in-situ observations to the broader environmental and ecological conditions. AOP data are available on the NEON Data Portal, and can also be downloaded programmatically using the <a href=\"https://pypi.org/project/neonutilities/\" target=\"_blank\">Python neonutilities</a> or <a href=\"https://cran.r-project.org/web/packages/neonUtilities/index.html\" target=\"_blank\">R neonUtilities</a> packages, and a subset of the data are also made available on Google Earth Engine Publisher datasets. This tutorial demonstrates working with full-site hyperspectral data that are available on GEE, using the Python API.\n",
    "\n",
    "#### Ground Beetles and the NEON Biorepository\n",
    "Ground beetles (Coleoptera: Carabidae) are widely recognized as effective bioindicators due to their sensitivity to environmental changes, particularly in relation to environmental changes, vegetation structure, and habitat disturbance. They are highly diverse, relatively easy to sample, and their community composition often reflect changes in local and landscape-scale conditions. Following natural or anthropogenic disturbances, beetle communities typically shift — favoring small-bodied, mobile, and ecologically flexible species in the early stages of recovery. As the habitat stabilizes over time, habitat specialists become more prevalent. Tracking these changes in species composition and abundance offers insight into ecosystem processes and can help assess the trajectory of recovery or the effectiveness of restoration efforts.\n",
    "\n",
    "At NEON field sites, Carabid beetles are captured biweekly during the growing season using pitfall traps. The trap contents are then sorted, with Carabids separated and identified to the species level. Select specimens are preserved as individual pinned reference vouchers, while the rest are stored in 95% ethanol for long-term archiving. Non-Carabid material from the traps is also retained for future use. All specimens are ultimately stored in the <a href=\"https://biorepo.neonscience.org/portal/\" target=\"_blank\">NEON Biorepository</a>, housed at Arizona State University, for long-term storage and curation. The NEON Biorepository makes these datasets available via <a href=\"https://www.gbif.org/\" target=\"_blank\">GBIF</a>, a global platform that aggregates biodiversity data from thousands of sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to use Python to:\n",
    "\n",
    "* Read in multiple visits and visualize AOP reflectance datasets\n",
    "* Calculate NBR (Normalized Burn Ratio) from reflectance data\n",
    "* Read in GBIF Occurrence Records using the pygbif package\n",
    "* Visualize AOP Imagery and GBIF records together\n",
    "* Conduct exploratory analysis to see if and how the fire impacted Carabid species composition\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To follow along with this code, you will need to:\n",
    "1. Sign up for a non-commercial Google Earth Engine account here https://code.earthengine.google.com/register.\n",
    "2. Install **Python 3.10+**\n",
    "3. Install required Python packages\n",
    "   \n",
    "- `pip install earthengine-api --upgrade`\n",
    "- `pip install geemap`\n",
    "- `pip install pygbif`\n",
    "- `pip install geopandas`\n",
    "- `pip install shapely`\n",
    "- `pip install seaborn`\n",
    "\n",
    "### Additional Resources\n",
    "- <a href=\"https://www.neonscience.org/resources/learning-hub/tutorials/aop-gee-py-intro\" target=\"_blank\">Intro to AOP Datasets in Google Earth Engine (GEE) using Python</a>\n",
    "- <a href=\"https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api\" target=\"_blank\">Google Developers Intro to Python API</a>\n",
    "- <a href=\"https://book.geemap.org/\" target=\"_blank\">`geemap` Text Book</a>\n",
    "- <a href=\"https://www.youtube.com/@giswqs\" target=\"_blank\">`geemap` YouTube Channel</a>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in and Visualizing AOP Imagery and GBIF Occurrence Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started! First we'll read in and visualize the AOP surface bidirectional reflectance data at the Great Smokey Mountains site, using GEE in Python.\n",
    "\n",
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pygbif import occurrences as gbif_occ\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Polygon\n",
    "from shapely import wkt\n",
    "\n",
    "# GEE packages\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the `ee` package, you will first need to Authenticate and Initialize. When you initialize you can specify your Google Cloud Platform (GCP) project name, or otherwise you will need to specify it as part of the intialization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "# optionally specify the project name\n",
    "# ee.Initialize(`gcp-project-name`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Available NEON Hyperspectral Imagery on GEE\n",
    "\n",
    "This next chunk of code shows how to find the available data on GEE at the Great Smokey Mountain (GRSM) site. Note that NEON data availability on GEE may not directly match availabilty on the NEON Data Portal, as of 2025. Additional data can be added to GEE upon request by emailing listaopgee@battelleecology.org. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an area of interest, for the imagery, I will simply be using a centroid because I want all\n",
    "# the imagery from GRSM domain. You can using a bounding box, shapefiles, etc. if you want a more granular\n",
    "# control of the geographic area\n",
    "\n",
    "site_center = ee.Geometry.Point([-83.5, 35.7])\n",
    "\n",
    "# Load Hyperspectral AOP Image Collection\n",
    "sdr_col = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/001')\n",
    "\n",
    "# Retrieve all available image IDs to make a list if you want to see everything, but also to cross \n",
    "# reference years you may want\n",
    "image_ids = sdr_col.aggregate_array(\"system:index\").getInfo()\n",
    "print(\"Available AOP Image IDs:\", image_ids)\n",
    "\n",
    "# Define a function that allows you to look through multiple years and domains of image collections\n",
    "def filter_aop_images(years, domains):\n",
    "    \"\"\"\n",
    "    Filters the AOP image collection based on a list of years and domains.\n",
    "    \n",
    "    Parameters:\n",
    "        years (list): List of years (e.g., [\"2016\", \"2017\"]).\n",
    "        domains (list): List of 4-letter site codes (e.g., [\"GRSM\", \"HARV\"]).\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with (year, domain) as key and list of matching image IDs.\n",
    "    \"\"\"\n",
    "    filtered_results = {}\n",
    "\n",
    "    for year in years:\n",
    "        for domain in domains:\n",
    "            matching_ids = [img_id for img_id in image_ids if year in img_id and domain in img_id]\n",
    "            if matching_ids:\n",
    "                filtered_results[(year, domain)] = matching_ids\n",
    "\n",
    "    return filtered_results\n",
    "\n",
    "# Define years and domains that you want to look at (NOTE: this code can be used to look at \n",
    "# multiple years and domains)\n",
    "years_input = [\"2016\", \"2017\"]  # Add multiple years here\n",
    "domains_input = [\"GRSM\"]  # Add multiple domains here\n",
    "\n",
    "# Get image filtered by year and domain\n",
    "filtered_images = filter_aop_images(years_input, domains_input)\n",
    "\n",
    "# NEON does not fly every single domain every year so there may be years where imagery is unavailable\n",
    "# I like to have a conditional statement so I can easily check if there are no images available, but \n",
    "# also print a list in case only some years are available\n",
    "if not filtered_images:\n",
    "    print(f\"No AOP images found for the selected years and domains.\")\n",
    "else:\n",
    "    print(f\"AOP images matching search criteria: {filtered_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate NBR (Normalized Burn Ratio) and visualize for 2016 and 2017 imagery\n",
    "\n",
    "The Normalized Burn Ratio is a standard index derived from multi or hyperspectral data to indicate burn severity. We will use the GEE `normalizedDifference` method to calculate NBR from the AOP hyperspectral data and visualize this in 2016 and 2017 to display the impact from the Chimney Tops Fire on the landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBR Visualization Parameters\n",
    "nbr_vis_params = {\n",
    "    'min': -1, 'max': 1,\n",
    "    'palette': ['white', 'yellow', 'red', 'black']  # typical burn severity color ramp\n",
    "}\n",
    "\n",
    "# Function to Compute NBR\n",
    "def addNBRBands(image):\n",
    "    nbr = image.normalizedDifference(['B097', 'B220']).rename('NBR')\n",
    "    return image.addBands(nbr).set({'Sensor': 'AOP'})\n",
    "\n",
    "# Create a geemap Map instance for NBR visualization\n",
    "NBR_Map = geemap.Map()\n",
    "NBR_Map.centerObject(site_center, 11)\n",
    "\n",
    "# Loop through filtered images and compute NBR\n",
    "for (year, domain), image_ids in filtered_images.items():\n",
    "    for image_id in image_ids:\n",
    "        # Retrieve the image by its system:index\n",
    "        aop_image = sdr_col.filter(ee.Filter.eq(\"system:index\", image_id)).first()\n",
    "\n",
    "        # Compute NBR\n",
    "        if aop_image:\n",
    "            aop_nbr = addNBRBands(aop_image).select('NBR')\n",
    "            print(f\"NBR computed for AOP image: {image_id}\")\n",
    "\n",
    "            # Add layer with proper naming\n",
    "            NBR_Map.addLayer(aop_nbr, nbr_vis_params, f'AOP NBR ({image_id})')\n",
    "\n",
    "# Save the final interactive HTML map for NBR\n",
    "html_nbr_filename = f\"AOP_NBR_{'_'.join(years_input)}_{'_'.join(domains_input)}.html\"\n",
    "NBR_Map.to_html(filename=html_nbr_filename)\n",
    "\n",
    "print(f\"NBR visualization saved: {html_nbr_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open up the html to interactively view the 2016 and 2017 NBR images. You should see something like the following:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_2016_NBR.png\" width=\"600\"> </td>\n",
    "<td> <img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_2017_NBR.png\" width=\"600\"> </td>\n",
    "</table>\n",
    "<figcaption>Normalized Burn Ratio (NBR) at the NEON GRSM site before the Chimney Tops Fire (2016, left) and after the fire (2017, right).  \n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in GBIF Occurrence Data\n",
    "\n",
    "Primary biodiversity data, also known as occurrence data, consist of records documenting observations of specific species at particular locations and times. These records form the foundation for understanding species distributions, tracking biodiversity changes over time, and supporting ecological and conservation research.\n",
    "\n",
    "To begin exploring these patterns, we'll read in the carabid beetle occurrence records using `gbif_occ` and create a geodataframe from those data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify GRSM centroid and bounding box parameters\n",
    "latitude, longitude = 35.6118, -83.4895\n",
    "bbox_size_deg = 0.09  # Approx. 10 km (~0.09 degrees)\n",
    "\n",
    "# Create bounding box polygon\n",
    "bounding_box_coords = [\n",
    "    (longitude - bbox_size_deg, latitude - bbox_size_deg),  # Bottom-left\n",
    "    (longitude + bbox_size_deg, latitude - bbox_size_deg),  # Bottom-right\n",
    "    (longitude + bbox_size_deg, latitude + bbox_size_deg),  # Top-right\n",
    "    (longitude - bbox_size_deg, latitude + bbox_size_deg),  # Top-left\n",
    "    (longitude - bbox_size_deg, latitude - bbox_size_deg)   # Close polygon\n",
    "]\n",
    "bounding_polygon = Polygon(bounding_box_coords)\n",
    "polygon_wkt = bounding_polygon.wkt\n",
    "\n",
    "# Get carabid records\n",
    "carabid_records = []\n",
    "carabid_taxon_key = 3792  # <-- update with correct taxon key for Carabidae\n",
    "for year in [2016, 2017]:\n",
    "    occurrences = gbif_occ.search(\n",
    "        taxonKey=carabid_taxon_key,\n",
    "        geometry=polygon_wkt,\n",
    "        year=year,\n",
    "        hasCoordinate=True,\n",
    "        limit=300\n",
    "    )\n",
    "    prefix = f\"grsm.{year}\".lower()\n",
    "    for occ in occurrences.get(\"results\", []):\n",
    "        if \"eventID\" in occ and occ[\"eventID\"].lower().startswith(prefix):\n",
    "            try:\n",
    "                lat = float(occ[\"decimalLatitude\"])\n",
    "                lon = float(occ[\"decimalLongitude\"])\n",
    "                carabid_records.append({\n",
    "                    \"species\": occ.get(\"species\", \"Unknown\"),\n",
    "                    \"latitude\": lat,\n",
    "                    \"longitude\": lon,\n",
    "                    \"year\": year,\n",
    "                    \"eventID\": occ.get(\"eventID\")\n",
    "                })\n",
    "            except (KeyError, TypeError, ValueError):\n",
    "                continue\n",
    "\n",
    "# Convert carabid records to GeoDataFrame and export as GeoJSON and CSV\n",
    "carabid_gdf = gpd.GeoDataFrame(\n",
    "    carabid_records,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        [r['longitude'] for r in carabid_records],\n",
    "        [r['latitude'] for r in carabid_records]\n",
    "    ),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Write the geodataframe to a geojson and csv file\n",
    "carabid_gdf.to_file(\"gbif_carabids_grsm_2016_2017.geojson\", driver=\"GeoJSON\")\n",
    "carabid_gdf.drop(columns='geometry').to_csv(\"gbif_carabids_grsm_2016_2017.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize AOP Imagery and GBIF records together\n",
    "\n",
    "This last cell combines the AOP NBR map along with the GBIF records, so you can see where those records occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GBIF records from the GeoJSON file\n",
    "gbif_geojson = \"gbif_carabids_grsm_2016_2017.geojson\"\n",
    "carabid_gdf = gpd.read_file(gbif_geojson)\n",
    "\n",
    "# Separate the GBIF records by year\n",
    "carabid_2016 = carabid_gdf[carabid_gdf[\"year\"] == 2016]\n",
    "carabid_2017 = carabid_gdf[carabid_gdf[\"year\"] == 2017]\n",
    "\n",
    "# Add the GBIF points to the map as separate layers\n",
    "NBR_Map.add_gdf(carabid_2016, layer_name=\"GBIF NEON Carabidae Trap Records 2016\")\n",
    "NBR_Map.add_gdf(carabid_2017, layer_name=\"GBIF NEON Carabidae Trap Records 2017\")\n",
    "\n",
    "# (Optional) Save the interactive NBR_map to an HTML file\n",
    "output_html = \"GRSM_GBIF_NBR_Map.html\"\n",
    "NBR_Map.to_html(filename=output_html)\n",
    "print(f\"Combined map saved as: {output_html}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you open this new html, you should be able to see the Carabidae Trap Records:\n",
    "\n",
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_NBR_Carabidae_Trap_Records.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_NBR_Carabidae_Trap_Records.png\" alt=\"GRSM Trap Records\" width=\"800\">\n",
    "    <figcaption>Great Smokey Mountain NBR overlaid with GBIF Carabidae Trap Records</figcaption></a>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Additional Analysis - Impact of the Fire on GBIF Records\n",
    "\n",
    "In this next section, we'll see if we can gain any insights as to if and how the fire impacted the beetle trap records.\n",
    "\n",
    "This next chunk of code vectorizes the burn scar mask, which we can then use to assess differences in the GBIF occurrence data relative to burn percentages for a given location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Select pre-fire and post-fire images ---\n",
    "# Assuming filtered_images is a dictionary with keys like ('2016', 'GRSM') and ('2017', 'GRSM')\n",
    "# Here we simply choose the first image ID for each year.\n",
    "pre_fire_img_id = filtered_images.get(('2016', 'GRSM'))[0]\n",
    "post_fire_img_id = filtered_images.get(('2017', 'GRSM'))[0]\n",
    "\n",
    "# Retrieve the images from the collection\n",
    "pre_fire_image = sdr_col.filter(ee.Filter.eq(\"system:index\", pre_fire_img_id)).first()\n",
    "post_fire_image = sdr_col.filter(ee.Filter.eq(\"system:index\", post_fire_img_id)).first()\n",
    "\n",
    "# --- STEP 2: Compute NBR for each image using your function ---\n",
    "pre_fire_nbr = addNBRBands(pre_fire_image).select('NBR')\n",
    "post_fire_nbr = addNBRBands(post_fire_image).select('NBR')\n",
    "\n",
    "# --- STEP 3: Calculate dNBR (difference NBR) ---\n",
    "dnbr = pre_fire_nbr.subtract(post_fire_nbr).rename('dNBR')\n",
    "\n",
    "# --- STEP 4: Apply a threshold to classify burned areas ---\n",
    "# Example: mark pixels as burned if dNBR > 0.27 (indicative of moderate to high burn severity)\n",
    "burn_threshold = 0.27  # This value may be adjusted based on local calibration or sensor characteristics.\n",
    "burned_area_mask = dnbr.gt(burn_threshold)\n",
    "\n",
    "# Optional: visualize burned vs unburned areas using a simple palette.\n",
    "dnbr_viz_params = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': ['white', 'orange', 'red']\n",
    "}\n",
    "\n",
    "# --- STEP 5: Vectorize the Burn Scar Mask ---\n",
    "# Define a region of interest (ROI) for vectorization.\n",
    "# You might base this on an extent around your site_center; here we buffer the center by 5000m.\n",
    "roi = site_center.buffer(5000)\n",
    "\n",
    "# Convert the burned area mask into vectors (polygons)\n",
    "burn_vectors = burned_area_mask.selfMask().reduceToVectors(\n",
    "    geometry=roi,\n",
    "    crs=post_fire_image.projection(), \n",
    "    scale=10,  # Adjust scale (pixel size) as appropriate for the data.\n",
    "    geometryType='polygon',\n",
    "    labelProperty='burned',\n",
    "    reducer=ee.Reducer.countEvery()\n",
    ")\n",
    "\n",
    "# --- STEP 6: Visualize the dNBR, burned area, and vectorized burn scar on the map ---\n",
    "# Create a geemap Map instance (if not already created)\n",
    "NBR_Map = geemap.Map()\n",
    "NBR_Map.centerObject(site_center, 11)\n",
    "\n",
    "# Add dNBR layer\n",
    "NBR_Map.addLayer(dnbr, dnbr_viz_params, 'dNBR (Pre-fire minus Post-fire)')\n",
    "\n",
    "# Add burned area mask layer\n",
    "NBR_Map.addLayer(burned_area_mask.selfMask(), {'palette': 'red'}, 'Burned Area Mask')\n",
    "\n",
    "# Add burn scar vectors layer\n",
    "NBR_Map.addLayer(burn_vectors, {}, 'Burn Scar Polygons')\n",
    "\n",
    "# Optionally, save the interactive map\n",
    "output_html = \"GRSM_Burn_Scar_Map.html\"\n",
    "NBR_Map.to_html(filename=output_html)\n",
    "print(f\"Burn scar map saved as: {output_html}\")\n",
    "\n",
    "# --- Optional: Export the burn scar vectors as a shapefile ---\n",
    "# If you wish to export the vector data from Earth Engine, use Export.table.toDrive\n",
    "# Uncomment the code below to do this\n",
    "\n",
    "# export_task = ee.batch.Export.table.toDrive(\n",
    "#     collection=burn_vectors,\n",
    "#     description='BurnScar_Shapefile_Export',\n",
    "#     folder='EarthEngineExports',\n",
    "#     fileFormat='SHP'\n",
    "# )\n",
    "# export_task.start()\n",
    "# print(\"Export of burn scar shapefile initiated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open this next html, you can see the vectorized burn scar.\n",
    "\n",
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_Burn_Scar_Map.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee-python/aop_gbif/GRSM_Burn_Scar_Map.png\" alt=\"GRSM Burn Scar\" width=\"800\">\n",
    "    <figcaption>Great Smokey Mountains Chimney Tops Fire Burn Scar</figcaption></a>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare GBIF presence / absence data from 2016 to 2017\n",
    "\n",
    "Next, we will compare species presence data from GBIF for ground beetles collected before and after the fire, using 2016 (pre-fire) and 2017 (post-fire) records. By examining which species were detected in each year, we can infer absences and explore changes in community composition following the disturbance, shedding light on how the fire may have influenced beetle species richness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GBIF records\n",
    "gbif_geojson = \"gbif_carabids_grsm_2016_2017.geojson\"\n",
    "occ_gdf = gpd.read_file(gbif_geojson)\n",
    "\n",
    "# Create a presence flag by dropping duplicate species–year pairs\n",
    "presence_df = (\n",
    "    occ_gdf[['species', 'year']]\n",
    "    .drop_duplicates()           # keep one row per species/year\n",
    "    .assign(presence=1)          # mark presence\n",
    ")\n",
    "\n",
    "# Pivot so each species is a row, columns are years, values are presence (1) or absence (0)\n",
    "presence_pivot = (\n",
    "    presence_df\n",
    "    .pivot(index='species', columns='year', values='presence')\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Display the presence data\n",
    "print('presence data:')\n",
    "print(presence_pivot)\n",
    "\n",
    "# Plot a heatmap of the presence/absence data\n",
    "plt.figure(figsize=(8, max(4, len(presence_pivot) * 0.3)))\n",
    "sns.heatmap(presence_pivot, cmap='Greys', cbar=False, linewidths=.5, linecolor='lightgray')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Species\")\n",
    "plt.title(\"Species Presence/Absence Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the species richness in 2017 is lower than 2016 at all four plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NBR values as a proxy for burn severity compared to trap areas\n",
    "\n",
    "In this next chunk of code, we'll find the unique sites and visualize them to make sure they are consistent across years.\n",
    "\n",
    "<< What does unique sites mean? And consistent across years ... Explain what this is doing, and why only 4 sites are returned. Typically 10 plots within each NEON site collect beetles >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GBIF records from your GeoJSON file\n",
    "gbif_geojson = \"gbif_carabids_grsm_2016_2017.geojson\"\n",
    "\n",
    "# Open and load the GeoJSON as a Python dictionary.\n",
    "with open(gbif_geojson, 'r') as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "# Extract unique coordinate pairs from the features.\n",
    "# We assume each feature is a Point geometry.\n",
    "unique_coords = {}\n",
    "for feature in geojson_data['features']:\n",
    "    # Get geometry details.\n",
    "    geom = feature.get('geometry', {})\n",
    "    if geom.get('type') == 'Point':\n",
    "        # Coordinates are typically stored as [longitude, latitude].\n",
    "        coord = tuple(geom.get('coordinates'))\n",
    "        # Use the coordinates as a key to deduplicate.\n",
    "        if coord not in unique_coords:\n",
    "            unique_coords[coord] = coord\n",
    "\n",
    "# Create a new GeoJSON with only the unique points.\n",
    "unique_features = []\n",
    "for coord in unique_coords.keys():\n",
    "    new_feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": list(coord)\n",
    "        },\n",
    "        \"properties\": {}  # Only lat/long are kept.\n",
    "    }\n",
    "    unique_features.append(new_feature)\n",
    "\n",
    "unique_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": unique_features\n",
    "}\n",
    "\n",
    "print(\"Number of unique points:\", len(unique_features))\n",
    "\n",
    "# Create an Earth Engine FeatureCollection from the unique GeoJSON.\n",
    "traps = ee.FeatureCollection(unique_geojson)\n",
    "\n",
    "# (Optional) Visualize the unique trap points using geemap.\n",
    "Map = geemap.Map(center=[35.7, -83.5], zoom=11)\n",
    "Map.addLayer(traps, {}, 'Unique Points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the burn mask to compute the number of burned pixels (burn percentage) within 300 meters of the unique points as follows. You can export this as a .csv or geojson file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_mask = burned_area_mask.unmask(0).toFloat().rename('burn_mask')\n",
    "\n",
    "traps_buffered = traps.map(lambda feature: feature.buffer(300))\n",
    "\n",
    "# Step 4: Define a function to compute the percentage of burned pixels within each buffer.\n",
    "def calculate_burn_percentage(feature):\n",
    "    stats = burn_mask.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=feature.geometry(),\n",
    "        scale=10,          # Adjust scale to match your sensor's resolution (e.g., 10 m)\n",
    "        maxPixels=1e6\n",
    "    )\n",
    "    # The mean value corresponds to the fraction of burned pixels (0–1).\n",
    "    burn_fraction = ee.Number(stats.get('burn_mask'))\n",
    "    burn_percentage = burn_fraction.multiply(100)\n",
    "    return feature.set({'burn_pct': burn_percentage})\n",
    "\n",
    "# Apply the function to each buffered trap.\n",
    "traps_with_burn = traps_buffered.map(calculate_burn_percentage)\n",
    "\n",
    "# Optionally, print a sample of the computed burn percentages.\n",
    "# print('Burn percentages for trap buffers:', traps_with_burn.limit(10).getInfo())\n",
    "\n",
    "# (Optional) Visualize the trap areas with burn percentage values on your existing map.\n",
    "# NBR_Map.addLayer(traps_with_burn, {}, 'Trap Areas with Burn %')\n",
    "\n",
    "# Convert the Earth Engine FeatureCollection (with burn percentages) to a GeoDataFrame\n",
    "gdf_traps = geemap.ee_to_gdf(traps_with_burn)\n",
    "print(\"Converted GeoDataFrame:\")\n",
    "print(gdf_traps.head())\n",
    "\n",
    "# Option 1: Export as CSV using pandas.\n",
    "# For CSV export, the geometry column may be better exported as WKT.\n",
    "gdf_traps_csv = gdf_traps.copy()\n",
    "gdf_traps_csv['geometry'] = gdf_traps_csv['geometry'].apply(lambda geom: geom.wkt if geom is not None else None)\n",
    "csv_filename = \"Trap_Burn_Percentage_Export.csv\"\n",
    "gdf_traps_csv.to_csv(csv_filename, index=False)\n",
    "print(f\"Data exported as CSV: {csv_filename}\")\n",
    "\n",
    "# Option 2: Export as GeoJSON using GeoPandas.\n",
    "# Here, we'll export the GeoDataFrame directly as a GeoJSON file.\n",
    "geojson_filename = \"Trap_Burn_Percentage_Export.geojson\"\n",
    "# Note: Make sure the geometry column contains proper shapely geometries; if you already converted to WKT above, use the original gdf_traps.)\n",
    "gdf_traps.to_file(geojson_filename, driver=\"GeoJSON\")\n",
    "print(f\"Data exported as GeoJSON: {geojson_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the presence/absence data at each of these plots, to see if there are any trends depending on the burn percentages calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# 1) Load occurrences and tag each record with its trap `site`\n",
    "# ---------------------------------------\n",
    "\n",
    "occ_gdf = gpd.read_file(\"gbif_carabids_grsm_2016_2017.geojson\")\n",
    "\n",
    "occ_gdf['site'] = (\n",
    "    occ_gdf['latitude'].round(6).astype(str) + \", \" +\n",
    "    occ_gdf['longitude'].round(6).astype(str)\n",
    ")\n",
    "\n",
    "all_species = sorted(occ_gdf['species'].unique())\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2) Load burn‐percentage data & build a site → burn_pct lookup\n",
    "# ---------------------------------------\n",
    "df_burn = pd.read_csv(\"Trap_Burn_Percentage_Export.csv\")\n",
    "df_burn['geometry'] = df_burn['geometry'].apply(wkt.loads)\n",
    "gdf_burn = gpd.GeoDataFrame(df_burn, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Compute centroids so we can recreate the same \"site\" key\n",
    "gdf_burn['centroid'] = gdf_burn.geometry.centroid\n",
    "gdf_burn['lat'] = gdf_burn.centroid.y.round(6)\n",
    "gdf_burn['lon'] = gdf_burn.centroid.x.round(6)\n",
    "gdf_burn['site'] = gdf_burn['lat'].astype(str) + \", \" + gdf_burn['lon'].astype(str)\n",
    "\n",
    "# Build a dict: site → burn percentage\n",
    "burn_mapping = gdf_burn.set_index('site')['burn_pct'].to_dict()\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3) Prepare subplots (2×2 for four sites)\n",
    "# ---------------------------------------\n",
    "sites = occ_gdf['site'].unique()\n",
    "n_sites = len(sites)\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(n_sites / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 8))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4) Loop over each site, build presence/absence, and plot\n",
    "# ---------------------------------------\n",
    "for ax, site in zip(axes.flat, sites):\n",
    "    # Filter to that site\n",
    "    occ_site = occ_gdf[occ_gdf['site'] == site]\n",
    "    \n",
    "    # One row per species-year\n",
    "    presence = (\n",
    "        occ_site[['species', 'year']]\n",
    "        .drop_duplicates()\n",
    "        .assign(presence=1)\n",
    "    )\n",
    "    \n",
    "    # Pivot into species × year\n",
    "    pivot = (\n",
    "        presence\n",
    "        .pivot(index='species', columns='year', values='presence')\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    \n",
    "    # Ensure both years are columns\n",
    "    for yr in [2016, 2017]:\n",
    "        if yr not in pivot.columns:\n",
    "            pivot[yr] = 0\n",
    "    pivot = pivot[[2016, 2017]]\n",
    "\n",
    "    pivot = pivot.reindex(index=all_species, fill_value=0)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(\n",
    "        pivot,\n",
    "        cmap='Greys',\n",
    "        cbar=False,\n",
    "        linewidths=0.5,\n",
    "        linecolor='lightgray',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Get burn percentage for this site\n",
    "    burn_pct = burn_mapping.get(site, 0.0)\n",
    "    \n",
    "    # Update title to include site and burn %\n",
    "    ax.set_title(f\"Site {site}\\nBurn: {burn_pct:.1f}%\", fontsize=12)\n",
    "    ax.set_xlabel(\"Year\")\n",
    "    ax.set_ylabel(\"Species\")\n",
    "\n",
    "# Turn off any extra axes (if fewer than 4 sites)\n",
    "for ax in axes.flat[n_sites:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions - on your own:\n",
    "- What are some trends you can find from looking at these four plots, broken out by burn percentage?\n",
    "- Are there any species-specific findings you can determine or hypotheses you can make from these heatmaps?\n",
    "\n",
    "### Recap\n",
    "\n",
    "Congratulations! In this lesson you have learned how to work with GBIF and NEON AOP data together, using `geemap` and `pygbif`, and have gone through an example to assess impacts of a wildfire on beetle trap occurrence data.\n",
    "\n",
    "**Author Contact**:\n",
    "\n",
    "Kit Lewers - Kristen.Lewers@colorado.edu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
