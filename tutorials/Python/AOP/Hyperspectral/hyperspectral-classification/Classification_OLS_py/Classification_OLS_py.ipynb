{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: 1f8217240c064ed1a67b9db20e9362f4\n",
    "title: \"Classification of Hyperspectral Data with Ordinary Least Squares in Python\"\n",
    "description: \"Learn to classify spectral data using the Ordinary Least Squares method.\" \n",
    "dateCreated: 2017-06-21 \n",
    "authors: Paul Gader\n",
    "contributors: Donal O'Leary\n",
    "estimatedTime: 1 hour\n",
    "packagesLibraries: numpy, gdal, matplotlib, matplotlib.pyplot\n",
    "topics: hyperspectral-remote-sensing, HDF5, remote-sensing\n",
    "languagesTool: python\n",
    "dataProduct: NEON.DP1.30006, NEON.DP3.30006, NEON.DP1.30008\n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/Hyperspectral/hyperspectral-classification/Classification_OLS_py/Classification_OLS_py.ipynb\n",
    "tutorialSeries: intro-hsi-py-series\n",
    "urlTitle: classification-ols-python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn to classify spectral data using the \n",
    "Ordinary Least Squares method. \n",
    "\n",
    "\n",
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Classify spectral remote sensing data using Ordinary Least Squares. \n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **numpy**\n",
    "* **gdal** \n",
    "* **matplotlib** \n",
    "* **matplotlib.pyplot** \n",
    "\n",
    "\n",
    "### Download Data\n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/8730436\">\n",
    "Download the spectral classification teaching data subset</a>\n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/8730436\" class=\"link--button link--arrow\">\n",
    "Download Dataset</a>\n",
    "\n",
    "### Additional Materials\n",
    "\n",
    "This tutorial was prepared in conjunction with a presentation on spectral classification\n",
    "that can be downloaded. \n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/8730613\">\n",
    "Download Dr. Paul Gader's Classification 1 PPT</a>\n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/8731960\">\n",
    "Download Dr. Paul Gader's Classification 2 PPT</a>\n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/8731963\">\n",
    "Download Dr. Paul Gader's Classification 3 PPT</a>\n",
    "\n",
    "</div>\n",
    "\n",
    "Classification with Ordinary Least Squares solves the 2-class least squares problem. \n",
    "\n",
    "First, we load the required packages and set initial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as mplt\n",
    "from scipy import linalg\n",
    "from scipy import io\n",
    "\n",
    "\n",
    "### Ordinary Least Squares\n",
    "### SOLVES 2-CLASS LEAST SQUARES PROBLEM\n",
    "\n",
    "### LOAD DATA ###\n",
    "### IF LoadClasses IS True, THEN LOAD DATA FROM FILES ###\n",
    "### OTHERSIE, RANDOMLY GENERATE DATA ###\n",
    "LoadClasses    = True\n",
    "TrainOutliers  = False\n",
    "TestOutliers   = False\n",
    "NOut           = 20\n",
    "NSampsClass    = 200\n",
    "NSamps         = 2*NSampsClass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we read in the example data. Note that you will need to update the filepaths below to work on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LoadClasses:\n",
    "    \n",
    "    ### GET FILENAMES %%%\n",
    "    ### THESE ARE THE OPTIONS ###\n",
    "    ### LinSepC1, LinSepC2,LinSepC2Outlier (Still Linearly Separable) ###\n",
    "    ### NonLinSepC1, NonLinSepC2, NonLinSepC22 ###\n",
    "    \n",
    "    \n",
    "    ## You will need to update these filepaths for your machine:\n",
    "    InFile1          = '/Users/olearyd/Git/data/RSDI2017-Data-SpecClass/NonLinSepC1.mat'\n",
    "    InFile2          = '/Users/olearyd/Git/data/RSDI2017-Data-SpecClass/NonLinSepC2.mat'\n",
    "    C1Dict           = io.loadmat(InFile1)\n",
    "    C2Dict           = io.loadmat(InFile2)\n",
    "    C1               = C1Dict['NonLinSepC1']\n",
    "    C2               = C2Dict['NonLinSepC2']\n",
    "    \n",
    "    if TrainOutliers:\n",
    "        ### Let's Make Some Noise ###\n",
    "        Out1        = 2*np.random.rand(NOut,2)-0.5\n",
    "        Out2        = 2*np.random.rand(NOut,2)-0.5\n",
    "        C1          = np.concatenate((C1,Out1),axis=0)\n",
    "        C2          = np.concatenate((C2,Out2),axis=0)\n",
    "        NSampsClass = NSampsClass+NOut\n",
    "        NSamps      = 2*NSampsClass\n",
    "else:\n",
    "    ### Randomly Generate Some Data\n",
    "    ### Make a covariance using a diagonal array and rotation matrix\n",
    "    pi      = 3.141592653589793\n",
    "    Lambda1 = 0.25\n",
    "    Lambda2 = 0.05\n",
    "    DiagMat = np.array([[Lambda1, 0.0],[0.0, Lambda2]])\n",
    "    RotMat  = np.array([[np.sin(pi/4), np.cos(pi/4)], [-np.cos(pi/4), np.sin(pi/4)]])\n",
    "    mu1     = np.array([0,0])\n",
    "    mu2     = np.array([1,1])\n",
    "    Sigma   = np.dot(np.dot(RotMat.T, DiagMat), RotMat)\n",
    "    C1      = np.random.multivariate_normal(mu1, Sigma, NSampsClass)\n",
    "    C2      = np.random.multivariate_normal(mu2, Sigma, NSampsClass)\n",
    "    print(Sigma)\n",
    "    print(C1.shape)\n",
    "    print(C2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOT DATA ###\n",
    "matplotlib.pyplot.figure(1)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP TARGET OUTPUTS ###\n",
    "TargetOutputs          = np.ones((NSamps,1))\n",
    "TargetOutputs[NSampsClass:NSamps] = -TargetOutputs[NSampsClass:NSamps]\n",
    "\n",
    "### PLOT TARGET OUTPUTS ###\n",
    "matplotlib.pyplot.figure(2)\n",
    "matplotlib.pyplot.plot(range(NSampsClass),         TargetOutputs[range(NSampsClass)],   'b-')\n",
    "matplotlib.pyplot.plot(range(NSampsClass, NSamps), TargetOutputs[range(NSampsClass, NSamps)], 'r-')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIND LEAST SQUARES SOLUTION ###\n",
    "AllSamps     = np.concatenate((C1,C2),axis=0)\n",
    "AllSampsBias = np.concatenate((AllSamps, np.ones((NSamps,1))), axis=1)\n",
    "Pseudo       = linalg.pinv2(AllSampsBias)\n",
    "w            = Pseudo.dot(TargetOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE OUTPUTS ON TRAINING DATA ###\n",
    "y = AllSampsBias.dot(w)\n",
    "\n",
    "### PLOT OUTPUTS FROM TRAINING DATA ###\n",
    "matplotlib.pyplot.figure(3)\n",
    "matplotlib.pyplot.plot(range(NSamps), y, 'm')\n",
    "matplotlib.pyplot.plot(range(NSamps),np.zeros((NSamps,1)), 'b')\n",
    "matplotlib.pyplot.plot(range(NSamps), TargetOutputs, 'k')\n",
    "matplotlib.pyplot.title('TrainingOutputs (Magenta) vs Desired Outputs (Black)')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALCULATE AND PLOT LINEAR DISCRIMINANT ###\n",
    "Slope     = -w[1]/w[0]\n",
    "Intercept = -w[2]/w[0]\n",
    "Domain    = np.linspace(-1.1, 1.1, 60)  # set up the descision surface domain, -1.1 to 1.1 (looking at the data), do it 60 times\n",
    "Disc      = Slope*Domain+Intercept\n",
    "\n",
    "matplotlib.pyplot.figure(4)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.plot(Domain, Disc, 'k-')\n",
    "matplotlib.pyplot.ylim([-1.1,1.3])\n",
    "matplotlib.pyplot.title('Ordinary Least Squares')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegConst      = 0.1\n",
    "AllSampsBias  = np.concatenate((AllSamps, np.ones((NSamps,1))), axis=1)\n",
    "AllSampsBiasT = AllSampsBias.T\n",
    "XtX           = AllSampsBiasT.dot(AllSampsBias)\n",
    "AllSampsReg   = XtX + RegConst*np.eye(3)\n",
    "Pseudo        = linalg.pinv2(AllSampsReg)\n",
    "wr            = Pseudo.dot(AllSampsBiasT.dot(TargetOutputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slope     = -wr[1]/wr[0]\n",
    "Intercept = -wr[2]/wr[0]\n",
    "Domain    = np.linspace(-1.1, 1.1, 60)\n",
    "Disc      = Slope*Domain+Intercept\n",
    "\n",
    "matplotlib.pyplot.figure(5)\n",
    "matplotlib.pyplot.plot(C1[:NSampsClass, 0], C1[:NSampsClass, 1], 'bo')\n",
    "matplotlib.pyplot.plot(C2[:NSampsClass, 0], C2[:NSampsClass, 1], 'ro')\n",
    "matplotlib.pyplot.plot(Domain, Disc, 'k-')\n",
    "matplotlib.pyplot.ylim([-1.1,1.3])\n",
    "matplotlib.pyplot.title('Ridge Regression')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this project with the name: OLSandRidgeRegress2DPGader.  Make a New Project for Spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTE OUTPUTS ON TRAINING DATA ###\n",
    "yr = AllSampsBias.dot(wr)\n",
    "\n",
    "### PLOT OUTPUTS FROM TRAINING DATA ###\n",
    "matplotlib.pyplot.figure(6)\n",
    "matplotlib.pyplot.plot(range(NSamps), yr, 'm')\n",
    "matplotlib.pyplot.plot(range(NSamps),np.zeros((NSamps,1)), 'b')\n",
    "matplotlib.pyplot.plot(range(NSamps), TargetOutputs, 'k')\n",
    "matplotlib.pyplot.title('TrainingOutputs (Magenta) vs Desired Outputs (Black)')\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[range(NSampsClass)]\n",
    "y2 = y[range(NSampsClass, NSamps)]\n",
    "Corr1 = np.sum([y1>0])\n",
    "Corr2 = np.sum([y2<0])\n",
    "\n",
    "y1r = yr[range(NSampsClass)]\n",
    "y2r = yr[range(NSampsClass, NSamps)]\n",
    "Corr1r = np.sum([y1r>0])\n",
    "Corr2r = np.sum([y2r<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Result for Ordinary Least Squares')\n",
    "CorrClassRate=(Corr1+Corr2)/NSamps\n",
    "print(Corr1 + Corr2, 'Correctly Classified for a ', round(100*CorrClassRate), '% Correct Classification \\n')\n",
    "\n",
    "print('Result for Ridge Regression')\n",
    "CorrClassRater=(Corr1r+Corr2r)/NSamps\n",
    "print(Corr1r + Corr2r, 'Correctly Classified for a ', round(100*CorrClassRater), '% Correct Classification \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make Confusion Matrices ###\n",
    "NumClasses = 2;\n",
    "Cm         = np.zeros((NumClasses,NumClasses))\n",
    "Cm[(0,0)]  = Corr1/NSampsClass\n",
    "Cm[(0,1)]  = (NSampsClass-Corr1)/NSampsClass\n",
    "Cm[(1,0)]  = (NSampsClass-Corr2)/NSampsClass\n",
    "Cm[(1,1)]  = Corr2/NSampsClass\n",
    "Cm           = np.round(100*Cm)\n",
    "print('Confusion Matrix for OLS Regression \\n', Cm, '\\n')\n",
    "\n",
    "Cm           = np.zeros((NumClasses,NumClasses))\n",
    "Cm[(0,0)]    = Corr1r/NSampsClass\n",
    "Cm[(0,1)]    = (NSampsClass-Corr1r)/NSampsClass\n",
    "Cm[(1,0)]    = (NSampsClass-Corr2r)/NSampsClass\n",
    "Cm[(1,1)]    = Corr2r/NSampsClass\n",
    "Cm           = np.round(100*Cm)\n",
    "print('Confusion Matrix for Ridge Regression \\n', Cm, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXERCISE:  Run Ordinary Least Squares and Ridge Regression on Spectra and plot the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
