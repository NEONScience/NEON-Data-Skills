{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: 61ad1fc43ddd45b49cad1bca48656bbe\n",
    "title: \"NEON AOP Hyperspectral Data in HDF5 format with Python - Tiled Data\" \n",
    "description: \"Learn how to read NEON AOP hyperspectral flightline data using Python and develop skills to manipulate and visualize spectral data.\"\n",
    "dateCreated: 2018-07-04 \n",
    "authors: Bridget Hass\n",
    "contributors: Donal O'Leary\n",
    "estimatedTime: 1 hour\n",
    "packagesLibraries: numpy, h5py, gdal, matplotlib.pyplot\n",
    "topics: hyperspectral-remote-sensing, HDF5, remote-sensing\n",
    "languagesTool: python\n",
    "dataProduct: NEON.DP3.30006, NEON.DP3.30008\n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/Hyperspectral/intro-hyperspectral/Intro_NEON_AOP_HDF5_Reflectance_Tiles_py/Intro_NEON_AOP_HDF5_Reflectance_Tiles_py.ipynb\n",
    "tutorialSeries: intro-hsi-py-series\n",
    "urlTitle: neon-aop-hdf5-tile-py\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this introductory tutorial, we discuss how to read NEON AOP hyperspectral flightline\n",
    "data using Python. We develop and practice skills and use several tools to manipulate and \n",
    "visualize the spectral data. By the end of this tutorial, you will become \n",
    "familiar with the Python syntax.\n",
    "\n",
    "If you are interested in learning how to do this for flightline NEON AOP hyperspectral data, \n",
    "please see <a href=\"/neon-aop-hdf5-py\" target=\"_blank\"> NEON AOP Hyperspectral Data in HDF5 format with Python - Flightlines</a>.\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Import and use Python packages `numpy, pandas, matplotlib, h5py, and gdal`.\n",
    "* Use the package `h5py` and the `visititems` functionality to read an HDF5 file \n",
    "and view data attributes.\n",
    "* Read the data ignore value and scaling factor and apply these values to produce \n",
    "a cleaned reflectance array.\n",
    "* Extract and plot a single band of reflectance data\n",
    "* Plot a histogram of reflectance values to visualize the range and distribution \n",
    "of values.\n",
    "* Subset an hdf5 reflectance file from the full flightline to a smaller region \n",
    "of interest (if you complete the optional extension). \n",
    "* Apply a histogram stretch and adaptive equalization to improve the contrast \n",
    "of an image (if you complete the optional extension) . \n",
    "\n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **numpy**\n",
    "* **pandas**\n",
    "* **gdal** \n",
    "* **matplotlib** \n",
    "* **h5py**\n",
    "\n",
    "\n",
    "### Download Data\n",
    "\n",
    "To complete this tutorial, you will use data available from the NEON 2017 Data\n",
    "Institute.\n",
    "\n",
    "This tutorial uses the following files:\n",
    "\n",
    "<ul>\n",
    "    <li> <a href=\"https://www.neonscience.org/sites/default/files/neon_aop_spectral_python_functions_tiled_data.zip\">neon_aop_spectral_python_functions_tiled_data.zip (10 KB)</a> <- Click to Download</li>\n",
    "    <li><a href=\"https://ndownloader.figshare.com/files/25752665\" target=\"_blank\">NEON_D02_SERC_DP3_368000_4306000_reflectance.h5 (618 MB)</a> <- Click to Download</li>\n",
    "</ul>\n",
    "\n",
    "<a href=\"https://ndownloader.figshare.com/files/25752665\" class=\"link--button link--arrow\">\n",
    "Download Dataset</a>\n",
    "\n",
    "The LiDAR and imagery data used to create this raster teaching data subset \n",
    "were collected over the \n",
    "<a href=\"http://www.neonscience.org/\" target=\"_blank\"> National Ecological Observatory Network's</a> \n",
    "<a href=\"http://www.neonscience.org/science-design/field-sites/\" target=\"_blank\" >field sites</a>\n",
    "and processed at NEON headquarters.\n",
    "The entire dataset can be accessed on the \n",
    "<a href=\"http://data.neonscience.org\" target=\"_blank\"> NEON data portal</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperspectral remote sensing data is a useful tool for measuring changes to our \n",
    "environment at the Earthâ€™s surface. In this tutorial we explore how to extract \n",
    "information from a tile (1000m x 1000m x 426 bands) of NEON AOP orthorectified surface reflectance data, stored in hdf5 format. For more information on this data product, refer to the <a href=\"http://data.neonscience.org/data-products/DP3.30006.001\" target=\"_blank\">NEON Data Product Catalog</a>.\n",
    "\n",
    "#### Mapping the Invisible: Introduction to Spectral Remote Sensing\n",
    "\n",
    "For more information on spectral remote sensing watch this video. \n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3iaFzafWJQE\" frameborder=\"0\" allowfullscreen></iframe>\n",
    "\n",
    "\n",
    "## Set up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import gdal, osr, os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set display preferences so that plots are inline (meaning any images you output from your code will show up below the cell in the notebook) and turn off plot warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in hdf5\n",
    "\n",
    "```f = h5py.File('file.h5','r')``` reads in an h5 file to the variable f. \n",
    "\n",
    "### Using the help\n",
    "We will be using a number of built-in and user-defined functions and methods throughout the tutorial. If you are uncertain what a certain function does, or how to call it, you can type `help()` or type a \n",
    "`?` at the end of the function or method and run the cell (either select Cell > Run Cells or Shift Enter with your cursor in the cell you want to run). The `?` will pop up a window at the bottom of the notebook displaying the function's `docstrings`, which includes information about the function and usage. We encourage you to use `help` and `?` throughout the tutorial as you come across functions you are unfamiliar with. Let's try this out with `h5py.File`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h5py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.File?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of how to use `h5py` to read in an h5 file, let's try it out. Note that if the h5 file is stored in a different directory than where you are running your notebook, you need to include the path (either relative or absolute) to the directory where that data file is stored. Use `os.path.join` to create the full path of the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you will need to update this filepath for your local machine\n",
    "f = h5py.File('/Users/olearyd/Git/data/NEON_D02_SERC_DP3_368000_4306000_reflectance.h5','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore NEON AOP HDF5 Reflectance Files\n",
    "\n",
    "We can look inside the HDF5 dataset with the ```h5py visititems``` function. The ```list_dataset``` function defined below displays all datasets stored in the hdf5 file and their locations within the hdf5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_dataset lists the names of datasets in an hdf5 file\n",
    "def list_dataset(name,node):\n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        print(name)\n",
    "\n",
    "f.visititems(list_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there is a lot of information stored inside this reflectance hdf5 file. Most of this information is *metadata* (data about the reflectance data), for example, this file stores input parameters used in the atmospheric correction. For this introductory lesson, we will only work with two of these datasets, the reflectance data (hyperspectral cube), and the corresponding geospatial information, stored in Metadata/Coordinate_System:\n",
    "\n",
    "- `SERC/Reflectance/Reflectance_Data`\n",
    "- `SERC/Reflectance/Metadata/Coordinate_System/`\n",
    "\n",
    "We can also display the name, shape, and type of each of these datasets using the `ls_dataset` function defined below, which is also called with the `visititems` method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls_dataset displays the name, shape, and type of datasets in hdf5 file\n",
    "def ls_dataset(name,node):\n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see what the visititems methods does, type ? at the end:\n",
    "f.visititems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visititems(ls_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see the structure of the hdf5 file, let's take a look at some of the information that is stored inside. Let's start by extracting the reflectance data, which is nested under `SERC/Reflectance/Reflectance_Data`:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_refl = f['SERC']['Reflectance']\n",
    "print(serc_refl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two members of the HDF5 group `/SERC/Reflectance` are `Metadata` and `Reflectance_Data`. Let's save the reflectance data as the variable serc_reflArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_reflArray = serc_refl['Reflectance_Data']\n",
    "print(serc_reflArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the size of this reflectance array that we extracted using the `shape` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refl_shape = serc_reflArray.shape\n",
    "print('SERC Reflectance Data Dimensions:',refl_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This 3-D shape (1000,1000,426) corresponds to (y,x,bands), where (x,y) are the dimensions of the reflectance array in pixels. Hyperspectral data sets are often called \"cubes\" to reflect this 3-dimensional shape.\n",
    "\n",
    "<figure>\n",
    "    <a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-general/DataCube.png\">\n",
    "    <img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-general/DataCube.png\"></a>\n",
    "    <figcaption> A \"cube\" showing a hyperspectral data set. Source: National Ecological Observatory Network\n",
    "    (NEON)  \n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "NEON hyperspectral data contain around 426 spectral bands, and when working with tiled data, the spatial dimensions are 1000 x 1000, where each pixel represents 1 meter. Now let's take a look at the wavelength values. First, we will extract wavelength information from the `serc_refl` variable that we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the wavelengths variable\n",
    "wavelengths = serc_refl['Metadata']['Spectral_Data']['Wavelength']\n",
    "\n",
    "#View wavelength information and values\n",
    "print('wavelengths:',wavelengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `numpy` (imported as `np`) to see the minimum and maximum wavelength values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display min & max wavelengths\n",
    "print('min wavelength:', np.amin(wavelengths),'nm')\n",
    "print('max wavelength:', np.amax(wavelengths),'nm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can determine the band widths (distance between center bands of two adjacent bands). Let's try this for the first two bands and the last two bands. Remember that Python uses 0-based indexing (`[0]` represents the first value in an array), and note that you can also use negative numbers to splice values from the end of an array (`[-1]` represents the last value in an array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the band widths between the first 2 bands and last 2 bands \n",
    "print('band width between first 2 bands =',(wavelengths.value[1]-wavelengths.value[0]),'nm')\n",
    "print('band width between last 2 bands =',(wavelengths.value[-1]-wavelengths.value[-2]),'nm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The center wavelengths recorded in this hyperspectral cube range from `383.66 - 2511.94 nm`, and each band covers a range of ~`5 nm`. Now let's extract spatial information, which is stored under `SERC/Reflectance/Metadata/Coordinate_System/Map_Info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_mapInfo = serc_refl['Metadata']['Coordinate_System']['Map_Info']\n",
    "print('SERC Map Info:',serc_mapInfo.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the output:**\n",
    "\n",
    "Here we can spatial information about the reflectance data. Below is a break down of what each of these values means:\n",
    "\n",
    "- `UTM` - coordinate system (Universal Transverse Mercator)\n",
    "- `1.000, 1.000` - \n",
    "- `368000.000, 4307000.0` - UTM coordinates (meters) of the map origin, which refers to the upper-left corner of the image  (xMin, yMax). \n",
    "- `1.0000000, 1.0000000` - pixel resolution (meters)\n",
    "- `18` - UTM zone\n",
    "- `N` - UTM hemisphere (North for all NEON sites)\n",
    "- `WGS-84` - reference ellipoid\n",
    "\n",
    "The letter `b` that appears before UTM signifies that the variable-length string data is stored in **b**inary format when it is written to the hdf5 file. Don't worry about it for now, as we will convert the numerical data we need into floating point numbers. For more information on hdf5 strings read the <a href=\"http://docs.h5py.org/en/latest/strings.html\" target=\"_blank\">h5py documentation</a>. \n",
    "\n",
    "Let's extract relevant information from the `Map_Info` metadata to define the spatial extent of this dataset. To do this, we can use the `split` method to break up this string into separate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First convert mapInfo to a string\n",
    "mapInfo_string = str(serc_mapInfo.value) #convert to string\n",
    "\n",
    "#see what the split method does\n",
    "mapInfo_string.split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the strings using the separator \",\" \n",
    "mapInfo_split = mapInfo_string.split(\",\") \n",
    "print(mapInfo_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract the spatial information we need from the map info values, convert them to the appropriate data type (float) and store it in a way that will enable us to access and apply it later when we want to plot the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the resolution & convert to floating decimal number\n",
    "res = float(mapInfo_split[5]),float(mapInfo_split[6])\n",
    "print('Resolution:',res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the upper left-hand corner coordinates from mapInfo\n",
    "xMin = float(mapInfo_split[3]) \n",
    "yMax = float(mapInfo_split[4])\n",
    "\n",
    "#Calculate the xMax and yMin values from the dimensions\n",
    "xMax = xMin + (refl_shape[1]*res[0]) #xMax = left edge + (# of columns * x pixel resolution)\n",
    "yMin = yMax - (refl_shape[0]*res[1]) #yMin = top edge - (# of rows * y pixel resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the spatial exten as the tuple `(xMin, xMax, yMin, yMax)`. This is the format required for applying the spatial extent when plotting with `matplotlib.pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define extent as a tuple:\n",
    "serc_ext = (xMin, xMax, yMin, yMax)\n",
    "print('serc_ext:',serc_ext)\n",
    "print('serc_ext type:',type(serc_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a Single Band from Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is useful to have all the data contained in a hyperspectral cube, it is difficult to visualize all this information at once. We can extract a single band (representing a ~5nm band, approximating a single wavelength) from the cube by using splicing as follows. Note that we have to cast the reflectance data into the type `float`. Recall that since Python indexing starts at 0 instead of 1, in order to extract band 56, we need to use the index 55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b56 = serc_reflArray[:,:,55].astype(float)\n",
    "print('b56 type:',type(b56))\n",
    "print('b56 shape:',b56.shape)\n",
    "print('Band 56 Reflectance:\\n',b56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we extracted a 2-D array (1000 x 1000) of the scaled reflectance data corresponding to the wavelength band 56. Before we can use the data, we need to clean it up a little. We'll show how to do this below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Scale factor and No Data Value\n",
    "\n",
    "This array represents the scaled reflectance for band 56. Recall from exploring the HDF5 data in HDFViewer that NEON AOP reflectance data uses a `Data_Ignore_Value` of `-9999` to represent missing data (often called `NaN`), and a reflectance `Scale_Factor` of `10000.0` in order to save disk space (can use lower precision this way). \n",
    "\n",
    " <figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/HDF5-general/hdfview_SERCrefl.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/HDF5-general/hdfview_SERCrefl.png\"></a>\n",
    "\t<figcaption> Screenshot of the NEON HDF5 file format.\n",
    "\tSource: National Ecological Observatory Network\n",
    "\t</figcaption>\n",
    "</figure>\n",
    "\n",
    "We can extract and apply the `Data_Ignore_Value` and `Scale_Factor` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View and apply scale factor and data ignore value\n",
    "scaleFactor = serc_reflArray.attrs['Scale_Factor']\n",
    "noDataValue = serc_reflArray.attrs['Data_Ignore_Value']\n",
    "print('Scale Factor:',scaleFactor)\n",
    "print('Data Ignore Value:',noDataValue)\n",
    "\n",
    "b56[b56==int(noDataValue)]=np.nan\n",
    "b56 = b56/scaleFactor\n",
    "print('Cleaned Band 56 Reflectance:\\n',b56)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot single reflectance band\n",
    "\n",
    "Now we can plot this band using the Python package ```matplotlib.pyplot```, which we imported at the beginning of the lesson as ```plt```. Note that the default colormap is jet unless otherwise specified. You can explore using different colormaps on your own; see the <a href=\"https://matplotlib.org/examples/color/colormaps_reference.html\" target=\"_blank\">mapplotlib colormaps</a> for  for other options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_plot = plt.imshow(b56,extent=serc_ext,cmap='Greys') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this image looks pretty washed out. To see why this is, it helps to look at the range and distribution of reflectance values that we are plotting. We can do this by making a histogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram\n",
    "\n",
    "We can plot a histogram using the `matplotlib.pyplot.hist` function. Note that this function won't work if there are any NaN values, so we can ensure we are only plotting the real data values using the call below. You can also specify the # of bins you want to divide the data into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(b56[~np.isnan(b56)],50); #50 signifies the # of bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the reflectance values are < 0.4. In order to show more contrast in the image, we can adjust the colorlimit (`clim`) to 0-0.4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_plot = plt.imshow(b56,extent=serc_ext,cmap='Greys',clim=(0,0.4)) \n",
    "plt.title('SERC Band 56 Reflectance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that adjusting the colorlimit displays features (eg. roads, buildings) much better than when we set the colormap limits to the entire range of reflectance values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension: Basic Image Processing -- Contrast Stretch & Histogram Equalization \n",
    "\n",
    "We can also try out some basic image processing to better visualize the \n",
    "reflectance data using the `ski-image` package. \n",
    "\n",
    "Histogram equalization is a method in image processing of contrast adjustment \n",
    "using the image's histogram. Stretching the histogram can improve the contrast \n",
    "of a displayed image, as we will show how to do below. \n",
    "\n",
    " <figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-general/histogram_equalization.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-general/histogram_equalization.png\"></a>\n",
    "\t<figcaption> Histogram equalization is a method in image processing of contrast adjustment \n",
    "using the image's histogram. Stretching the histogram can improve the contrast \n",
    "of a displayed image, as we will show how to do below.\n",
    "\tSource: <a href=\"https://en.wikipedia.org/wiki/Talk%3AHistogram_equalization#/media/File:Histogrammspreizung.png\"> Wikipedia - Public Domain </a>\n",
    "\t</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "*The following tutorial section is adapted from skikit-image's tutorial\n",
    "<a href=\"http://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html#sphx-glr-auto-examples-color-exposure-plot-equalize-py\" target=\"_blank\"> Histogram Equalization</a>.*\n",
    "\n",
    "Below we demonstrate a widget to interactively display different linear contrast stretches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the contrast stretch feature interactively using IPython widgets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from IPython.html.widgets import *\n",
    "\n",
    "def linearStretch(percent):\n",
    "    pLow, pHigh = np.percentile(b56[~np.isnan(b56)], (percent,100-percent))\n",
    "    img_rescale = exposure.rescale_intensity(b56, in_range=(pLow,pHigh))\n",
    "    plt.imshow(img_rescale,extent=serc_ext,cmap='gist_earth') \n",
    "    #cbar = plt.colorbar(); cbar.set_label('Reflectance')\n",
    "    plt.title('SERC Band 56 \\n Linear ' + str(percent) + '% Contrast Stretch'); \n",
    "    ax = plt.gca()\n",
    "    ax.ticklabel_format(useOffset=False, style='plain') #do not use scientific notation #\n",
    "    rotatexlabels = plt.setp(ax.get_xticklabels(),rotation=90) #rotate x tick labels 90 degree\n",
    "    \n",
    "interact(linearStretch,percent=(0,50,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01659f9fa09d4925b1b2a83977e08aee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntSliderModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "IntSliderView",
       "continuous_update": true,
       "description": "percent",
       "description_tooltip": null,
       "disabled": false,
       "layout": "IPY_MODEL_464f28586cc2430a8eb8be8241448e58",
       "max": 50,
       "min": 0,
       "orientation": "horizontal",
       "readout": true,
       "readout_format": "d",
       "step": 1,
       "style": "IPY_MODEL_4667178c16c94a83ab8de04ea01b6feb",
       "value": 25
      }
     },
     "2b191855aee345f1ac7f9cdec3ca4c8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "464f28586cc2430a8eb8be8241448e58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4667178c16c94a83ab8de04ea01b6feb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "SliderStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": "",
       "handle_color": null
      }
     },
     "826e5c107b924c1da2b798c5d0417f42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [
        "widget-interact"
       ],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_01659f9fa09d4925b1b2a83977e08aee",
        "IPY_MODEL_d10741a30aeb4f25b3b248bb006b455f"
       ],
       "layout": "IPY_MODEL_acd9d02d76304333b5a62082ab1e150e"
      }
     },
     "acd9d02d76304333b5a62082ab1e150e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d10741a30aeb4f25b3b248bb006b455f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_2b191855aee345f1ac7f9cdec3ca4c8b",
       "msg_id": "",
       "outputs": []
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
