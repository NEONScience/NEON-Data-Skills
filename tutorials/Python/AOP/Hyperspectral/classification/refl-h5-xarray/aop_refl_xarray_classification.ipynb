{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: f685c4fab1004d95887228147dff37d9\n",
    "title: \"Tree Classification with NEON Airborne Imaging Spectrometer Data using Python xarray\"\n",
    "description: \"Download, explore, interactively visualize, and perform a supervised classification using NEON AOP bidirectional reflectance data and TOS vegetation structure data.\"\n",
    "dateCreated: 2025-07-30\n",
    "authors: Bridget Hass\n",
    "contributors: \n",
    "estimatedTime: 1 hr 30 minutes\n",
    "packagesLibraries: fiona, gdal, hvplot, geoviews, geopandas, rioxarray, rasterio, jupyter, jupyter_bokeh, jupyterlab, h5py, spectral, scikit-imag, scikit-learn, seaborn\n",
    "topics: hyperspectral, remote-sensing, vegetation, classification\n",
    "languageTool: Python\n",
    "dataProduct: DP1.10098.001, DP3.30006.001, DP3.30006.002\n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/AOP/Hyperspectral/classification/refl-h5-xarray/aop_refl_xarray_classification.ipynb\n",
    "tutorialSeries: \n",
    "urlTitle: refl-classification-pyxarray\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Summary\n",
    "\n",
    "The National Ecological Observatory Network (NEON) Airborne Observation Platform (AOP) collects airborne remote sensing data, including hyperspectral reflectance data, over 81 sites across the United States and Puerto Rico. In this notebook we will show how to download and visualize reflectance data from NEON's [Smithsonian Environmental Research Center](https://www.neonscience.org/field-sites/serc) site (SERC) in Maryland. We will then demonstrate how to run a supervised classification using the NEON Observational System (OS) Vegetation Structure data as training data, and evaluate the model results.\n",
    "\n",
    "### Background\n",
    "\n",
    "The **NEON Imaging Spectrometer (NIS)** is an airborne [imaging spectrometer](https://www.neonscience.org/data-collection/imaging-spectrometer) built by JPL (AVIRIS-NG) and operated by the National Ecological Observatory Network's (NEON) Airborne Observation Platform (AOP). NEON's hyperspectral sensors collect measurements of sunlight reflected from the Earth's surface in 426 narrow (~5 nm) spectral channels spanning wavelengths between ~ 380 - 2500 nm. NEON's remote sensing data is intended to map and answer questions about a landscape, with ecological applications including identifying and classifying plant species and communities, mapping vegetation health, detecting disease or invasive species, and mapping droughts, wildfires, or other natural disturbances and their impacts. \n",
    "\n",
    "In 2024, NEON started producing bidirectional reflectance data products (including BRDF and topographic corrections). These are currently available for AOP data collected between 2022-2025. For more details on this newly revised data product, please refer to the tutorial: [Introduction to Bidirectional Hyperspectral Reflectance Data in Python](https://www.neonscience.org/resources/learning-hub/tutorials/neon-brdf-refl-h5-py).\n",
    "\n",
    "NEON surveys sites spanning the continental US, during peak phenological greenness, capturing each site 3 out of every 5 years, for most terrestrial sites. AOP's [Flight Schedules and Coverage](https://www.neonscience.org/data-collection/flight-schedules-coverage) provide's more information about the current and past schedules.\n",
    "\n",
    "More detailed information about NEON's airborne sampling design can be found in the paper: [Spanning scales: The airborne spatial and temporal sampling design of the National Ecological Observatory Network](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13942).\n",
    "\n",
    " ### Set Up Python Environment\n",
    " - *No Python setup requirements if connected to the workshop Openscapes cloud instance!*\n",
    "   \n",
    " - **Local Only** \n",
    "\n",
    "Using your preferred command line interface (command prompt, terminal, etc.) navigate to your local copy of the repository, then type the following to create a compatible Python environment.\n",
    "\n",
    "    For Windows:\n",
    "\n",
    "    ```cmd\n",
    "    conda create -n neon_aop -c conda-forge --yes python=3.10 fiona=1.8.22 gdal hvplot geoviews rioxarray rasterio jupyter geopandas jupyter_bokeh h5py spectral scikit-image scikit-learn jupyterlab seaborn\n",
    "    ```\n",
    "\n",
    "    For MacOSX:\n",
    "\n",
    "    ```cmd\n",
    "    conda create -n neon_aop -c conda-forge --yes python=3.10 gdal=3.7.2 hvplot geoviews rioxarray rasterio geopandas fiona=1.9.4 jupyter jupyter_bokeh h5py spectral scikit-image scikit-learn seaborn jupyterlab\n",
    "    ```\n",
    "\n",
    " ### Create a NEON AOP Token\n",
    " - NEON API Token (optional, but strongly recommended), see [NEON API Tokens Tutorial](https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-tokens-tutorial) for more details on how to create and set up your token in Python (and R). Once you create your token (on the [NEON User Accounts](https://www.neonscience.org/about/user-accounts)) page, this notebook will show you how to set it as an environment variable and use it for downloading AOP data.\n",
    "\n",
    "### Optional: Download NEON Shapefiles\n",
    "\n",
    "The lesson shows how to programmatically download the NEON shapefiles, but you can also download them by clicking on the following links:\n",
    "\n",
    "- AOP Flight Box Boundaries: <a href=\"https://www.neonscience.org/sites/default/files/AOP_flightBoxes_0.zip\" class=\"link--button link--arrow\">AOP_FlightBoxes.zip</a>\n",
    "- TOS Sampling Boundaries: <a href=\"https://www.neonscience.org/sites/default/files/Field_Sampling_Boundaries_202503.zip\" class=\"link--button link--arrow\">TOS_SamplingBoundaries.zip</a>\n",
    "\n",
    "### Learning Objectives\n",
    "- Explore NEON airborne and field (instrumented, observational) shapefiles to understand what colloated data are available\n",
    "- Use the neonutilities package to determine available reflectance data and download\n",
    "- Use a custom function to convert reflectance data into an xarray dataset\n",
    "- Create some interactive visualizations of reflectance data\n",
    "- Run a random forest model to classify trees using reflectance data and data generated from vegetation structure (as the training data set)\n",
    "- Evaluate classification model results\n",
    "- Understand data QA considerations and potential steps to improve classification results\n",
    "\n",
    "### Tutorial Outline \n",
    "\n",
    "1. Setup\n",
    "2. Visualize NEON AOP, OS, and IS shapefiles at SERC\n",
    "3. Find available NEON reflectance data at SERC and download\n",
    "4. Read in and visualize reflectance data interactively\n",
    "5. Create a random forest model to predict the tree families from the reflectance spectra\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Import Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not already installed, install the `neonutilities` and `python-dotenv` packages using `pip` as follows:\n",
    "- `!pip install neonutilities`\n",
    "- `!pip install python-dotenv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries, grouped by functionality\n",
    "# --- System and utility packages ---\n",
    "from datetime import timedelta\n",
    "import dotenv\n",
    "import os\n",
    "import requests\n",
    "#import sys\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# --- Data handling and scientific computing ---\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Geospatial and multi-dimensional raster data ---\n",
    "import geopandas as gpd\n",
    "import h5py\n",
    "import rasterio as rio  # work with geospatial raster data\n",
    "import rioxarray as rxr  # work with raster arrays\n",
    "from shapely import geometry\n",
    "from shapely.geometry.polygon import orient\n",
    "from osgeo import gdal  # work with raster and vector geospatial data\n",
    "import xarray as xr\n",
    "\n",
    "# --- Plotting and visualization ---\n",
    "import holoviews as hv\n",
    "import hvplot.xarray  # plot multi-dimensional arrays\n",
    "# import hvplot.pandas  # plot DataFrames/Series\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import folium\n",
    "# import folium.plugins\n",
    "from branca.element import Figure\n",
    "from IPython.display import display\n",
    "from skimage import io\n",
    "\n",
    "# --- neonutilities ---\n",
    "import neonutilities as nu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set your NEON Token\n",
    "\n",
    "Define your token. You can set this up on your NEON user account page, https://data.neonscience.org/myaccount. Please refer to the [NEON API Tokens Tutorial](https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-tokens-tutorial) for more details on how to create and set up your token in Python (and R).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1: set the NEON_TOKEN directly in your code\n",
    "NEON_TOKEN='YOUR_TOKEN_HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method 2: set the token as an environment variable using the dotenv package\n",
    "```\n",
    "dotenv.set_key(dotenv_path=\".env\",\n",
    "key_to_set=\"NEON_TOKEN\",\n",
    "value_to_set=\"YOUR_TOKEN_HERE\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize NEON AOP, OS, and IS shapefiles at SERC\n",
    "\n",
    "In this next section, we will look at some of the NEON spatial data, honing in on our site of interest (SERC). We will look at the AOP flight box (the area over which the NEON AOP platform flies, including multiple priority boxes), the IS tower airshed, and the OS terrestrial sampling boundaries. This will provide an overview of how the NEON sites are set up, and the spatial overlap between the field and airborne data.\n",
    "\n",
    "First, let's define a function that will download data from a url. We will use this to download shapefile boundares of the NEON AOP flight boxes, as well as the IS and OS shapefiles in order to see the spatial extent of the various data samples that NEON collects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download data stored on the internet in a public url to a local file\n",
    "def download_url(url,download_dir):\n",
    "    if not os.path.isdir(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    filename = url.split('/')[-1]\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    file_object = open(os.path.join(download_dir,filename),'wb')\n",
    "    file_object.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NEON AOP flight box boundary\n",
    "\n",
    "Download, Unzip, and Open the shapefile (.shp) containing the AOP flight box boundaries, which can also be downloaded from [NEON Spatial Data and Maps](https://www.neonscience.org/data-samples/data/spatial-data-maps). Read this shapefile into a `geodataframe`, explore the contents, and check the coordinate reference system (CRS) of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Unzip the NEON Flight Boundary Shapefile\n",
    "aop_flight_boundary_url = \"https://www.neonscience.org/sites/default/files/AOP_flightBoxes_0.zip\"\n",
    "# Use download_url function to save the file to a directory\n",
    "os.makedirs('./data/shapefiles', exist_ok=True)\n",
    "download_url(aop_flight_boundary_url,'./data/shapefiles')\n",
    "# Unzip the file\n",
    "with ZipFile(f\"./data/shapefiles/{aop_flight_boundary_url.split('/')[-1]}\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/shapefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aop_flightboxes = gpd.read_file(\"./data/shapefiles/AOP_flightBoxes/AOP_flightboxesAllSites.shp\")\n",
    "aop_flightboxes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's examine the AOP flightboxes polygons at the SERC site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id = 'SERC'\n",
    "aop_flightboxes[aop_flightboxes.siteID == site_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the site `geodataframe` consists of a single polygon, that we want to include in our study site (sometimes NEON sites may have more than one polygon, as there are sometimes multiple areas, with different priorities for collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write this to a new variable called \"site_polygon\"\n",
    "site_aop_polygon = aop_flightboxes[aop_flightboxes.siteID == site_id]\n",
    "# subset to only include columns of interest\n",
    "site_aop_polygon = site_aop_polygon[['domain','siteName','siteID','sampleType','flightbxID','priority','geometry']]\n",
    "# rename the flightbxID column to flightboxID for clarity\n",
    "site_aop_polygon = site_aop_polygon.rename(columns={'flightbxID':'flightboxID'})\n",
    "site_aop_polygon # display site polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can visualize our region of interest and the exterior boundary polygon containing ROIs. First add a function to help reformat bounding box coordinates to work with leaflet notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert a bounding box for use in leaflet notation\n",
    "def convert_bounds(bbox, invert_y=False):\n",
    "    \"\"\"\n",
    "    Helper method for changing bounding box representation to leaflet notation\n",
    "\n",
    "    ``(lon1, lat1, lon2, lat2) -> ((lat1, lon1), (lat2, lon2))``\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    if invert_y:\n",
    "        y1, y2 = y2, y1\n",
    "    return ((y1, x1), (y2, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a function that uses folium to display the bounding box polygon on a map. We will first use this function to visualize the AOP flight box polygon, and then we will use it to visualize the IS and OS polygons as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_folium_shapes(\n",
    "    shapefiles,      # list of file paths or GeoDataFrames\n",
    "    styles=None,     # list of style dicts for each shapefile\n",
    "    names=None,      # list of names for each shapefile\n",
    "    map_center=None, # [lat, lon]\n",
    "    zoom_start=12\n",
    "):\n",
    "    import pyproj\n",
    "    # If no center is provided, use the centroid of the first shapefile (projected)\n",
    "    if map_center is None:\n",
    "        if isinstance(shapefiles[0], str):\n",
    "            gdf = gpd.read_file(shapefiles[0])\n",
    "        else:\n",
    "            gdf = shapefiles[0]\n",
    "        # Project to Web Mercator (EPSG:3857) for centroid calculation\n",
    "        gdf_proj = gdf.to_crs(epsg=3857)\n",
    "        centroid = gdf_proj.geometry.centroid.iloc[0]\n",
    "        # Convert centroid back to lat/lon\n",
    "        lon, lat = gpd.GeoSeries([centroid], crs=\"EPSG:3857\").to_crs(epsg=4326).geometry.iloc[0].coords[0]\n",
    "        map_center = [lat, lon]\n",
    "    \n",
    "    m = folium.Map(\n",
    "        location=map_center,\n",
    "        zoom_start=zoom_start,\n",
    "        tiles=None\n",
    "    )\n",
    "    folium.TileLayer(\n",
    "        tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n",
    "        attr='Google',\n",
    "        name='Google Satellite'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    for i, shp in enumerate(shapefiles):\n",
    "        if isinstance(shp, str):\n",
    "            gdf = gpd.read_file(shp)\n",
    "        else:\n",
    "            gdf = shp\n",
    "        style = styles[i] if styles and i < len(styles) else {}\n",
    "        layer_name = names[i] if names and i < len(names) else f\"Shape {i+1}\"\n",
    "        folium.GeoJson(\n",
    "            gdf,\n",
    "            name=layer_name,\n",
    "            style_function=lambda x, style=style: style,\n",
    "            tooltip=layer_name\n",
    "        ).add_to(m)\n",
    "    \n",
    "    folium.LayerControl().add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map1 = plot_folium_shapes(\n",
    "    shapefiles=[site_aop_polygon],\n",
    "    names=['NEON AOP Flight Bounding Box']\n",
    ")\n",
    "\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_flightbox.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_flightbox.png\" alt=\"AOP SERC Flight Box\" style=\"max-width: 100%; height: auto;\">\n",
    "\t<figcaption>AOP flight box polygon at the SERC site.</figcaption>\n",
    "\t</a>\n",
    "</figure> \n",
    "\n",
    "### 2.2 NEON OS terrestrial sampling boundaries\n",
    "\n",
    "We will follow a similar process to download and visualize the NEON OS terrestrial sampling boundaries. The OS terrestrial sampling boundaries are also available as a shapefile, which can be downloaded from [NEON Spatial Data and Maps](https://www.neonscience.org/data-samples/data/spatial-data-maps) page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Unzip the NEON Terrestrial Field Sampling Boundaries Shapefile\n",
    "neon_field_boundary_file = \"https://www.neonscience.org/sites/default/files/Field_Sampling_Boundaries_202503.zip\"\n",
    "# Use download_url function to save the file to the data directory\n",
    "download_url(neon_field_boundary_file,'./data/shapefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the file\n",
    "with ZipFile(f\"./data/shapefiles/Field_Sampling_Boundaries_202503.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/shapefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_terr_bounds = gpd.read_file(\"./data/shapefiles/Field_Sampling_Boundaries/terrestrialSamplingBoundaries.shp\")\n",
    "neon_terr_bounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boundaries for the site to a new variable called \"site_terr_bounds\"\n",
    "site_terr_bounds = neon_terr_bounds[neon_terr_bounds.siteID == site_id]\n",
    "site_terr_bounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 NEON IS tower footprint boundaries\n",
    "\n",
    "Lastly, we'll download and read in the IS tower footprint shapefile, which represents the area of the airshed over which the IS tower collects data. This shapefile is available from the [NEON Spatial Data and Maps](https://www.neonscience.org/data-samples/data/spatial-data-maps) page, but is pre-downloaded for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the 90 percent footprint tower airshed file\n",
    "with ZipFile(f\"./data/90percentfootprint.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/shapefiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neon_tower_airshed = gpd.read_file(\"./data/shapefiles/90percentfootprint/90percent_footprint.shp\")\n",
    "neon_tower_airshed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boundaries for the site to a new variable called \"site_terr_bounds\"\n",
    "site_tower_bounds = neon_tower_airshed[neon_tower_airshed.SiteID == site_id]\n",
    "site_tower_bounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Visualize AOP, OS, and IS boundaries together\n",
    "\n",
    "Now that we've read in all the shapefiles into geodataframes, we can visualize them all together as follows. We will use the `plot_folium_shapes` function defined above, and define a `styles` list of dictionaries specifying the color, so that we can display each polygon with a different color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_shapefiles = [site_aop_polygon, site_terr_bounds, site_tower_bounds]\n",
    "\n",
    "# define a list of styles for the polygons\n",
    "# each style is a dictionary with 'fillColor' and 'color' keys\n",
    "styles = [\n",
    "    {'fillColor': '#228B22', 'color': '#228B22'}, # green\n",
    "    {'fillColor': '#00FFFFFF', 'color': '#00FFFFFF'}, # blue\n",
    "    {'fillColor': '#FF0000', 'color': '#FF0000'}, # red\n",
    "    {'fillColor': '#FFFF00', 'color': '#FFFF00'}, # yellow\n",
    "]\n",
    "\n",
    "map2 = plot_folium_shapes(\n",
    "    shapefiles=neon_shapefiles,\n",
    "    names=['NEON AOP Flight Bounding Box', 'NEON Terrestrial Sampling Boundaries', 'NEON Tower Airshed'],\n",
    "    styles=styles\n",
    ")\n",
    "\n",
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_os_is_shapefiles.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_os_is_shapefiles.png\" alt=\"AOP SERC Flight Box\" style=\"max-width: 100%; height: auto;\">\n",
    "\t<figcaption>AOP, OS, and IS polygons at the SERC site.</figcaption>\n",
    "\t</a>\n",
    "</figure> \n",
    "\n",
    "\n",
    "Above we can see the SOAP flightbox, and the exterior TOS boundary polygon which shows the extent of the area where observational data are collected.\n",
    "\n",
    "## 3. Find available NEON reflectance data and download\n",
    "\n",
    "Finally we can look at the available NEON hyperspectral reflectance data, which are delivered as 1 km by 1 km hdf5 files (also called tiles) over the site. The next figure we make will make it clear why the files are called tiles. First, we will determine the available reflectance data, and then pull in some metadata shapefiles from another L3 AOP data product, derived from the lidar data.\n",
    "\n",
    "NEON hyperspectral reflectance data are currently available under two different revisions, as AOP is in the process of implementing a BRDF (Bidirectional Reflectance Distribution Function), but this has not been applied to the full archive of data yet. These data product IDs are DP3.30006.001 (directional surface reflectance), and DP3.30006.002 (bidirectional surface reflectance). The bidirectional surface reflectance data include BRDF and topographic corrections, which helps correct for differences in illumination throughout the flight. \n",
    "\n",
    "### 3.1 Find available data\n",
    "Let's see what data are available at the SERC site for each of these data products using the `neonutilities` `list_available_dates` function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data product IDs for the reflectance data\n",
    "refl_rev1_dpid = 'DP3.30006.001'\n",
    "refl_rev2_dpid = 'DP3.30006.002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Directional Reflectance Data Available at NEON Site {site_id}:')\n",
    "nu.list_available_dates(refl_rev1_dpid,site_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Bidirectional Reflectance Data Available at NEON Site {site_id}:')\n",
    "nu.list_available_dates(refl_rev2_dpid,site_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates provided are the year and month that the data were published (YYYY-MM). A single site may be collected over more than one month, so this publish date typically represents the month where the majority of the flight lines were collected. There are released directional reflectance data available from 2016 to 2021, and provisional bidirectional reflectance data available in 2022 and 2025. As of 2025, bidirectional data are only available provisionally because they were processed in 2024 (there is a year lag-time before data is released to allow for time to review for data quality issues).\n",
    "\n",
    "For this exercise, we'll look at the most recent data, from 2025. You may wish to consider other factors, for example if you collected field data in a certain year, you are looking at a year when there was a recent disturbance, or if you want to find the clearest weather data (data are not always collected in optimal sky conditions). For SERC, the most recent clear (<10% cloud cover) weather collection to date was in 2017, so this directional reflectance data may be another good option to consider for your analysis.\n",
    "\n",
    "For this lesson, we will use the 2025 bidirectional reflectance data, which is provisional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2025'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Download NEON Lidar data using neonutilities by_file_aop\n",
    "\n",
    "We can download the reflectance data either using the neonutilities function `nu.by_file_aop`, which downloads all tiles for the entire site for a given year, or `nu.by_tile_aop`. To figure out the inputs of these functions, you can type `nu.by_tile_aop?`, for example. \n",
    "\n",
    "AOP data are projected into a WGS84 coordinate system, with coordinates in UTM x, y. When using `nu.by_tile_aop` you need to specify the UTM easting and northing values for the tiles you want to download. If you're not sure the extent of the site, you can use the function `nu.get_aop_tile_extents`. Let's do that here, for the SOAP site collected in 2024. First set up your NEON token as follows, replacing the `\"YOUR TOKEN HERE\"` string with the token copied from the NEON \"[My Account](https://data.neonscience.org/myaccount)\" page. This will help speeed up downloads, and is strongly recommended (and will likely soon be required) for interacting with the NEON data via the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dotenv.set_key(dotenv_path=\".env\",\n",
    "key_to_set=\"NEON_TOKEN\",\n",
    "value_to_set=\"YOUR TOKEN HERE\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc2025_utm_extents = nu.get_aop_tile_extents(refl_rev2_dpid, \n",
    "                                               site_id,\n",
    "                                               year,\n",
    "                                               token=os.environ.get(\"NEON_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AOP collection over SERC in 2025 extends from UTM 358000 - 370000 m (Easting) and 4298000 - 4312000 m (Northing). To display a list of the extents of every tile, you can print `serc2025_utm_extents`. This is sometimes useful when trying to determine the extents of irregularly shaped sites.\n",
    "\n",
    "We can also look at the full extents by downloading one of the smaller lidar raster data products to start. The L3 lidar data products include metadata shapefiles that can be useful for understanding the spatial extents of the individual files that comprise the data product. To show how to look at these shapefiles, we can download the Canopy Height Model data (DP3.30015.001). The next cell shows how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all CHM tiles (https://data.neonscience.org/data-products/DP3.30015.001)\n",
    "nu.by_file_aop(dpid='DP3.30015.001', # Ecosystem Structure / CHM \n",
    "               site=site_id,\n",
    "               year=year,\n",
    "               include_provisional=True,\n",
    "               token='NEON_TOKEN',\n",
    "               savepath='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the lidar tile boundary file\n",
    "with ZipFile(f\"./data/shapefiles/2025_SERC_7_TileBoundary.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data/shapefiles/2025_SERC_7_TileBoundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aop_tile_boundaries = gpd.read_file(\"./data/shapefiles/2025_SERC_7_TileBoundary/shps/NEON_D02_SERC_DPQA_2025_merged_tiles_boundary.shp\")\n",
    "aop_tile_boundaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append this last boundary file to the existing neon_shapefiles list\n",
    "neon_shapefiles.append(aop_tile_boundaries)\n",
    "\n",
    "# plot all shapefiles together\n",
    "map3 = plot_folium_shapes(\n",
    "    shapefiles=neon_shapefiles,\n",
    "    names=['NEON AOP Flight Bounding Box', 'NEON Terrestrial Sampling Boundaries', 'NEON Tower Airshed', 'AOP Tile Boundaries'],\n",
    "    styles=styles,\n",
    "    zoom_start=12\n",
    ")\n",
    "\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_tiles.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/hyperspectral-classification/xarray/serc_aop_tiles.png\" alt=\"AOP SERC Flight Box\" style=\"max-width: 100%; height: auto;\">\n",
    "\t<figcaption>AOP, OS, and IS polygons at the SERC site.</figcaption>\n",
    "\t</a>\n",
    "</figure> \n",
    "\n",
    "\n",
    "From the image above, you can see why the data are called \"tiles\"! The individual tiles make up a grid comprising the full site. These smaller areas make it easier to process the large data, and allow for batch processing instead of running an operation on a huge file, which might cause memory errors.\n",
    "\n",
    "### 3.3 Download NEON Reflectance Data using neonutilities by_tile_aop\n",
    "\n",
    "Now that we've explored the spatial extent of the NEON airborne data, as well as the OS terrestrial sampling plots and the IS tower airshed, we can start playing with the data! \n",
    "First, let's download a single tile to start. For this exercise we'll download the tile that encompasses the NEON tower, since there is typically more OS sampling in the NEON tower plots. The tile of interest for us is `365000_4305000` (note that AOP tiles are named by the SW or lower-left coordinate of the tile).\n",
    "\n",
    "You can specify the download path using the `savepath` variable. Let's set it to a data directory in line with the root directory where we're working, in this case we'll set it to `./data/NEON/refl`. \n",
    "\n",
    "The reflectance data are large in size (especially for an entire site's worth of data), so by default the download functions will display the expected download size and ask if you want to proceed with the download (y/n). The reflectance tile downloaded below is ~ 660 MB in size, so make sure you have enough space on your local disk (or cloud platform) before downloading. If you want to download without being prompted to continue, you can set the input variable `check_size=False`.\n",
    "\n",
    "By default the files will be downloaded following the same structure that they are stored in on Google Cloud Storage, so the actual data files are nested in sub-folders. We encourage you to navigate through the `data/DP3.30006.002` folder, and explore the additional metadata (such as QA reports) that are downloaded along with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tile that encompasses the NEON tower\n",
    "nu.by_tile_aop(dpid='DP3.30006.002',\n",
    "               site=site_id,\n",
    "               year=2025,\n",
    "               easting=364005,\n",
    "               northing=4305005,\n",
    "               include_provisional=True,\n",
    "               token='NEON_TOKEN',\n",
    "               check_size=False,\n",
    "               savepath='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either navigate to the download folder in File Explorer, or to programmatically see what files were downloaded, you can display the files as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all files that were downloaded (including data, metadata, and READMEs):\n",
    "for root, dirs, files in os.walk(r'data\\DP3.30006.002'):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))  # print file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see there are several .txt and .csv files in addition to the .h5 data file (NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5). These include citation information: `citation_DP3.30006.002_PROVISIONAL.txt`, an issue log: `issueLog_DP3.30006.002.csv`, and a README: `NEON.D02.SERC.DP3.30006.002.readme.20250719T050120Z.txt`. We encourage you to look through these files, particularly the issue log, which conveys information about issues and the resolution for the data product in question. Make sure there is not a known issue with the data you downloaded, especially since it is provisional.\n",
    "\n",
    "If you only want to see the names of the .h5 reflectance data you downloaded, you can modify the code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see only the .h5 files that were downloaded\n",
    "for root, dirs, files in os.walk(r'.\\data\\DP3.30006.002'):\n",
    "    for name in files:\n",
    "        if name.endswith('.h5'):\n",
    "            print(os.path.join(root, name))  # print file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We've now downloaded a NEON bidirectional surface reflectance tile into our data directory.\n",
    "\n",
    "## 4. Read in and visualize reflectance data interactively\n",
    "\n",
    "### 4.1 Convert Reflectance Data to an xarray Dataset\n",
    "\n",
    "The function below will read in a NEON reflectance hdf5 dataset and export an xarray dataset. According to the `xarray` documentation, \"xarray makes working with labelled multi-dimensional arrays in Python simple, efficient, and fun!\" `rioxarray` is simply the rasterio xarray extension, so you can work with xarray for geospatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aop_h5refl2xarray(h5_filename):\n",
    "    \"\"\"\n",
    "    Reads a NEON AOP reflectance HDF5 file and returns an xarray.Dataset with reflectance and weather quality indicator data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h5_filename : str\n",
    "        Path to the NEON AOP reflectance HDF5 file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dsT : xarray.Dataset\n",
    "        An xarray Dataset containing:\n",
    "            - 'reflectance': DataArray of reflectance values (y, x, wavelengths)\n",
    "            - 'weather_quality_indicator': DataArray of weather quality indicator (y, x)\n",
    "            - Coordinates: y (UTM northing), x (UTM easting), wavelengths, fwhm, good_wavelengths\n",
    "            - Metadata attributes: projection, spatial_ref, EPSG, no_data_value, scale_factor, bad_band_window1, bad_band_window2, etc.\n",
    "    \"\"\"\n",
    "    import h5py\n",
    "    import numpy as np\n",
    "    import xarray as xr\n",
    "\n",
    "    with h5py.File(h5_filename) as hdf5_file:\n",
    "        print('Reading in ', h5_filename)\n",
    "        sitename = list(hdf5_file.keys())[0]\n",
    "        h5_refl_group = hdf5_file[sitename]['Reflectance']\n",
    "        refl_dataset = h5_refl_group['Reflectance_Data']\n",
    "        refl_array = refl_dataset[()].astype('float32')\n",
    "\n",
    "        # Transpose and flip reflectance data\n",
    "        refl_arrayT = np.transpose(refl_array, (1, 0, 2))\n",
    "        refl_arrayT = refl_array[::-1, :, :]\n",
    "\n",
    "        refl_shape = refl_arrayT.shape\n",
    "        wavelengths = h5_refl_group['Metadata']['Spectral_Data']['Wavelength'][:]\n",
    "        fwhm = h5_refl_group['Metadata']['Spectral_Data']['FWHM'][:]\n",
    "\n",
    "        # Weather Quality Indicator: transpose and flip to match reflectance\n",
    "        wqi_array = h5_refl_group['Metadata']['Ancillary_Imagery']['Weather_Quality_Indicator'][()]\n",
    "        wqi_arrayT = np.transpose(wqi_array, (1, 0))\n",
    "        wqi_arrayT = wqi_array[::-1, :]\n",
    "\n",
    "        # Collect metadata\n",
    "        metadata = {}\n",
    "        metadata['shape'] = refl_shape\n",
    "        metadata['no_data_value'] = float(refl_dataset.attrs['Data_Ignore_Value'])\n",
    "        metadata['scale_factor'] = float(refl_dataset.attrs['Scale_Factor'])\n",
    "        metadata['bad_band_window1'] = h5_refl_group.attrs['Band_Window_1_Nanometers']\n",
    "        metadata['bad_band_window2'] = h5_refl_group.attrs['Band_Window_2_Nanometers']\n",
    "        metadata['projection'] = h5_refl_group['Metadata']['Coordinate_System']['Proj4'][()].decode('utf-8')\n",
    "        metadata['spatial_ref'] = h5_refl_group['Metadata']['Coordinate_System']['Coordinate_System_String'][()].decode('utf-8')\n",
    "        metadata['EPSG'] = int(h5_refl_group['Metadata']['Coordinate_System']['EPSG Code'][()])\n",
    "\n",
    "        # Parse map info for georeferencing\n",
    "        map_info = str(h5_refl_group['Metadata']['Coordinate_System']['Map_Info'][()]).split(\",\")\n",
    "        pixel_width = float(map_info[5])\n",
    "        pixel_height = float(map_info[6])\n",
    "        x_min = float(map_info[3]); x_min = int(x_min)\n",
    "        y_max = float(map_info[4]); y_max = int(y_max)\n",
    "        x_max = x_min + (refl_shape[1]*pixel_width); x_max = int(x_max)\n",
    "        y_min = y_max - (refl_shape[0]*pixel_height); y_min = int(y_min)\n",
    "\n",
    "        # Calculate UTM coordinates for x and y axes\n",
    "        x_coords = np.linspace(x_min, x_max, num=refl_shape[1]).astype(float)\n",
    "        y_coordsT = np.linspace(y_min, y_max, num=refl_shape[0]).astype(float)\n",
    "\n",
    "        # Flag good/bad wavelengths (1=good, 0=bad)\n",
    "        good_wavelengths = np.ones_like(wavelengths)\n",
    "        for bad_window in [metadata['bad_band_window1'], metadata['bad_band_window2']]:\n",
    "            bad_indices = np.where((wavelengths >= bad_window[0]) & (wavelengths <= bad_window[1]))[0]\n",
    "            good_wavelengths[bad_indices] = 0\n",
    "        good_wavelengths[-10:] = 0\n",
    "\n",
    "        # Create xarray DataArray for reflectance\n",
    "        refl_xrT = xr.DataArray(\n",
    "            refl_arrayT,\n",
    "            dims=[\"y\", \"x\", \"wavelengths\"],\n",
    "            name=\"reflectance\",\n",
    "            coords={\n",
    "                \"y\": (\"y\", y_coordsT),\n",
    "                \"x\": (\"x\", x_coords),\n",
    "                \"wavelengths\": (\"wavelengths\", wavelengths),\n",
    "                \"fwhm\": (\"wavelengths\", fwhm),\n",
    "                \"good_wavelengths\": (\"wavelengths\", good_wavelengths)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create xarray DataArray for Weather Quality Indicator\n",
    "        wqi_xrT = xr.DataArray(\n",
    "            wqi_arrayT,\n",
    "            dims=[\"y\", \"x\"],\n",
    "            name=\"weather_quality_indicator\",\n",
    "            coords={\n",
    "                \"y\": (\"y\", y_coordsT),\n",
    "                \"x\": (\"x\", x_coords)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create xarray Dataset and add metadata as attributes\n",
    "        dsT = xr.Dataset({\n",
    "            \"reflectance\": refl_xrT,\n",
    "            \"weather_quality_indicator\": wqi_xrT\n",
    "        })\n",
    "        for key, value in metadata.items():\n",
    "            if key not in ['shape', 'extent', 'ext_dict']:\n",
    "                dsT.attrs[key] = value\n",
    "\n",
    "        return dsT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined a function that reads in the reflectance hdf5 data and exports an xarray dataset, we can apply this function to our downloaded reflectance data. This should take around 15 seconds or so to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# serc_refl_h5 = r'./data/NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5'\n",
    "serc_refl_h5 = r'./data/DP3.30006.002/neon-aop-provisional-products/2025/FullSite/D02/2025_SERC_7/L3/Spectrometer/Reflectance/NEON_D02_SERC_DP3_364000_4305000_bidirectional_reflectance.h5'\n",
    "serc_refl_xr = aop_h5refl2xarray(serc_refl_h5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define a function that updates the neon reflectance xarray dataset to apply the no data value (-9999), set the bad bands to NaN, and applies the CRS to make the xarray objet an rioxarray object. These could also be incorporated into the function above, but you may wish to work with unscaled reflectance data, for example, so we will keep these functions separate for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_neon_xr(neon_refl_ds):\n",
    "\n",
    "    # Set no data values (-9999) equal to np.nan\n",
    "    neon_refl_ds.reflectance.data[neon_refl_ds.reflectance.data == -9999] = np.nan\n",
    "    \n",
    "    # Scale by the reflectance scale factor\n",
    "    neon_refl_ds['reflectance'].data = ((neon_refl_ds['reflectance'].data) /\n",
    "                                        (neon_refl_ds.attrs['scale_factor']))\n",
    "    \n",
    "    # Set \"bad bands\" (water vapor absorption bands and noisy bands) to NaN\n",
    "    neon_refl_ds['reflectance'].data[:,:,neon_refl_ds['good_wavelengths'].data==0.0] = np.nan\n",
    "\n",
    "    neon_refl_ds.rio.write_crs(f\"epsg:{neon_refl_ds.attrs['EPSG']}\", inplace=True)\n",
    "    \n",
    "    return neon_refl_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function on our xarray dataset. This should take a few seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_refl_xr = update_neon_xr(serc_refl_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Explore the reflectance dataset\n",
    "\n",
    "Display the dataset. You can use the up and down arrows to the left of the table (e.g. to the left of Dimensions, Coordinates, Data variables, etc.) to explore each part of the dataset in more detail. You can also click on the icons to the right to see more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serc_refl_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to auto-scale to make RGB images more realistic\n",
    "def gamma_adjust(rgb_ds, bright=0.2, white_background=False):\n",
    "    array = rgb_ds.reflectance.data\n",
    "    gamma = math.log(bright)/math.log(np.nanmean(array)) # Create exponent for gamma scaling - can be adjusted by changing 0.2 \n",
    "    scaled = np.power(np.nan_to_num(array,nan=1),np.nan_to_num(gamma,nan=1)).clip(0,1) # Apply scaling and clip to 0-1 range\n",
    "    if white_background == True:\n",
    "        scaled = np.nan_to_num(scaled, nan = 1) # Set NANs to 1 so they appear white in plots\n",
    "    rgb_ds.reflectance.data = scaled\n",
    "    return rgb_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Plot the reflectance dataset\n",
    "\n",
    "Now let's plot a true color (or RGB) image of the reflectance data as shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RGB image of the SERC tower tile\n",
    "serc_refl_rgb = serc_refl_xr.sel(wavelengths=[650, 560, 470], method='nearest')\n",
    "serc_refl_rgb = gamma_adjust(serc_refl_rgb,bright=0.3,white_background=True)\n",
    "\n",
    "serc_rgb_plot = serc_refl_rgb.hvplot.rgb(y='y',x='x',bands='wavelengths',\n",
    "                         xlabel='UTM x',ylabel='UTM y',\n",
    "                         title='NEON AOP Reflectance RGB - SERC Tower Tile',\n",
    "                         frame_width=480, frame_height=480)\n",
    "\n",
    "# Set axis format to integer (no scientific notation)\n",
    "serc_rgb_plot = serc_rgb_plot.opts(\n",
    "    xformatter='%.0f',\n",
    "    yformatter='%.0f'\n",
    ")\n",
    "\n",
    "serc_rgb_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Plot the weather quality indicator data\n",
    "\n",
    "We can look at the weather conditions during the flight by displaying the `weather_quality_indicator` data array. This is a 2D array with values ranging from 1 to 3, where: 1 = <10% cloud cover, 2 = 10-50% cloud cover, 3 = >50% cloud cover. NEON uses a stop-light convention to indicate the weather and cloud conditions, where green (1) is good, yellow (2) is moderate, and red (3) is poor. The figure below shows some examples of these three conditions as captured by the flight operators during science flights.\n",
    "\n",
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee2023/1b_sdr_weather/flight_cloud_photos.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/aop-gee2023/1b_sdr_weather/flight_cloud_photos.png\" alt=\"In-flight cloud photos\" style=\"max-width: 100%; height: auto;\">\n",
    "\t<figcaption>Cloud cover percentage during AOP flights. Left: green (<10%), Middle: yellow (10-50%), Right: red (>50%).</figcaption>\n",
    "\t</a>\n",
    "</figure>  \n",
    "\n",
    "Let's visualize this weather quality indicator data for this SERC tile using a transparent color on top of our RGB reflectance plot, following the same stop-light convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the WQI mask\n",
    "wqi = serc_refl_xr.weather_quality_indicator\n",
    "\n",
    "# Map WQI values to colors: 1=green, 2=yellow, 3=red, 0/other=transparent\n",
    "wqi_colors = ['#228B22', '#FFFF00', '#FF0000']\n",
    "# wqi_mask = wqi[wqi > 0]  # mask out zeros or nodata\n",
    "\n",
    "# Use hvplot with categorical colormap and alpha (50% transparency)\n",
    "wqi_overlay = wqi.hvplot.image(\n",
    "    x='x', y='y', cmap=wqi_colors,\n",
    "    clim=(1, 3), colorbar=False, alpha=0.5, \n",
    "    xlabel='UTM x', ylabel='UTM y',\n",
    "    title='NEON AOP Reflectance Weather Quality - SERC Tower Tile',\n",
    "    frame_width=480, frame_height=480)\n",
    "\n",
    "# Overlay the RGB and WQI\n",
    "(serc_rgb_plot * wqi_overlay).opts(title=\"RGB + Weather Quality Indicator\").opts(xformatter='%.0f',\n",
    "                                                                                 yformatter='%.0f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cloud conditions for this tile are yellow, which indicates somewhere between 10-50% cloud cover, which is moderate. This is not ideal for reflectance data, but it is still usable. As we will use this data for classification, you would want to consider how the cloud cover may impact your results. You may wish to find a clear-weather (<10% cloud cover) tile to run classification, or at a minimum compare results between the two to better understand how cloud cover impacts the model.\n",
    "\n",
    "### 4.5 Plot a false color image\n",
    "\n",
    "Let's continue visualizing the data, next by making a False-Color image, which is a 3-band combination that shows you more than what you would see with the naked eye. For example, you can pull in SWIR or NIR bands to create an image that shows more information about vegetation health Here we will use a SWIR band (2000 nm), a NIR band (850 nm), and blue band (450 nm). Try some different band combinations on your own, remembering not to use bands that are flagged as bad (e.g. the last 10 bands, or those in the bad band windows between 1340-1445 nm and between 1790-1955 nm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a False-Color image of the SERC tower tile\n",
    "serc_refl_false_color = serc_refl_xr.sel(wavelengths=[2000, 850, 450], method='nearest')\n",
    "serc_refl_false_color = gamma_adjust(serc_refl_false_color,bright=0.3,white_background=True)\n",
    "serc_refl_false_color.hvplot.rgb(y='y',x='x',bands='wavelengths',\n",
    "                         xlabel='UTM x',ylabel='UTM y',\n",
    "                         title='NEON AOP Reflectance False Color Image - SERC Tower Tile',\n",
    "                         frame_width=480, frame_height=480).opts(xformatter='%.0f', yformatter='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Make an interactive spectral signature plot\n",
    "\n",
    "We can also make an interactive plot that displays the spectral signature of the reflectance data for any pixel you click on. This is useful for exploring the spectral signature of different land cover types, and can help you identify which bands may be most useful for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Points Plotting\n",
    "# Modified from https://github.com/auspatious/hyperspectral-notebooks/blob/main/03_EMIT_Interactive_Points.ipynb\n",
    "POINT_LIMIT = 10\n",
    "color_cycle = hv.Cycle('Category20')\n",
    "\n",
    "# Create RGB Map\n",
    "map = serc_refl_rgb.hvplot.rgb(x='x', y='y',\n",
    "                               bands='wavelengths',\n",
    "                               fontscale=1.5,\n",
    "                               xlabel='UTM x', ylabel='UTM y',\n",
    "                               frame_width=480, frame_height=480).opts(xformatter='%.0f', yformatter='%.0f')\n",
    "\n",
    "# Set up a holoviews points array to enable plotting of the clicked points\n",
    "xmid = serc_refl_rgb.x.values[int(len(serc_refl_rgb.x) / 2)]\n",
    "ymid = serc_refl_rgb.y.values[int(len(serc_refl_rgb.y) / 2)]\n",
    "\n",
    "x0 = serc_refl_rgb.x.values[0]\n",
    "y0 = serc_refl_rgb.y.values[0]\n",
    "\n",
    "# first_point = ([xmid], [ymid], [0])\n",
    "first_point = ([x0], [y0], [0])\n",
    "points = hv.Points(first_point, vdims='id')\n",
    "points_stream = hv.streams.PointDraw(\n",
    "    data=points.columns(),\n",
    "    source=points,\n",
    "    drag=True,\n",
    "    num_objects=POINT_LIMIT,\n",
    "    styles={'fill_color': color_cycle.values[1:POINT_LIMIT+1], 'line_color': 'gray'}\n",
    ")\n",
    "\n",
    "posxy = hv.streams.PointerXY(source=map, x=xmid, y=ymid)\n",
    "clickxy = hv.streams.Tap(source=map, x=xmid, y=ymid)\n",
    "\n",
    "# Function to build spectral plot of clicked location to show on hover stream plot\n",
    "def click_spectra(data):\n",
    "    coordinates = []\n",
    "    if data is None or not any(len(d) for d in data.values()):\n",
    "        coordinates.append(clicked_points[0][0], clicked_points[1][0])\n",
    "    else:\n",
    "        coordinates = [c for c in zip(data['x'], data['y'])]\n",
    "    \n",
    "    plots = []\n",
    "    for i, coords in enumerate(coordinates):\n",
    "        x, y = coords\n",
    "        data = serc_refl_xr.sel(x=x, y=y, method=\"nearest\")\n",
    "        plots.append(\n",
    "            data.hvplot.line(\n",
    "                y=\"reflectance\",\n",
    "                x=\"wavelengths\",\n",
    "                color=color_cycle,\n",
    "                label=f\"{i}\"\n",
    "            )\n",
    "        )\n",
    "        points_stream.data[\"id\"][i] = i\n",
    "    return hv.Overlay(plots)\n",
    "\n",
    "def hover_spectra(x,y):\n",
    "    return serc_refl_xr.sel(x=x,y=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths', color='black', frame_width=400)\n",
    "    # return emit_ds.sel(longitude=x,latitude=y,method='nearest').hvplot.line(y='reflectance',x='wavelengths',\n",
    "    #                                                                         color='black', frame_width=400)\n",
    "# Define the Dynamic Maps\n",
    "click_dmap = hv.DynamicMap(click_spectra, streams=[points_stream])\n",
    "hover_dmap = hv.DynamicMap(hover_spectra, streams=[posxy])\n",
    "# Plot the Map and Dynamic Map side by side\n",
    "hv.Layout(hover_dmap*click_dmap + map * points).cols(2).opts(\n",
    "    hv.opts.Points(active_tools=['point_draw'], size=10, tools=['hover'], color='white', line_color='gray'),\n",
    "    hv.opts.Overlay(show_legend=False, show_title=False, fontscale=1.5, frame_height=480)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Supervised Classification Using TOS Vegetation Structure Data\n",
    "\n",
    "In the last part of this lesson, we'll go over an example of how to run a supervised classification using the reflectance data along with observational \"vegetation structure\" data. We will create a random forest model to classify the families of trees represented in this SERC tile, using species determined from the vegetation structure data product (https://data.neonscience.org/data-products/DP1.10098.001)[DP1.10098.001] See the notebook __ to see how the vegetation structure data were pre-processed to generate the training data file. In this notebook, we will just read in this file as a starting point.\n",
    "\n",
    "Note that this is a quick-and-dirty example, and there are many ways you could improve the classification results, such as using more training data (this uses only data within this AOP tile), filtering out sub-optimal data (e.g. data collected in > 10 % cloud cover conditions, removing outliers (e.g. due to spatial mis-match, shadowing, or other issues), tuning the model parameters, or using a different classification algorithm.\n",
    "\n",
    "Let's get started, first by exploring the training data.\n",
    "\n",
    "### 5.1 Read in the training data\n",
    "\n",
    "First, read in the training data csv file (called `serc_2025_training_data.csv`) that was generated in the previous lesson. This file contains the training data for the random forest model, including the taxonId, family, and geographic coordinates (UTM easting and northing) of the training points. Note that there was not a lot of extensive pre-processing when creating this training data, so you may want to consider ways to assess and improve the training data quality before running the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woody_veg_data = pd.read_csv(r\"./data/serc_2025_training_data.csv\")\n",
    "woody_veg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `xarray` `sel` method to select the reflectance data corresponding to the training points. This will return an xarray dataset with the reflectance values for each band at the training point locations. As a test, let's plot the reflectance values for the first training point, which corresponds to an American Beech tree (Fagaceae family)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coordinates of the first training data pixel\n",
    "easting = woody_veg_data.iloc[0]['adjEasting']\n",
    "northing = woody_veg_data.iloc[0]['adjNorthing']\n",
    "\n",
    "# Extract the reflectance data from serc_refl_xr for the specified coordinates\n",
    "pixel_value = serc_refl_xr.sel(x=easting, y=northing, method='nearest')\n",
    "pixel_value.reflectance\n",
    "\n",
    "# Plot the reflectance values for the pixel\n",
    "plt.plot(pixel_value['wavelengths'].values.flatten(), pixel_value['reflectance'].values.flatten(), 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another test, we can plot the refletance value for one of the water bodies that shows up in the reflectance data. In the interactive plot, hover your mouse over one of the water bodies to see the UTM x, y coordinates, and then set those as the easting and northing, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the coordinates of the pixel over the pool in the NW corner of the site\n",
    "easting = 364750\n",
    "northing = 4305180\n",
    "\n",
    "# Extract and plot the reflectance data from serc_refl_xr specified coordinates\n",
    "pixel_value = serc_refl_xr.sel(x=easting, y=northing, method='nearest')\n",
    "plt.plot(pixel_value['wavelengths'].values.flatten(), pixel_value['reflectance'].values.flatten(), 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the spectral signature of water is quite different from that of vegetation.\n",
    "\n",
    "Now that we've extracted the pixel value for a single pixel, we can extract the reflectance values for all of the training data points. We will loop through the rows of the training dataframe and use the `xarray.Dataset.sel` method to select the reflectance values of the pixels corresponding to the same geographic location as the training data points, and then we will convert this into a pandas DataFrame for use in the random forest model.\n",
    "\n",
    "### 5.2 Inspect the training data\n",
    "\n",
    "It is good practice to visually inspect the spectral signatures of the training data, for example, as shown above, to make sure you are executing the code correctly, and that there aren't any major outliers (e.g. you might catch instances of geographic mismatch between the terrestrial location and the airborne data, or if there was a shadowing effect that caused the reflectance values to be very low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the wavelengths as column names for reflectance\n",
    "wavelengths = serc_refl_xr.wavelengths.values\n",
    "wavelength_cols = [f'refl_{int(wl)}' for wl in wavelengths]\n",
    "\n",
    "records = []\n",
    "\n",
    "for idx, row in woody_veg_data.iterrows():\n",
    "    # Find nearest pixel in xarray\n",
    "    y_val = serc_refl_xr.y.sel(y=row['adjNorthing'], method='nearest').item()\n",
    "    x_val = serc_refl_xr.x.sel(x=row['adjEasting'], method='nearest').item()\n",
    "    # Extract reflectance spectrum\n",
    "    refl = serc_refl_xr.reflectance.sel(y=y_val, x=x_val).values\n",
    "    # Build record: taxonID, easting, northing, reflectance values\n",
    "    record = {\n",
    "        'taxonID': row['taxonID'],\n",
    "        'family': row['family'],\n",
    "        'adjEasting': row['adjEasting'],\n",
    "        'adjNorthing': row['adjNorthing'],\n",
    "    }\n",
    "    # Add reflectance values with wavelength column names\n",
    "    record.update({col: val for col, val in zip(wavelength_cols, refl)})\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a dataframe from this records, and display the first few rows. You can see that the reflectance values are in columns named `refl_381`, `refl_386`, etc., and the family is in the `family` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectance_df = pd.DataFrame.from_records(records)\n",
    "# display the updated dataframe, which now includes the reflectance values for all \n",
    "reflectance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the unique taxonIDs and families represented in this training data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectance_df.taxonID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectance_df.family.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can manipulate the dataframe using `melt` to reshape the data and make it easier to display the reflectance spectra for each family. This is a helpful first step to visualizing the data and understanding what we're working with before getting into the classification model.\n",
    "\n",
    "After re-shaping, we can make a figure to display what the spectra look like for the different families that were recorded as part of the vegetation structure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt (re-shape) the dataframe; wavelength columns start with 'refl_'\n",
    "melted_df = reflectance_df.melt(\n",
    "    id_vars=['family', 'adjEasting', 'adjNorthing'],\n",
    "    value_vars=[col for col in reflectance_df.columns if col.startswith('refl_')],\n",
    "    var_name='wavelength',\n",
    "    value_name='reflectance'\n",
    ")\n",
    "\n",
    "# Convert 'wavelength' from 'refl_XXX' to integer\n",
    "melted_df['wavelength'] = melted_df['wavelength'].str.replace('refl_', '').astype(int)\n",
    "\n",
    "# Create a summary dataframe that aggregates statistics (mean, min, and max)\n",
    "summary_df = (\n",
    "    melted_df\n",
    "    .groupby(['family', 'wavelength'])\n",
    "    .reflectance\n",
    "    .agg(['mean', 'min', 'max'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Create a color palette\n",
    "palette = sns.color_palette('hls', n_colors=summary_df['family'].nunique())\n",
    "\n",
    "# Plot the mean reflectance spectra for each family, filling with semi-transparent color between the min and max value\n",
    "for i, (family, group) in enumerate(summary_df.groupby('family')):\n",
    "    # print(family)\n",
    "    if family in ['Fagaceae','Magnoliaceae','Hamamelidaceae','Juglandaceae','Aceraceae']:\n",
    "    # Plot mean line\n",
    "        plt.plot(group['wavelength'], group['mean'], label=family, color=palette[i])\n",
    "        # Plot min-max fill\n",
    "        plt.fill_between(\n",
    "            group['wavelength'],\n",
    "            group['min'],\n",
    "            group['max'],\n",
    "            color=palette[i],\n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Reflectance')\n",
    "plt.title('Average Reflectance Spectra by Family \\n (with Min/Max Range)')\n",
    "plt.legend(title='family')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the spectral signatures for the different families have similar shapes, and there is a decent amount of spread in the reflectance values for each family. Some of this spread may be due to the cloud conditions during the time of acquisition. Reflectance values of one species may vary depending on how cloudy it was, or whether there was a cloud obscuring the sun during the collection. The random forest model may not be able to fully distinguish between the different families based on their spectral signatures, but we will see!\n",
    "\n",
    "### 5.3 Set up the Random Forest Model to Classify Tree Families\n",
    "We can set up our random forest model by following the steps below:\n",
    "\n",
    "1. Prepare the training data by dropping the `family` column and setting the `family` column as the target variable. Remove the bad bands (NaN) from the reflectance predictor variables.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Train the random forest model on the training data.\n",
    "4. Evaluate the model on the testing data.\n",
    "5. Visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to import scikit-learn (sklearn) packages in order to run the random forest model. If you don't have these packages installed, you can install them using `!pip install scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Prepare and clean the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare the Data\n",
    "# Identify reflectance columns\n",
    "refl_cols = [col for col in reflectance_df.columns if col.startswith('refl_')]\n",
    "\n",
    "# Remove rows with any NaN in reflectance columns (these are the 'bad bands')\n",
    "clean_df = reflectance_df.dropna(axis=1)\n",
    "# re-define refl_columns after removing the ones that are all NaN\n",
    "refl_cols = [col for col in clean_df.columns if col.startswith('refl_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the cleaned dataframe\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have > 360 predictor variables (reflectance values for each band), and only 100 training points, so the model may not perform very well, due to over fitting. You can try increasing the number of training points by using more of the training data, or by using a different classification algorithm. Recall that we just pulled woody vegetation data from this tile that covers the tower, and there are also data collected throughout the rest of the TOS terrestrial sampling plots, so you could pull in more training data from the other tiles as well. You would likely not need all of the reflectance bands - for example, you could take every 2nd or 3rd band, or perform a PCA to reduce the number of bands. These are all things you could test as part of your model. For this lesson, we will include all of the valid reflectance bands for the sake of simplicity.\n",
    "\n",
    "That said, we will need to remove some of the families that are poorly represented in the training data, as they will not be able to be predicted by the model. We can do this by filtering out families that have less than 10 training points. If you leave these in, the model will not be able to predict them, and will return an error when you try to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of training data points for each family\n",
    "clean_df[['taxonID','family']].groupby('family').count().sort_values('taxonID', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where there are fewer than 10 samples\n",
    "# List of families to remove\n",
    "families_to_remove = ['Rosaceae', 'Pinaceae', 'Ulmaceae']\n",
    "\n",
    "# Remove rows where family is in the families_to_remove list\n",
    "clean_df = clean_df[~clean_df['family'].isin(families_to_remove)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Encode the target variable\n",
    "\n",
    "Next we need to encode the target variable (family) as integers, so that the model can work properly. Encoding is the process of converting from human-readable text (words / characters) to the byte representations used by computers. We can do this using the `LabelEncoder` from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the Target Variable (family)\n",
    "# Machine learning models require numeric targets. Use LabelEncoder:\n",
    "le = LabelEncoder()\n",
    "clean_df['family_encoded'] = le.fit_transform(clean_df['family'])\n",
    "# Display the cleaned dataframe after encoding the target variable\n",
    "clean_df[['taxonID','family','family_encoded','adjEasting','adjNorthing','refl_381','refl_2461']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the number of unique encodings is the same as the number of unique families, as a sanity check\n",
    "clean_df['family_encoded'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Split the data into training and testing sets\n",
    "\n",
    "In this next step, we will split the data into training and testing sets. We will use 80% of the data for training and 20% for testing (this is the default split). This is a common practice in machine learning to test the performance of the model, and to ensure that the model is able to generalize to new data (e.g. you're not over-fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Train/Test Sets\n",
    "X = clean_df[refl_cols].values\n",
    "y = clean_df['family_encoded'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Create a Random Forest Classifier Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier object and fit it to the training data\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the accuracy scores based off of the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these accuracy metrics mean?\n",
    "\n",
    "- **Precision**: Of the items predicted as a given class, what fraction were actually that class?  \n",
    "  (Precision = True Positives / (True Positives + False Positives))\n",
    "\n",
    "- **Recall**: Of all actual items of a given class, what fraction were correctly predicted?  \n",
    "  (Recall = True Positives / (True Positives + False Negatives))\n",
    "\n",
    "- **F1-score**: The harmonic mean of precision and recall. It balances both metrics.  \n",
    "  (F1 = 2 * (Precision * Recall) / (Precision + Recall))\n",
    "\n",
    "- **Support**: The number of true instances of each class in the dataset (i.e., how many samples belong to each class).\n",
    "\n",
    "These metrics are commonly used to evaluate classification models. Ideally we would be closer to 1 for the precision, recall, and f1-scores, which would indicate that the model is performing well. The support values indicate how many training points were used for each family, and you can see that some families have very few training points, which is likely negatively impacting the model performance.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "What are some things you could do to improve the classification results?\n",
    "\n",
    "Models are only as good as the underlying training data - so the better the training data (more + higher quality training data points) the better your results will be. \n",
    "\n",
    "You could consider the following:\n",
    "- **Increase the number of training points**: Use more training data from the other tiles\n",
    "- **Filter out sub-optimal data**: Remove training points that were collected in poor weather conditions (e.g. > 10% cloud cover), or that are outliers (e.g. due to spatial mis-match, shadowing, or other issues)\n",
    "- **Average the reflectance values over an entire tree crown**: In this example, we just pulled the reflectance values from a single pixel, but you could average the reflectance values over an entire tree crown to get a more representative value for each tree. If part of the tree is in shadow, you may want to remove that pixel from the average.\n",
    "- **Tune the model parameters**: You can adjust the hyperparameters of the random forest model, such as the number of trees, maximum depth, and minimum samples per leaf, to improve performance.\n",
    "- **Use a different classification algorithm**: Random forest is a good starting point, but you could also try other algorithms such as support vector machines, gradient boosting, or neural networks to see if they perform better.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In this example, we just scratched the surface of what you can do with NEON reflectance data. Here are some next steps you could take to further explore and analyze the data:\n",
    "- **Apply the model to the entire reflectance dataset**: Use the trained model to predict the tree families for all pixels in the reflectance dataset, and visualize the results.\n",
    "- **Try out the same model on SERC that was acquired in better weather conditions**: Use the reflectance data from SERC 2017, which was collected in clearer weather conditions, to see if the model performs better. Note that you may need to make some minor modifications to the aop_h5refl2xarray functions to accommodate the slightly different data structure of the directional reflectance data product (2019 data is not yet available with BRDF and topographic corrections.)\n",
    "- **Explore other NEON sites**: Use the `neonutilities` package to explore reflectance data from other NEON sites, and compare the spectral signatures of different land cover types.\n",
    "- **Add in other NEON AOP datasets**: In this lesson, we only looked at the reflectance data. How might other NEON data products compliment this analysis? For example, you could look at the lidar data to get information about the structure of the vegetation, for example the Canopy Height Model (CHM) or the Digital Surface Model (DSM). You could also look at the AOP imagery data.\n",
    "- **Use the reflectance data for other applications**: The reflectance data can be used for a variety of applications, such as mapping vegetation health, detecting disease or invasive species, and mapping droughts, wildfires, or other natural disturbances and their impacts. You could use a similar approach to explore some of these applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Apply the model to the full AOP reflectance data tile at SERC (IS tower area)\n",
    "\n",
    "# 1. Prepare the data:\n",
    "\n",
    "# Extract the reflectance array from your xarray Dataset:\n",
    "refl = serc_refl_xr['reflectance'].values  # shape: (y, x, bands)\n",
    "# Remove the bad bands so that we can apply the model, which only uses 363 bands\n",
    "good_bands = serc_refl_xr['good_wavelengths'].values.astype(bool)\n",
    "refl_good = refl[:, :, good_bands]         # shape: (y, x, n_good_bands)\n",
    "\n",
    "# 2. Reshape for prediction:\n",
    "nrows, ncols, nbands = refl_good.shape\n",
    "refl_2d = refl_good.reshape(-1, nbands)\n",
    "\n",
    "# 3. Apply the model:\n",
    "# Use the trained random forest model (e.g., rf_model) to predict values for every pixel\n",
    "preds = clf.predict(refl_2d)\n",
    "\n",
    "# 4. Reshape predictions back to image (y, x):\n",
    "pred_map = preds.reshape(nrows, ncols)\n",
    "\n",
    "# 5. Create an xarray DataArray for mapping, using the coordinates from your original data:\n",
    "pred_xr = xr.DataArray(\n",
    "    pred_map,\n",
    "    dims=('y', 'x'),\n",
    "    coords={'y': serc_refl_xr['y'], 'x': serc_refl_xr['x']},\n",
    "    name='classification_prediction'\n",
    ")\n",
    "\n",
    "# 6. Plot the map, using hvplot to visualize:\n",
    "# pred_xr.hvplot.image(x='x', y='y', cmap='tab20', title='Random Forest Classification Map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = le.classes_\n",
    "print('classes:', classes)\n",
    "\n",
    "class_labels = dict(enumerate(classes))\n",
    "print('class labels:',class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your prediction DataArray to a categorical type with labels:\n",
    "pred_xr_labeled = pred_xr.copy()\n",
    "pred_xr_labeled = pred_xr_labeled.assign_coords(\n",
    "    family=(('y', 'x'), np.vectorize(class_labels.get)(pred_xr.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the classification map, using hvplot to visualize:\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "# Plot using hvplot with the family coordinate as the color dimension:\n",
    "\n",
    "family_codes = np.arange(7)\n",
    "family_names = classes\n",
    "# Choose 7 distinct colors (can use tab10, Set1, or your own)\n",
    "colors = plt.get_cmap('tab10').colors[:7]  # 7 distinct colors from tab10\n",
    "cmap = ListedColormap([code_to_color[code] for code in family_codes])\n",
    "\n",
    "# Create a mapping from code to color\n",
    "code_to_color = {code: colors[i] for i, code in enumerate(family_codes)}\n",
    "\n",
    "pred_xr_labeled.hvplot.image(\n",
    "    x='x', y='y', groupby=[], color='family', cmap=cmap,\n",
    "    title='Random Forest Classification Map', frame_width=600, frame_height=600\n",
    ").opts(xormatter='%.0f', yformatter='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a custom colorbar for the classification map\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 1))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "# Create a colormap and norm\n",
    "cmap = ListedColormap([code_to_color[code] for code in family_codes])\n",
    "norm = BoundaryNorm(np.arange(-0.5, 7.5, 1), cmap.N)\n",
    "\n",
    "# Create colorbar\n",
    "cb = plt.colorbar(\n",
    "    plt.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "    cax=ax, orientation='horizontal', ticks=family_codes\n",
    ")\n",
    "cb.ax.set_xticklabels(family_names,fontsize=6)\n",
    "cb.set_label('Family')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgements\n",
    "\n",
    "Much of this tutorial was inspired by and adapated from the [NASA VITALS GitHub Repository](https://github.com/nasa/VITALS/tree/main/python). Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
