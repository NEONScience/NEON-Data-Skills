{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: e6ccf19a4b454ca594388eeaa88ebe12\n",
    "title: \"Calculate Vegetation Biomass from LiDAR Data in Python\"\n",
    "description: \"Learn to calculate the biomass of standing vegetation using a canopy height model data product.\" \n",
    "dateCreated: 2017-06-21 \n",
    "authors: Tristan Goulden\n",
    "contributors: Donal O'Leary\n",
    "estimatedTime: 1 hour\n",
    "packagesLibraries: numpy, gdal, matplotlib, matplotlib.pyplot, os\n",
    "topics: lidar,remote-sensing\n",
    "languagesTool: python\n",
    "dataProduct: DP1.10098.001, DP3.30015.001, \n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/Lidar/lidar-biomass/calc-biomass_py/calc-biomass_py.ipynb\n",
    "tutorialSeries: intro-lidar-py-series\n",
    "urlTitle: calc-biomass-py\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "In this tutorial, we will calculate the biomass for a section of the SJER site. We \n",
    "will be using the Canopy Height Model discrete LiDAR data product as well as NEON\n",
    "field data on vegetation data. This tutorial will calculate Biomass for individual \n",
    "trees in the forest. \n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Learn how to apply a guassian smoothing fernal for high-frequency spatial filtering\n",
    "* Apply a watershed segmentation algorithm for delineating tree crowns\n",
    "* Calculate biomass predictor variables from a CHM\n",
    "* Setup training data for Biomass predictions\n",
    "* Apply a Random Forest machine learning approach to calculate biomass\n",
    "\n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **os**\n",
    "* **numpy**\n",
    "* **gdal** \n",
    "* **matplotlib**\n",
    "* **scipy** \n",
    "\n",
    "\n",
    "### Download Data\n",
    "\n",
    "If you have already downloaded the data set for the Data Institute, you have the \n",
    "data for this tutorial within the SJER directory. If you would like to just \n",
    "download the data for this tutorial use the following links. \n",
    "\n",
    "**Download the Training Data:** <a href=\"./calc-biomass_py_files/SJER_Biomass_Training.csv\" download=\"SJER_Biomass_Training.csv\">SJER_Biomass_Training.csv</a> and save it in your working directory.\n",
    "\n",
    "**Download the SJER Canopy Height Model Tile:** <a href=\"https://storage.googleapis.com/neon-aop-products/2018/FullSite/D17/2018_SJER_3/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D17_SJER_DP3_256000_4106000_CHM.tif\" class=\"link--button link--arrow\">NEON_D17_SJER_DP3_256000_4106000_CHM.tif</a>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will calculate the biomass for a section of the SJER site. We \n",
    "will be using the Canopy Height Model discrete LiDAR data product as well as NEON\n",
    "field data on vegetation data. This tutorial will calculate Biomass for individual \n",
    "trees in the forest. \n",
    "\n",
    "The calculation of biomass consists of four primary steps:\n",
    "\n",
    "1. Delineating individual tree crowns\n",
    "2. Calculating predictor variables for all individuals\n",
    "3. Collecting training data\n",
    "4. Applying a regression model to estiamte biomass from predictors\n",
    "\n",
    "In this tutorial we will use a watershed segmentation algorithm for delineating \n",
    "tree crowns (step 1) and and a Random Forest (RF) machine learning algorithm for \n",
    "relating the predictor variables to biomass (part 4). The predictor variables were \n",
    "selected following suggestions by Gleason et al. (2012) and biomass estimates were \n",
    "determined from DBH (diamter at breast height) measurements following relationships \n",
    "given in Jenkins et al. (2003). \n",
    "\n",
    "## Get Started\n",
    "\n",
    "First, we will import some Python packages required to run various parts of the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gdal, osr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage as ndi\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to specify the directory where we will find and save the data needed for this tutorial. You may need to change this line if you have a different working directly, or to suit your local machine. I have decided to save my data in the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(os.path.join(os.sep,'neon_biomass_tutorial','data'))\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add libraries from skimage and sklearn which will help with the watershed delination, determination of predictor variables and random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import biomass specific libraries\n",
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.measure import regionprops\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions \n",
    "\n",
    "Now we will define a few functions that allow us to more easily work with the NEON data. \n",
    "\n",
    "* `plot_band_array`: function to plot NEON spatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plot band array function\n",
    "\n",
    "def plot_band_array(band_array,image_extent,title,cmap_title,colormap,colormap_limits):\n",
    "    plt.imshow(band_array,extent=image_extent)\n",
    "    cbar = plt.colorbar(); plt.set_cmap(colormap); plt.clim(colormap_limits)\n",
    "    cbar.set_label(cmap_title,rotation=270,labelpad=20)\n",
    "    plt.title(title); ax = plt.gca()\n",
    "    ax.ticklabel_format(useOffset=False, style='plain') \n",
    "    rotatexlabels = plt.setp(ax.get_xticklabels(),rotation=90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `array2raster`: function to output geotiff files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2raster(newRasterfn,rasterOrigin,pixelWidth,pixelHeight,array,epsg):\n",
    "\n",
    "    cols = array.shape[1]\n",
    "    rows = array.shape[0]\n",
    "    originX = rasterOrigin[0]\n",
    "    originY = rasterOrigin[1]\n",
    "\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Float32)\n",
    "    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))\n",
    "    outband = outRaster.GetRasterBand(1)\n",
    "    outband.WriteArray(array)\n",
    "    outRasterSRS = osr.SpatialReference()\n",
    "    outRasterSRS.ImportFromEPSG(epsg)\n",
    "    outRaster.SetProjection(outRasterSRS.ExportToWkt())\n",
    "    outband.FlushCache()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `raster2array`: function to conver rasters to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster2array(geotif_file):\n",
    "    metadata = {}\n",
    "    dataset = gdal.Open(geotif_file)\n",
    "    metadata['array_rows'] = dataset.RasterYSize\n",
    "    metadata['array_cols'] = dataset.RasterXSize\n",
    "    metadata['bands'] = dataset.RasterCount\n",
    "    metadata['driver'] = dataset.GetDriver().LongName\n",
    "    metadata['projection'] = dataset.GetProjection()\n",
    "    metadata['geotransform'] = dataset.GetGeoTransform()\n",
    "\n",
    "    mapinfo = dataset.GetGeoTransform()\n",
    "    metadata['pixelWidth'] = mapinfo[1]\n",
    "    metadata['pixelHeight'] = mapinfo[5]\n",
    "\n",
    "    metadata['ext_dict'] = {}\n",
    "    metadata['ext_dict']['xMin'] = mapinfo[0]\n",
    "    metadata['ext_dict']['xMax'] = mapinfo[0] + dataset.RasterXSize/mapinfo[1]\n",
    "    metadata['ext_dict']['yMin'] = mapinfo[3] + dataset.RasterYSize/mapinfo[5]\n",
    "    metadata['ext_dict']['yMax'] = mapinfo[3]\n",
    "\n",
    "    metadata['extent'] = (metadata['ext_dict']['xMin'],metadata['ext_dict']['xMax'],\n",
    "                          metadata['ext_dict']['yMin'],metadata['ext_dict']['yMax'])\n",
    "\n",
    "    if metadata['bands'] == 1:\n",
    "        raster = dataset.GetRasterBand(1)\n",
    "        metadata['noDataValue'] = raster.GetNoDataValue()\n",
    "        metadata['scaleFactor'] = raster.GetScale()\n",
    "\n",
    "        # band statistics\n",
    "        metadata['bandstats'] = {} # make a nested dictionary to store band stats in same \n",
    "        stats = raster.GetStatistics(True,True)\n",
    "        metadata['bandstats']['min'] = round(stats[0],2)\n",
    "        metadata['bandstats']['max'] = round(stats[1],2)\n",
    "        metadata['bandstats']['mean'] = round(stats[2],2)\n",
    "        metadata['bandstats']['stdev'] = round(stats[3],2)\n",
    "\n",
    "        array = dataset.GetRasterBand(1).ReadAsArray(0,0,\n",
    "                                                     metadata['array_cols'],\n",
    "                                                     metadata['array_rows']).astype(np.float)\n",
    "        array[array==int(metadata['noDataValue'])]=np.nan\n",
    "        array = array/metadata['scaleFactor']\n",
    "        return array, metadata\n",
    "\n",
    "    elif metadata['bands'] > 1:\n",
    "        print('More than one band ... need to modify function for case of multiple bands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `crown_geometric_volume_pth`: function to get tree crown volumn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crown_geometric_volume_pth(tree_data,min_tree_height,pth):\n",
    "    p = np.percentile(tree_data, pth)\n",
    "    tree_data_pth = [v if v < p else p for v in tree_data]\n",
    "    crown_geometric_volume_pth = np.sum(tree_data_pth - min_tree_height)\n",
    "    return crown_geometric_volume_pth, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_predictors`: function to get the trees from the biomass data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(tree,chm_array, labels):\n",
    "    indexes_of_tree = np.asarray(np.where(labels==tree.label)).T\n",
    "    tree_crown_heights = chm_array[indexes_of_tree[:,0],indexes_of_tree[:,1]]\n",
    "    \n",
    "    full_crown = np.sum(tree_crown_heights - np.min(tree_crown_heights))\n",
    "    \n",
    "    crown50, p50 = crown_geometric_volume_pth(tree_crown_heights,tree.min_intensity,50)\n",
    "    crown60, p60 = crown_geometric_volume_pth(tree_crown_heights,tree.min_intensity,60)\n",
    "    crown70, p70 = crown_geometric_volume_pth(tree_crown_heights,tree.min_intensity,70)\n",
    "    \n",
    "        \n",
    "    return [tree.label,\n",
    "            np.float(tree.area),\n",
    "            tree.major_axis_length,\n",
    "            tree.max_intensity,\n",
    "            tree.min_intensity, \n",
    "            p50, p60, p70,\n",
    "            full_crown, crown50, crown60, crown70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canopy Height Data\n",
    "\n",
    "With everything set up, we can now start working with our data by define the file path to our CHM file. Note that you will need to change this and subsequent filepaths according to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_file = os.path.join(data_path,'NEON_D17_SJER_DP3_256000_4106000_CHM.tif')\n",
    "chm_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we output the results, we will want to include the same file information as the input, so we will gather the file name information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get info from chm file for outputting results\n",
    "just_chm_file = os.path.basename(chm_file)\n",
    "just_chm_file_split = just_chm_file.split(sep=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the CHM data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chm_array, chm_array_metadata = raster2array(chm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..., plot it, and save the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the original CHM\n",
    "plt.figure(1)\n",
    "\n",
    "#Plot the CHM figure\n",
    "plot_band_array(chm_array,chm_array_metadata['extent'],\n",
    "                'Canopy Height Model',\n",
    "                'Canopy Height (m)',\n",
    "                'Greens',[0, 9])\n",
    "plt.savefig(os.path.join(data_path,just_chm_file.replace('.tif','.png')),dpi=300,orientation='landscape',\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like SJER primarily has low vegetation with scattered taller trees. \n",
    "\n",
    "## Create Filtered CHM\n",
    "\n",
    "Now we will use a Gaussian smoothing kernal (convolution) across the data set to remove spurious high vegetation points. This will help ensure we are finding the treetops properly before running the watershed segmentation algorithm. \n",
    "\n",
    "For different forest types it may be necessary to change the input parameters. Information on the function can be found in the <a href=\"https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.ndimage.filters.gaussian_filter.html\" target=\"_blank\">SciPy documentation</a>. \n",
    "\n",
    "Of most importance are the second and fifth inputs. The second input defines the standard deviation of the Gaussian smoothing kernal. Too large a value will apply too much smoothing, too small and some spurious high points may be left behind. The fifth, the truncate value, controls after how many standard deviations the Gaussian kernal will get cut off (since it theoretically goes to infinity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smooth the CHM using a gaussian filter to remove spurious points\n",
    "chm_array_smooth = ndi.gaussian_filter(chm_array,2,\n",
    "                                       mode='constant',cval=0,truncate=2.0)\n",
    "chm_array_smooth[chm_array==0] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now save a copy of filtered CHM. We will later use this in our code, so we'll output it into our data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the smoothed CHM\n",
    "array2raster(os.path.join(data_path,'chm_filter.tif'),\n",
    "             (chm_array_metadata['ext_dict']['xMin'],chm_array_metadata['ext_dict']['yMax']),\n",
    "             1,-1,\n",
    "             np.array(chm_array_smooth,dtype=float),\n",
    "             32611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine local maximums\n",
    "\n",
    "Now we will run an algorithm to determine local maximums within the image. Setting indices to 'False' returns a raster of the maximum points, as opposed to a list of coordinates. The footprint parameter is an area where only a single peak can be found. This should be approximately the size of the smallest tree. Information on more sophisticated methods to define the window can be found in Chen (2006).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate local maximum points in the smoothed CHM\n",
    "local_maxi = peak_local_max(chm_array_smooth,indices=False, footprint=np.ones((5, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new object `local_maxi` is an array of boolean values where each pixel is identified as either being the local maximum (`True`) or not being the local maximum (`False`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_maxi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is helpful, but it can be difficult to visualize boolean values using our typical numeric plotting procedures as defined in the `plot_band_array` function above. Therefore, we will need to convert this boolean array to an numeric format to use this function. Booleans convert easily to integers with values of `False=0` and `True=1` using the `.astype(int)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_maxi.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next ,we can plot the raster of local maximums bo coercing the boolean array into an array ofintegers inline. The following figure shows the difference in finding local maximums for a filtered vs. non-filtered CHM.\n",
    "\n",
    "We will save the graphics (.png) in an outputs folder sister to our working directory and data outputs (.tif) to our data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the local maximums\n",
    "plt.figure(2)\n",
    "plot_band_array(local_maxi.astype(int),chm_array_metadata['extent'],\n",
    "                'Maximum',\n",
    "                'Maxi',\n",
    "                'Greys',\n",
    "                [0, 1])\n",
    "\n",
    "plt.savefig(data_path+just_chm_file[0:-4]+ '_Maximums.png',\n",
    "            dpi=300,orientation='landscape',\n",
    "            bbox_inches='tight',pad_inches=0.1)\n",
    "\n",
    "array2raster(data_path+'maximum.tif',\n",
    "             (chm_array_metadata['ext_dict']['xMin'],chm_array_metadata['ext_dict']['yMax']),\n",
    "             1,-1,np.array(local_maxi,dtype=np.float32),32611)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to look at the overlap between the tree crowns and the local maxima from each method, it would appear a bit like this raster. \n",
    "\n",
    " <figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/raster-general/raster-classification-filter-vs-nonfilter.jpg\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/raster-general/raster-classification-filter-vs-nonfilter.jpg\"></a>\n",
    "\t<figcaption> The difference in finding local maximums for a filtered vs. \n",
    "\tnon-filtered CHM. \n",
    "\tSource: National Ecological Observatory Network (NEON) \n",
    "\t</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Apply labels to all of the local maximum points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify all the maximum points\n",
    "markers = ndi.label(local_maxi)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a mask layer of all of the vegetation points so that the watershed segmentation will only occur on the trees and not extend into the surrounding ground points. Since 0 represent ground points in the CHM, setting the mask to 1 where the CHM is not zero will define the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a CHM mask so the segmentation will only occur on the trees\n",
    "chm_mask = chm_array_smooth\n",
    "chm_mask[chm_array_smooth != 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed segmentation\n",
    "\n",
    "As in a river system, a watershed is divided by a ridge that divides areas. Here our watershed are the individual tree canopies and the ridge is the delineation between each one. \n",
    "\n",
    "<figure>\n",
    "\t<a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/raster-general/raster-classification-watershed-segments.png\">\n",
    "\t<img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/raster-general/raster-classification-watershed-segments.png\"></a>\n",
    "\t<figcaption> A raster classified based on watershed segmentation. \n",
    "\tSource: National Ecological Observatory Network (NEON) \n",
    "\t</figcaption>\n",
    "</figure>\n",
    "\n",
    "Next, we will perform the watershed segmentation which produces a raster of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perfrom watershed segmentation        \n",
    "labels = watershed(chm_array_smooth, markers, mask=chm_mask)\n",
    "labels_for_plot = labels.copy()\n",
    "labels_for_plot = np.array(labels_for_plot,dtype = np.float32)\n",
    "labels_for_plot[labels_for_plot==0] = np.nan\n",
    "max_labels = np.max(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the segments      \n",
    "plot_band_array(labels_for_plot,chm_array_metadata['extent'],\n",
    "                'Crown Segmentation','Tree Crown Number',\n",
    "                'Spectral',[0, max_labels])\n",
    "\n",
    "plt.savefig(data_path+just_chm_file[0:-4]+'_Segmentation.png',\n",
    "            dpi=300,orientation='landscape',\n",
    "            bbox_inches='tight',pad_inches=0.1)\n",
    "\n",
    "array2raster(data_path+'labels.tif',\n",
    "             (chm_array_metadata['ext_dict']['xMin'],\n",
    "              chm_array_metadata['ext_dict']['yMax']),\n",
    "             1,-1,np.array(labels,dtype=float),32611)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get several properties of the individual trees will be used as predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the properties of each segment\n",
    "tree_properties = regionprops(labels,chm_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get the predictor variables to match the (soon to be loaded) training data using the function defined above. The first column will be segment IDs, the rest will be the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_chm = np.array([get_predictors(tree, chm_array, labels) for tree in tree_properties])\n",
    "X = predictors_chm[:,1:]\n",
    "tree_ids = predictors_chm[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "We now bring in the training data file which is a simple CSV file with no header. If you haven't yet downloaded this, you can scroll up to the top of the lesson and find the **Download Data** section. The first column is biomass, and the remaining columns are the same predictor variables defined above. The tree diameter and max height are defined in the NEON vegetation structure data along with the tree DBH. The field validated values are used for training, while the other were determined from the CHM and camera images by manually delineating the tree crowns and pulling out the relevant information from the CHM. \n",
    "\n",
    "Biomass was calculated from DBH according to the formulas in Jenkins et al. (2003). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the file of training data  \n",
    "training_data_file = os.path.join(data_path,'SJER_Biomass_Training.csv')\n",
    "\n",
    "#Read in the training data from a CSV file\n",
    "training_data = np.genfromtxt(training_data_file,delimiter=',') \n",
    "\n",
    "#Grab the biomass (Y) from the first line\n",
    "biomass = training_data[:,0]\n",
    "\n",
    "#Grab the biomass prdeictors from the remaining lines\n",
    "biomass_predictors = training_data[:,1:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifiers\n",
    "\n",
    "We can then define parameters of the Random Forest classifier and fit the predictor variables from the training data to the Biomass estaimtes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paraemters for Random forest regressor\n",
    "max_depth = 30\n",
    "\n",
    "#Define regressor rules\n",
    "regr_rf = RandomForestRegressor(max_depth=max_depth, random_state=2)\n",
    "\n",
    "#Fit the biomass to regressor variables\n",
    "regr_rf.fit(biomass_predictors,biomass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the Random Forest model to the predictor variables to retreive biomass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the model to the predictors\n",
    "estimated_biomass = regr_rf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For outputting a raster, copy the labels raster to a biomass raster, then cycle through the segments and assign the biomass estimate to each individual tree segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set an out raster with the same size as the labels\n",
    "biomass_map =  np.array((labels),dtype=float)\n",
    "#Assign the appropriate biomass to the labels\n",
    "biomass_map[biomass_map==0] = np.nan\n",
    "for tree_id, biomass_of_tree_id in zip(tree_ids, estimated_biomass):\n",
    "    biomass_map[biomass_map == tree_id] = biomass_of_tree_id  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Biomass\n",
    "Collect some of the biomass statistics and then plot the results and save an output geotiff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(data_path,just_chm_file.replace('CHM.tif','Biomass.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get biomass stats for plotting\n",
    "mean_biomass = np.mean(estimated_biomass)\n",
    "std_biomass = np.std(estimated_biomass)\n",
    "min_biomass = np.min(estimated_biomass)\n",
    "sum_biomass = np.sum(estimated_biomass)\n",
    "\n",
    "print('Sum of biomass is ',sum_biomass,' kg')\n",
    "\n",
    "# Plot the biomass!\n",
    "plt.figure(5)\n",
    "plot_band_array(biomass_map,chm_array_metadata['extent'],\n",
    "                'Biomass (kg)','Biomass (kg)',\n",
    "                'winter',\n",
    "                [min_biomass+std_biomass, mean_biomass+std_biomass*3])\n",
    "\n",
    "# Save the biomass figure; use the same name as the original file, but replace CHM with Biomass\n",
    "plt.savefig(os.path.join(data_path,just_chm_file.replace('CHM.tif','Biomass.png')),\n",
    "            dpi=300,orientation='landscape',\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1)\n",
    "\n",
    "# Use the array2raster function to create a geotiff file of the Biomass\n",
    "array2raster(os.path.join(data_path,just_chm_file.replace('CHM.tif','Biomass.tif')),\n",
    "             (chm_array_metadata['ext_dict']['xMin'],chm_array_metadata['ext_dict']['yMax']),\n",
    "             1,-1,np.array(biomass_map,dtype=float),32611)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
