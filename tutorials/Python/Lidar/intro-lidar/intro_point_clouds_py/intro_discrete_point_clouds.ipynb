{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a016d7d",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: \n",
    "title: \"Introduction to NEON Discrete Lidar Point Clodus in Python\"\n",
    "description: \"Programmatically download lidar data and metadata and explore discrete lidar point clouds in Python\"\n",
    "dateCreated: 2022-09-24\n",
    "authors: Bridget Hass\n",
    "contributors: \n",
    "estimatedTime: 30 minutes\n",
    "packagesLibraries: requests, json, gdal, geopandas, laspy, lasrs\n",
    "topics:\n",
    "languagesTool: python\n",
    "dataProduct: DP3.10003.001, \n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/Lidar/intro-lidar/intro_point_clouds_py/intro_discrete_point_clouds.py\n",
    "tutorialSeries: \n",
    "urlTitle: neon-discrete-point-clouds\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c663f54",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Use Python functions to programmatically download NEON AOP data from the API\n",
    "* Download and plot shapefiles and kmls included in lidar metadata to visualize coverage for a given year\n",
    "* Explore and plot the AOP discrete lidar point cloud contents in Python using the `laspy` package\n",
    "* Read in and plot the AOP L3 raster data products (CHM, DTM, DSM) in Python using the `rasterio` package \n",
    "\n",
    "### Requirements\n",
    "\n",
    "To follow along with this code, you will need to install Python. We recommend starting in Jupyter Notebooks so you can run each cell \"chunk\" individually. You can install both Python and Jupyter Notebooks by downloading <a href=\"https://www.anaconda.com/products/distribution\" target=\"_blank\">Anaconda</a>.\n",
    "\n",
    "You will also need to have the script `download_aop_files.py` downloaded and saved in your working directory.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "If you are interested in learning more about the NEON API, or want a deeper dive in how this works with the Python `requests` package, please refer to the tutorial and webpages linked below.\n",
    " * <a href=\"https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-01-introduction-requests\" target=\"_blank\"> Introduction to NEON API in Python  </a>\n",
    " * <a href=\"https://data.neonscience.org/data-api/\" target=\"_blank\"> NEON Data API </a>\n",
    "\n",
    "For a handy resource on Jupyter Notebook tips, tricks and shortcuts, check out the DataQuest blog linked below.\n",
    " * <a href=\"https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-sh\" target=\"_blank\"> 28 Jupyter Notebook Tips, Tricks, and Shortcuts  </a>\n",
    " \n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **requests**\n",
    "* **json** \n",
    "* **gdal**\n",
    "* **fiona**\n",
    "* **geopandas**\n",
    "* **rasterio**\n",
    "* **laspy**\n",
    "* **lazrs**\n",
    "\n",
    "#### Installation Tips: \n",
    "Most of these packages can be installed using `pip install`, eg. to install `gdal`, in the command line, run:\n",
    "\n",
    "```python\n",
    "pip install gdal\n",
    "```\n",
    "\n",
    "or within Jupyter notebooks you can also install packages but have to include an ! before the statement to run a shell command (as you would from a command prompt):\n",
    "\n",
    "```python\n",
    "!pip install gdal\n",
    "```\n",
    "\n",
    "However for many of the geospatial packages (eg. gdal, fiona, geopandas, rasterio), there may be errors installing on your version of python if you don't find the correct wheel file. You can find the package wheel file specific to your version of python and your computer. A comprehensive archive of these geospatial (and other) wheel files can be found here:\n",
    "\n",
    "https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "\n",
    "For example, to install `gdal` on a windows 64 machine, using Python 3.9, download the file GDAL-3.4.3-cp39-cp39-win_amd64.whl, found here (you can also find this by navigating through the link above):\n",
    "\n",
    "https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal\n",
    "\n",
    "```python\n",
    "pip install C:\\Users\\username\\Downloads\\GDAL-3.4.3-cp39-cp39-win_amd64.whl\n",
    "```\n",
    "\n",
    "To confirm the installation worked properly, import the package and make sure there are no error messages.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4934176",
   "metadata": {},
   "source": [
    "First, we need to import the required Python packages. \n",
    "\n",
    "**Reminder**: If you haven't installed these packages (see more detailed installation instructions above), you can install them in the notebook as shown below. If the install doesn't work with a simple pip install, download the appropriate wheel file and substitute the package name with the wheel file name (including the full path). We recommend installing these packages one by one so you can make sure each package installs successfully.\n",
    "\n",
    "```python\n",
    "!pip install requests\n",
    "!pip install json\n",
    "!pip install gdal\n",
    "!pip install fiona\n",
    "!pip install geopandas\n",
    "!pip install rasterio\n",
    "!pip install laspy\n",
    "!pip install lazrs\n",
    "```\n",
    "\n",
    "Once all packages are successfully installed, import them as follows. Note that the `requests` and `json` packages will be imported when we import the separate module, so you don't need to import those separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import laspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda3685",
   "metadata": {},
   "source": [
    "Now we'll pull in all the functions in the module **neon_aop_download_functions.py**, linked at the top of this tutorial. \n",
    "\n",
    "First make sure this script is saved in your working directory, which we'll check below, otherwise you will need to provide the relative path to this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b014166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that script is saved in same folder:\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0352eb4",
   "metadata": {},
   "source": [
    "We can see that the download_functions script is there, so to import the contents, use the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neon_aop_download_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15118f",
   "metadata": {},
   "source": [
    "Alternatively, if you'd like to see the contents of that file, you can use the \"magic\" command `%load` as follows:\n",
    "\n",
    "```python\n",
    "%load neon_aop_download_functions.py\n",
    "```\n",
    "\n",
    "If you go this route, you will need to run the cell twice for the functions to be read into the ntoebook. The first run will load the functions and the second will run the cell. This option of loading in the functions may be useful if you wish to modify the functions in the notebook cell for your specific workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91bb3c",
   "metadata": {},
   "source": [
    "Now that we've imported in all the required packages and functions, we can get started! First let's take a look at what exactly we've imported by using the magic command `%whos`. Since there's no variable explorer in Jupyter Notebooks, this is a quick way to see what all we have in our working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6198109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f27f0",
   "metadata": {},
   "source": [
    "### Data Tip\n",
    "If you are unsure what a function or module does, you can find more information about the function in two ways: \n",
    "1. type `help(function_name)`, which will print out documentation below the cell, or\n",
    "2. type the function name followed by `?`, which will pop up the documentation at the bottom of your Jupyter Notebook window, and you can then exit out of it at your convenience\n",
    "\n",
    "```python\n",
    "help(requests)\n",
    "requests?\n",
    "```\n",
    "\n",
    "The functions loaded from the `neon_aop_download_functions.py` file also include similar documentation, so you can use this trick for these user-defined functions.\n",
    "\n",
    "```python\n",
    "help(list_available_urls)\n",
    "list_available_urls?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26033c7a",
   "metadata": {},
   "source": [
    "This tutorial will be working with the Discrete Return LiDAR Point Cloud https://data.neonscience.org/data-products/DP1.30003.001)\n",
    "\n",
    "First we'll start by defining variables that specify the NEON data product ID, site, and year. You can change these to look at a different site of your interest, but this tutorial will explore the NEON site `GUAN` in Domain 04, Puerto Rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd351604",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpID='DP1.30003.001' \n",
    "site = 'GUAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec828e5a",
   "metadata": {},
   "source": [
    "We can use the function `list_available_urls` to see what data is available for this data product and site. This function requires two inputs: the data product ID `dpID` and the site ID, `site`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e53b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(list_available_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_available_urls(dpID,site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f216fb1",
   "metadata": {},
   "source": [
    "The AOP has only flown Puerto Rico (D04) once so far, in 2018. D04 is only on the AOP schedule every 4 years; the next campaign is scheduled for the fall of 2022, so new data is expected relatively soon!\n",
    "\n",
    "Next let's set up some paths where we can save our downloaded data. We'll start with downloading geospatial metadata in order to get a sense of the coverage (geographic extents) of the flight area. We'll make a folder for the shapefiles (shp), kml files (which may be useful for interactively looking at the site boundaries in Google Earth), and a folder for the actual lidar (laz) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2018'\n",
    "data_root_path = './data/'+site+'/'+year+'/'\n",
    "shp_path = data_root_path+'shp/'\n",
    "kml_path = data_root_path+'kml/'\n",
    "laz_path = data_root_path+'laz/'\n",
    "print(data_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bea5c6",
   "metadata": {},
   "source": [
    "Next, let's take a look at the `download_aop_files` function, which we'll use to download the metadata and data that we want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(download_aop_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac2963",
   "metadata": {},
   "source": [
    "The only required inputs for this function are the `product` and the `site`; optionally we can specify the `year`, the `download_folder` to save the files, and a `match_string` to download a subset of the data by a string. By default, the function will display the size of the files, and prompt the user to continue the download (by typing `y`); any other response will halt the download. This is to prevent an accidental download of a large volume of data.\n",
    "\n",
    "We'll start by downloading the shape files, which are included as part of the metadata with the lidar data products. Because AOP data for a full site can be pretty large, and you may only need to work with a subset of the data for a given site, we recommend starting with the metadata to get a better sense of the data and your area of interest.\n",
    "\n",
    "There are summary shape files provided along with the lidar data for each site. These summary files end with `merged_tiles.shp/.shx`, so we can key off that string to download only the full boundary shape file. You could also download all of the individual `.shp` files for each data tile (L3 data is provided in 1km x 1km tiles), by using the match string `.shp`, or similarly all the `.kml` files, if you wanted to pull the data boundaries into Google Earth and explore more interactively.\n",
    "\n",
    "Try out some of the options below to explore different metadata products. Optionally, you can set `check_size=False` since these will all have small data volumes.\n",
    "\n",
    "```python\n",
    "#download all shp files (L3 - tiles)\n",
    "download_aop_files(dpID,site,year,kml_path,'.shp',check_size=False) \n",
    "\n",
    "#download all kml files (L1 - flightline + L3 - tiles)\n",
    "download_aop_files(dpID,site,year,kml_path,'.kml',check_size=False) \n",
    "\n",
    "#downloads only the full boundary kml files\n",
    "download_aop_files(dpID,site,year,kml_path,'full_boundary.kml',check_size=False) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659fd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_aop_files(dpID,site,year,shp_path,'merged_tiles.shp',check_size=False)\n",
    "download_aop_files(dpID,site,year,shp_path,'merged_tiles.shx',check_size=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd4f516",
   "metadata": {},
   "source": [
    "We can see that these files have downloaded to the expected location by listing the contents of the `shp_path` directory that we've made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(shp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810aed8c",
   "metadata": {},
   "source": [
    "download_aop_files(dpID,site,year,kml_path,'.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(shp_path,'2018_GUAN_1_merged_tiles.shp'))\n",
    "gdf.plot();\n",
    "ax = plt.gca(); ax.ticklabel_format(style='plain') \n",
    "ax.set_title('AOP Coverage of ' + site + ' in ' + year);\n",
    "plt.xticks(rotation=90); #optionally rotate the xtick labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_aop_files(dpID,site,year,kml_path,'full_boundary.kml',check_size=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded508d3",
   "metadata": {},
   "source": [
    "If you pull this into Google Earth you can see the coverage with more geographic context:\n",
    "\n",
    "<figure>\n",
    "    <a href=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/py-figs/intro-point-clouds-py/guan_boundary_google_earth.PNG\">\n",
    "    <img src=\"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/py-figs/intro-point-clouds-py/guan_boundary_google_earth.PNG\" width=\"400\"/>GUAN kml boundary</a>\n",
    "    <figcaption=\"KML boundary of GUAN\"</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f37077",
   "metadata": {},
   "source": [
    "Now that we can see the extent of the tiles, we'll pick a single tile in this area to download. For this example, I'll choose the tile \"724000_1985000\" towards the southern part of the site, including both land and sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_aop_files('DP1.30003.001',site,year,laz_path,match_string='725000_1985000_classified_point_cloud_colorized.laz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5306ffc3",
   "metadata": {},
   "source": [
    "We can use `os.listdir` again to check that this file successfully downloaded to the expected location. Alternatively you could go into your file explorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b928e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir(laz_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bf0ee",
   "metadata": {},
   "source": [
    "Now that we've successfully downloaded a laz (or zipped las) file, we can use the `laspy` package to read it in! We'll do that in the next line, reading the lidar file into the variable name `point_cloud`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "laz_data_file=os.path.join(laz_path,'NEON_D04_GUAN_DP1_725000_1985000_classified_point_cloud_colorized.laz')\n",
    "point_cloud=laspy.read(laz_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8595fdc",
   "metadata": {},
   "source": [
    "Reading in the file with with laspy.read() reads in both the metadata and the raw point cloud data. We can print out the `point_cloud` variable to show some basic information about what we've read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17107096",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3a616",
   "metadata": {},
   "source": [
    "`point_format.dimension_names` show us the available information stored in this LasData object format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(point_cloud.point_format.dimension_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03622c",
   "metadata": {},
   "source": [
    "In the next few cells, we can explore some of these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922493a",
   "metadata": {},
   "source": [
    "Let's get the `set` of this `list` to see all the unique classification values in this file. This may take a little time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(list(point_cloud.classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074e30d",
   "metadata": {},
   "source": [
    "Las files have \"predefined classification schemes defined by the American Society for Photogrammetry and Remote Sensing (ASPRS)\". Refer to https://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/lidar-point-classification.htm for more details.\n",
    "\n",
    "The following table lists the LAS classification codes defined by ASPRS for these LAS versions:\n",
    "\n",
    "| Classification value | Meaning           |\n",
    "|---------------------|-------------------|\n",
    "| 0                   | Never classified  |\n",
    "| 1                   | Unassigned        |\n",
    "| 2                   | Ground            |\n",
    "| 3                   | Low Vegetation    |\n",
    "| 4                   | Medium Vegetation |\n",
    "| 5                   | High Vegetation   |\n",
    "| 6                   | Building          |\n",
    "| 7                   | Low Point         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3aa807",
   "metadata": {},
   "source": [
    "Next let's take a look at what we can consider to be the main data - the geographic loation of each point in the point cloud. This can be accessed either by `point_cloud.X`, `point_cloud.Y`, `point_cloud.Z`, or more succinctly by `point_cloud.xyz`. Let's take a look at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d1ac4",
   "metadata": {},
   "source": [
    "We can see this is a 3-dimensional array, as we might expect. Let's read this into the variable `xyz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = point_cloud.xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e1908",
   "metadata": {},
   "source": [
    "We can see the size (or number of points) in this array using the built-in python function `len`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cffd09",
   "metadata": {},
   "source": [
    "There are > 2 million lidar points in this single 1km x 1km tile. For the rest of this exercise, we'll look at a random subset of these points, taking every100th point (you can change this subset factor, but when we visualize the data in a few steps, subsetting by a larger factor will speed up the time it takes to make the plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor=100\n",
    "points_dec = xyz[::factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e841d05",
   "metadata": {},
   "source": [
    "These point clouds have been \"colorized\" by the camera RGB imagery. If you refer back to the dimension names, you can see there are a `red`, `green`, and `blue` attributes. We can pull these into a single array by using `np.vstack`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = np.vstack((point_cloud.x, point_cloud.y, point_cloud.z)).transpose()\n",
    "colors = np.vstack((point_cloud.red, point_cloud.green, point_cloud.blue)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9abce",
   "metadata": {},
   "source": [
    "These colors have been scaled to store the color at a higher resolution, accomodated by the camera, so we'll need to re-scale the values between 0-1 in order to use them in our plot. The code below does this re-scaling, and then subsets the color data to by same factor we used to subset the `xyz` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_norm = (colors - np.min(colors))/np.ptp(colors)\n",
    "colors_dec = colors_norm[::factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4b6eb",
   "metadata": {},
   "source": [
    "### 3D Point Cloud Visualization \n",
    "Lastly, we can visualize this 3D data using matplotlib to see what the point cloud looks like. Other open-source tools such as https://plas.io/ are more interactive, and Python may not be the best platform to do this sort of visualization, but we can at least demonstrate how this might look.\n",
    "\n",
    "For this you'll need to import some visualization packages. These should be part of the standard Anaconda distribution.\n",
    "\n",
    "https://www.neonscience.org/resources/learning-hub/tutorials/introduction-light-detection-and-ranging-lidar-explore-point#toggle-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facaf40a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the las data in 3D\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(points_dec[:,0],points_dec[:,1],points_dec[:,2],color=colors_dec,s=4)\n",
    "ax.set_zlim3d(-10,50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead1959",
   "metadata": {},
   "source": [
    "We can see a mix of both land and sea here, with slightly fewer returns on the ocean. A lot of the energy from the laser beam is absorbed in water, so it is typical to see low density over bodies of water. Remember this plot only displays 1/100th of the data, so there is a lot more information stored in the las file than is shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3318d",
   "metadata": {},
   "source": [
    "### AOP Raster Data\n",
    "\n",
    "Lastly, we'll take a look at some of the derived (Level-3, or L3) data products generated from this point cloud data. NEON generates 5 different derived L3 products from the discrete data, summarized below. \n",
    "\n",
    "\n",
    "In the last part of this lesson, we'll show how to read in and visualize the CHM, DTM, and DSM data using the Python package `rasterio`. First we'll import the package and sub-package that's used to display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11195d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4582ab7a",
   "metadata": {},
   "source": [
    "In the next couple cells, we'll create a path to save the raster data, and then download the L3 CHM, DTM, and DSM geotiffs of the same tile as the point cloud file we downloaded earlier. You'll see the syntax here is the same, we are just using different data product IDs and match_strings with the appropriate extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5615522",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_path = data_root_path+'L3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_aop_files('DP3.30015.001',site,year,l3_path,match_string='725000_1985000_CHM.tif',check_size=False)\n",
    "download_aop_files('DP3.30024.001',site,year,l3_path,match_string='725000_1985000_DTM.tif',check_size=False)\n",
    "download_aop_files('DP3.30024.001',site,year,l3_path,match_string='725000_1985000_DSM.tif',check_size=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53a419",
   "metadata": {},
   "source": [
    "Next we'll read these in, using `rasterio`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chm = rasterio.open(os.path.join(l3_path,'NEON_D04_GUAN_DP3_725000_1985000_CHM.tif'))\n",
    "dtm = rasterio.open(os.path.join(l3_path,'NEON_D04_GUAN_DP3_725000_1985000_DTM.tif'))\n",
    "dsm = rasterio.open(os.path.join(l3_path,'NEON_D04_GUAN_DP3_725000_1985000_DSM.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3033d",
   "metadata": {},
   "source": [
    "And finally, we can plot the data using the rasterio `show` function that we imported earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b421839",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(18,4))\n",
    "show((chm), ax=ax1, title='CHM');\n",
    "show((dtm), ax=ax2, title='DTM');\n",
    "show((dsm), ax=ax3, title='DSM');\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007c680",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* **L1 Point Clouds (.laz)**: If you'd like to continue exploring the point cloud data in Python using `laspy`, <a href=\"https://laspy.readthedocs.io/en/latest/complete_tutorial.html\" target=\"_blank\"> laspy website </a> has some nice examples you can follow, now that you know how to download NEON point cloud data and read it into Python.\n",
    "* **L3 Rasters (.tif)**: Refer to the <a href=\"https://rasterio.readthedocs.io/en/latest/\" target=\"_blank\"> rasterio documentation </a> for more options on plotting, and beyond in rasterio.\n",
    "\n",
    "### Python and Beyond - Other Options for working with Point Cloud Data\n",
    "\n",
    "There are also a number of open-source tools for working with point-cloud data. Python may not be the best option for developing more rigourous processing workflows, for example. The resources below show some other recommended tools that can be integrated with Python for your analysis:\n",
    "\n",
    "* <a href=\"https://rapidlasso.com/lastools/\" target=\"_blank\">LAStools</a>\n",
    "* <a href=\"https://pdal.io/en/stable/\" target=\"_blank\">PDAL (Point Data Abstraction Library)</a> \n",
    "* <a href=\"https://r-lidar.github.io/lidRbook/\" target=\"_blank\"> lidR (R package for point cloud data)</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
