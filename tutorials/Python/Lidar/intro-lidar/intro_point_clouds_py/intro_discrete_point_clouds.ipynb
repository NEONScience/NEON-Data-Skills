{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d29468b2",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: \n",
    "title: \"Introduction to NEON Discrete Lidar Point Clodus in Python\"\n",
    "description: \"Programmatically download lidar data and metadata and explore discrete lidar point clouds in Python\"\n",
    "dateCreated: 2022-09-24\n",
    "authors: Bridget Hass\n",
    "contributors: \n",
    "estimatedTime: 30 minutes\n",
    "packagesLibraries: requests, json, gdal, geopandas, laspy, lasrs\n",
    "topics:\n",
    "languagesTool: python\n",
    "dataProduct: DP3.10003.001, \n",
    "code1: https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/Lidar/intro-lidar/intro_point_clouds_py/intro_discrete_point_clouds.py\n",
    "tutorialSeries: \n",
    "urlTitle: neon-discrete-point-clouds\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be6625",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Use Python functions to programmatically download NEON AOP data from the API\n",
    "* Download and plot shapefiles and kmls included in lidar metadata to visualize coverage for a given year\n",
    "* Explore the NEON discrete lidar point cloud contents in Python\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To follow along with this code, you will need to install Python. We recommend starting in Jupyter Notebooks so you can run each cell \"chunk\" individually. You can install both Python and Jupyter Notebooks by downloading <a href=\"https://www.anaconda.com/products/distribution\" target=\"_blank\"> Anaconda</a>.\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "If you are interested in learning more about the NEON API, or want a deeper die in how this works with the Python `requests` package, please refer to the tutorial and webpages linked below.\n",
    " * <a href=\"https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-01-introduction-requests\" target=\"_blank\"> Introduction to NEON API in Python  </a>\n",
    " * <a href=\"https://data.neonscience.org/data-api/\" target=\"_blank\"> NEON Data API </a>\n",
    "\n",
    "For a handy resource on Jupyter Notebook tips, tricks and shortcuts, check out the DataQuest blog linked below.\n",
    " * <a href=\"https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-sh\" target=\"_blank\"> 28 Jupyter Notebook Tips, Tricks, and Shortcuts  </a>\n",
    " \n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **requests**\n",
    "* **json** \n",
    "* **gdal**\n",
    "* **fiona**\n",
    "* **geopandas**\n",
    "* **laspy**\n",
    "* **lazrs**\n",
    "\n",
    "#### Installation Tips: \n",
    "Most of these packages can be installed using `pip install`, eg. to install `gdal`, in the command line, run:\n",
    "\n",
    "```python\n",
    "pip install gdal\n",
    "```\n",
    "\n",
    "or within Jupyter notebooks you can also install packages but have to include an ! before the statement to run a shell command (as you would from a command prompt):\n",
    "\n",
    "```python\n",
    "!pip install gdal\n",
    "```\n",
    "\n",
    "However for many of the geospatial packages (eg. gdal, fiona, geopandas), there may be errors installing on your version of python if you don't find the correct wheel file. You can find the package wheel file specific to your version of python and your computer. A comprehensive archive of these geospatial (and other) wheel files can be found here:\n",
    "\n",
    "https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "\n",
    "For example, to install `gdal` on a windows 64 machine, using Python 3.9, download the file GDAL-3.4.3-cp39-cp39-win_amd64.whl, found here (you can also find this by navigating through the link above):\n",
    "\n",
    "https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal\n",
    "\n",
    "```python\n",
    "pip install C:\\Users\\username\\Downloads\\GDAL-3.4.3-cp39-cp39-win_amd64.whl\n",
    "```\n",
    "\n",
    "Similarly, to install `fiona`, download the wheel file Fiona-1.8.21-cp39-cp39-win_amd64.whl\n",
    "\n",
    "```python\n",
    "pip install C:\\Users\\username\\Downloads\\Fiona-1.8.21-cp39-cp39-win_amd64.whl\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d3213",
   "metadata": {},
   "source": [
    "#Package Installation Requirements (for Python 3.9.12 on Windows 10)\n",
    "download package wheel files from https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "- https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal\n",
    "- https://www.lfd.uci.edu/~gohlke/pythonlibs/#fiona\n",
    "- !pip install C:\\Users\\bhass\\Downloads\\GDAL-3.4.3-cp39-cp39-win_amd64.whl\n",
    "- !pip install C:\\Users\\bhass\\Downloads\\Fiona-1.8.21-cp39-cp39-win_amd64.whl\n",
    "- !pip install geopandas\n",
    "- !pip install laspy\n",
    "\n",
    "also need to install las backend to unzip laz files\n",
    "https://laspy.readthedocs.io/en/latest/installation.html\n",
    "- !pip install lazrs\n",
    "\n",
    "Optional dependencies / features\n",
    "laspy does not support LAZ (.laz) file by itself but can use one of several optional dependencies to support compressed LAZ files.\n",
    "\n",
    "The 2 supported options are:\n",
    "1. lazrs [lazrs PyPi] - lazrs is a Rust port of the laszip compression and decompression. Its main advantage is that it is able to compress/decompress using multiple threads which can greatly speed up things. However it does not supports points with waveforms.\n",
    "2.  laszip-python (bindings to laszip) - laszip is the official and original LAZ implementation by Martin Isenburg. The advantage of the laszip backend is that its the official implementation, it supports points with waveform but does not offer multi-threaded compression/decompression.\n",
    "\n",
    "When encountering LAZ data, laspy will try to use one of the backend in the order described above. (Example: if lazrs is not installed or if it fails during, the process, laspy will try laszip)\n",
    "\n",
    "Both the laszip bindings and lazrs are available on pip.\n",
    "\n",
    "- !pip install open3d #for 3D visualization (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbee46",
   "metadata": {},
   "source": [
    "Starting with download, following similar workflow to:\n",
    "https://github.com/NEONScience/NEON-Data-Skills/blob/main/tutorials-in-development/CyverseNEON/aop_data_download/Download_NEON_AOP_Data_Python_API.ipynb\n",
    "\n",
    "Borrowing heavily from these tutorials, using NEON data.\n",
    "- https://towardsdatascience.com/guide-to-real-time-visualisation-of-massive-3d-point-clouds-in-python-ea6f00241ee0\n",
    "- https://medium.com/spatial-data-science/an-easy-way-to-work-and-visualize-lidar-data-in-python-eed0e028996c\n",
    "- https://geemap.org/notebooks/101_lidar/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09add57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fbd3030",
   "metadata": {},
   "source": [
    "First, import the required packages. \n",
    "\n",
    "Reminder: If you haven't installed these (see more detailed installation instructions above), you can install them in the notebook as shown below, substituting the path to the wheel file if the install doesn't work on it's own. Run the installation for each package separately (eg. each in it's own code cell) so you can make sure each package installs successfully.\n",
    "\n",
    "```python\n",
    "!pip install requests\n",
    "!pip install json\n",
    "!pip install gdal\n",
    "!pip install fiona\n",
    "!pip install geopandas\n",
    "!pip install laspy\n",
    "!pip install lazrs\n",
    "```\n",
    "\n",
    "Once all packages are successfully installed, import them as follows. Note that the `requests` and `json` packages will be imported when we import the a separate module, so you don't need to import those separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3d662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import laspy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f67a0d",
   "metadata": {},
   "source": [
    "Now we'll pull in all the functions in the module **neon_aop_download_functions.py**, linked at the top of this tutorial. \n",
    "\n",
    "First make sure this script is saved in your working directory, which we'll check below, otherwise you will need to provide the relative path to this script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56a6360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'intro_discrete_point_clouds.ipynb',\n",
       " 'neon_aop_download_functions.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that script is saved in same folder:\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b6674",
   "metadata": {},
   "source": [
    "We can see that the download_functions script is there, so to import the contents, use the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f24803df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neon_aop_download_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1620427a",
   "metadata": {},
   "source": [
    "Alternatively, if you'd like to see the contents of that file, you can use the \"magic\" command `%load` as follows:\n",
    "\n",
    "```python\n",
    "%load neon_aop_download_functions.py\n",
    "```\n",
    "\n",
    "If you go this route, you will need to run the cell twice for the functions to be read into the ntoebook. The first run will load the functions and the second will run the cell. This option of loading in the functions may be useful if you wish to modify the functions in the notebook cell for your specific workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load neon_download_functions.py\n",
    "\"\"\"\n",
    "Created on Mon Apr  8 08:18:00 2019\n",
    "@author: bhass\n",
    "\"\"\"\n",
    "\n",
    "import requests, urllib, os\n",
    "\n",
    "def list_available_urls(product,site):\n",
    "    \"\"\"\n",
    "    list_available urls lists the api url for a given product and site\n",
    "    --------\n",
    "     Inputs:\n",
    "         product: the data product code (eg. 'DP3.30015.001' - CHM)\n",
    "         site: the 4-digit NEON site code (eg. 'SRER', 'JORN')\n",
    "    --------\n",
    "    Usage:\n",
    "    --------\n",
    "    jorn_chm_urls = list_available_urls('DP3.30015.001','JORN')\n",
    "    \"\"\"\n",
    "    r = requests.get(\"http://data.neonscience.org/api/v0/products/\" + product)\n",
    "    for i in range(len(r.json()['data']['siteCodes'])):\n",
    "        if site in r.json()['data']['siteCodes'][i]['siteCode']:\n",
    "            data_urls=r.json()['data']['siteCodes'][i]['availableDataUrls']\n",
    "    if len(data_urls)==0:\n",
    "        print('WARNING: no urls found for product ' + product + ' at site ' + site)\n",
    "    else:\n",
    "        return data_urls\n",
    "\n",
    "def list_available_urls_by_year(product,site,year):\n",
    "    \"\"\"\n",
    "    list_available urls_by_year lists the api url for a given product, site, and year\n",
    "    --------\n",
    "     Inputs:\n",
    "         product: the data product code (eg. 'DP3.30015.001' - CHM)\n",
    "         site: the 4-digit NEON site code (eg. 'SRER', 'JORN')\n",
    "         year: the year data was collected (eg. '2017','2018','2019')\n",
    "    --------\n",
    "    Usage:\n",
    "    --------\n",
    "    jorn_chm_2018_url = list_available_urls_by_year('DP3.30015.001','JORN','2018')\n",
    "    \"\"\"\n",
    "    r = requests.get(\"http://data.neonscience.org/api/v0/products/\" + product)\n",
    "    for i in range(len(r.json()['data']['siteCodes'])):\n",
    "        if site in r.json()['data']['siteCodes'][i]['siteCode']:\n",
    "            all_data_urls=r.json()['data']['siteCodes'][i]['availableDataUrls']\n",
    "    data_urls = [url for url in all_data_urls if year in url]\n",
    "    if len(data_urls)==0:\n",
    "        print('WARNING: no urls found for product ' + product + ' at site ' + site + ' in year ' + year)\n",
    "    else:\n",
    "        return data_urls\n",
    "    \n",
    "def download_urls(url_list,download_folder_root,zip=False):\n",
    "    # downloads data from urls to folder, maintaining month-year folder structure\n",
    "    for url in url_list:\n",
    "        month = url.split('/')[-1]\n",
    "        download_folder = download_folder_root + month + '/'\n",
    "        if not os.path.exists(download_folder):\n",
    "            os.makedirs(download_folder)\n",
    "        r=requests.get(url)\n",
    "        files=r.json()['data']['files']\n",
    "        for i in range(len(files)):\n",
    "            if zip==False:\n",
    "                if '.zip' not in files[i]['name']:\n",
    "                    print('downloading ' + files[i]['name'] + ' to ' + download_folder)\n",
    "                    urllib.request.urlretrieve(files[i]['url'],download_folder + files[i]['name'])\n",
    "            elif zip==True:\n",
    "                if '.zip' in files[i]['name']:\n",
    "                    print('downloading ' + files[i]['name'] + ' to ' + download_folder)\n",
    "                    urllib.request.urlretrieve(files[i]['url'],download_folder + files[i]['name'])\n",
    "\n",
    "def download_file(url,filename):\n",
    "    r = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    return\n",
    "\n",
    "def get_file_size(urls,match_string):\n",
    "    size=0\n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "        files = r.json()['data']['files']\n",
    "        for i in range(len(files)):\n",
    "            if match_string is not None:\n",
    "                if match_string in files[i]['name']:\n",
    "    #             print('downloading ' + files[i]['name'] + ' to ' + download_folder)\n",
    "                    size += int(files[i]['size'])\n",
    "            else:\n",
    "                size += int(files[i]['size'])\n",
    "    if size < 10**6:\n",
    "        print('Download size:',size,'bytes')\n",
    "    elif size > 10**6 and size < 10**9:\n",
    "        print('Download size:',round(size/(10**6),2),'MB')\n",
    "    elif size > 10**9 and size < 10**12:\n",
    "        print('Download size:',round(size/(10**9),2),'GB')\n",
    "    else:\n",
    "        print('Download size:',round(size/(10**12),2),'TB')\n",
    "    return size\n",
    "\n",
    "def download_aop_files(data_product_id,site,year=None,download_folder='./data',match_string=None,check_size=True):\n",
    "    \"\"\"\n",
    "    download_aop_files downloads NEON AOP files from the AOP for a given data product, site, and \n",
    "    optional year, download folder, and \n",
    "    --------\n",
    "     Inputs:\n",
    "         required:\n",
    "             data_product_id: the data product code (eg. 'DP3.30015.001' - CHM)\n",
    "             site: the 4-digit NEON site code (eg. 'SRER', 'JORN')\n",
    "         \n",
    "         optional:\n",
    "             year: year (eg. '2020'); default (None) is all years\n",
    "             download_folder: folder to store downloaded files; default (./data) in current directory\n",
    "             match_string: subset of data to match, need to use exact pattern for file name\n",
    "             check_size: prompt to continue download (y/n) after displaying size; default = True\n",
    "    --------\n",
    "    Usage:\n",
    "    --------\n",
    "    download_aop_files('DP3.30015.001','JORN','2019','./data/JORN_2019/CHM','314000_3610000_CHM.tif')\n",
    "    \"\"\"\n",
    "    \n",
    "    #get a list of the urls for a given data product, site, and year (if included)\n",
    "    if year is not None:\n",
    "        urls = list_available_urls_by_year(data_product_id,site,year)\n",
    "    else:\n",
    "        urls = list_available_urls(data_product_id,site)\n",
    "    \n",
    "    #make the download folder if it doesn't already exist\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    #get the size of all the files you are planning to download\n",
    "    size = get_file_size(urls,match_string)\n",
    "    \n",
    "    #prompt to continue with download after displaying the file size\n",
    "    if check_size:\n",
    "        if input(\"Do you want to continue with the download? (y/n) \") != \"y\":\n",
    "            print('Exiting download_aop_files')\n",
    "            return\n",
    "    \n",
    "    #download files in the urls\n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "        files = r.json()['data']['files']\n",
    "        for i in range(len(files)):\n",
    "            if match_string is not None:\n",
    "                if match_string in files[i]['name']:\n",
    "                    print('downloading ' + files[i]['name'] + ' to ' + download_folder)\n",
    "                    try:\n",
    "                        download_file(files[i]['url'],os.path.join(download_folder,files[i]['name']))\n",
    "                    except requests.exceptions.RequestException as e:\n",
    "                        print(e)\n",
    "            else:\n",
    "                try:\n",
    "                    download_file(files[i]['url'],os.path.join(download_folder,files[i]['name']))\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640fa37",
   "metadata": {},
   "source": [
    "Now that we've imported in all the required packages and functions, we can get started! First let's take a look at what exactly we've imported by using the magic command `%whos`. Since there's no variable explorer in Jupyter Notebooks, this is a quick way to see what all we have in our working environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b190088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                      Type        Data/Info\n",
      "---------------------------------------------------\n",
      "download_aop_files            function    <function download_aop_fi<...>es at 0x0000016A68B848B0>\n",
      "download_file                 function    <function download_file at 0x0000016A68B84B80>\n",
      "download_urls                 function    <function download_urls at 0x0000016A68B84CA0>\n",
      "dpID                          str         DP1.30003.001\n",
      "get_file_size                 function    <function get_file_size at 0x0000016A68B84C10>\n",
      "gpd                           module      <module 'geopandas' from <...>\\geopandas\\\\__init__.py'>\n",
      "laspy                         module      <module 'laspy' from 'C:\\<...>ges\\\\laspy\\\\__init__.py'>\n",
      "list_available_urls           function    <function list_available_<...>ls at 0x0000016A637D4F70>\n",
      "list_available_urls_by_year   function    <function list_available_<...>ar at 0x0000016A68B84040>\n",
      "np                            module      <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "os                            module      <module 'os' from 'C:\\\\Us<...>\\\\Anaconda3\\\\lib\\\\os.py'>\n",
      "plt                           module      <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "requests                      module      <module 'requests' from '<...>\\\\requests\\\\__init__.py'>\n",
      "site                          str         GUAN\n",
      "urllib                        module      <module 'urllib' from 'C:<...>ib\\\\urllib\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0181dd6e",
   "metadata": {},
   "source": [
    "### Data Tip\n",
    "If you are unsure what a function or module does, you can find more information about the function in two ways: \n",
    "1. type `help(function_name)`, which will print out documentation in the cell below, or\n",
    "2. type the function name followed by `?`, which will pop up the documentation at the bottom of your Jupyter Notebook window, and you can then exit out of it at your convenience\n",
    "\n",
    "```python\n",
    "help(requests)\n",
    "requests?\n",
    "```\n",
    "\n",
    "The functions loaded from the `neon_aop_download_functions.py` file also include similar documentation, so you can use this trick for these user-defined functions.\n",
    "\n",
    "```python\n",
    "help(list_available_urls)\n",
    "list_available_urls?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26033c7a",
   "metadata": {},
   "source": [
    "This tutorial will be working with the Discrete Return LiDAR Point Cloud https://data.neonscience.org/data-products/DP1.30003.001)\n",
    "\n",
    "First we'll start by defining variables that specify the NEON data product ID, site, and year. You can change these to look at a different site of your interest, but this tutorial will explore the NEON site `GUAN` in Domain 04, Puerto Rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd351604",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpID='DP1.30003.001' \n",
    "site = 'GUAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febfc054",
   "metadata": {},
   "source": [
    "We can use the function `list_available_urls` to see what data is available for this data product and site. This function requires two inputs: the data product ID `dpID` and the site ID, `site`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a85ee04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function list_available_urls in module neon_aop_download_functions:\n",
      "\n",
      "list_available_urls(product, site)\n",
      "    list_available urls lists the api url for a given product and site\n",
      "    --------\n",
      "     Inputs:\n",
      "         product: the data product code (eg. 'DP3.30015.001' - CHM)\n",
      "         site: the 4-digit NEON site code (eg. 'SRER', 'JORN')\n",
      "    --------\n",
      "    Usage:\n",
      "    --------\n",
      "    jorn_chm_urls = list_available_urls('DP3.30015.001','JORN')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(list_available_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb36a921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://data.neonscience.org/api/v0/data/DP1.30003.001/GUAN/2018-05']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_available_urls(dpID,site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38028002",
   "metadata": {},
   "source": [
    "The AOP has only flown Puerto Rico (D04) once so far. D04 is only scheduled every 4-5 years, and the next campaign is scheduled for the fall of 2022, so new data is expected relatively soon!\n",
    "\n",
    "Next let's set up some paths to download data. We'll start with downloading geospatial metadata in order to get a sense of the coverage and geographic extents of the flight area. We'll make a folder for the shapefiles (shp), kml files (which may be useful for interactively looking at the site boundaries in Google Earth, and a folder for the actual lidar (laz) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b4bd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/GUAN/2018/\n"
     ]
    }
   ],
   "source": [
    "year='2018'\n",
    "data_root_path = './data/'+site+'/'+year+'/'\n",
    "shp_path = data_root_path+'shp/'\n",
    "kml_path = data_root_path+'kml/'\n",
    "laz_path = data_root_path+'laz/'\n",
    "print(data_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065ae40e",
   "metadata": {},
   "source": [
    "Next, let's take a look at the `download_aop_files` function, which we'll use to download the metadata and data that we want to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fc8c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function download_aop_files in module neon_aop_download_functions:\n",
      "\n",
      "download_aop_files(data_product_id, site, year=None, download_folder='./data', match_string=None, check_size=True)\n",
      "    download_aop_files downloads NEON AOP files from the AOP for a given data product, site, and \n",
      "    optional year, download folder, and \n",
      "    --------\n",
      "     Inputs:\n",
      "         required:\n",
      "             data_product_id: the data product code (eg. 'DP3.30015.001' - CHM)\n",
      "             site: the 4-digit NEON site code (eg. 'SRER', 'JORN')\n",
      "         \n",
      "         optional:\n",
      "             year: year (eg. '2020'); default (None) is all years\n",
      "             download_folder: folder to store downloaded files; default (./data) in current directory\n",
      "             match_string: subset of data to match, need to use exact pattern for file name\n",
      "             check_size: prompt to continue download (y/n) after displaying size; default = True\n",
      "    --------\n",
      "    Usage:\n",
      "    --------\n",
      "    download_aop_files('DP3.30015.001','JORN','2019','./data/JORN_2019/CHM','314000_3610000_CHM.tif')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(download_aop_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b212c",
   "metadata": {},
   "source": [
    "We'll start by downloading the shape files, which are included as part of the metadata with the lidar data products. There are summary shape files for each site which end in `merged_tiles`, so we can key off that string to download only the full boundary. You could also download all `.shp` files, which would include shape files for each tile. For this we can \n",
    "\n",
    "```python\n",
    "download_aop_files(dpID,site,year,kml_path,'.kml')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4659fd5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download size: 0.78 kB\n",
      "downloading 2018_GUAN_1_merged_tiles.shp to ./data/GUAN/2018/shp/\n",
      "Download size: 0.0 kB\n",
      "downloading 2018_GUAN_1_merged_tiles.shx to ./data/GUAN/2018/shp/\n"
     ]
    }
   ],
   "source": [
    "download_aop_files(dpID,site,year,shp_path,'merged_tiles.shp',check_size=False)\n",
    "download_aop_files(dpID,site,year,shp_path,'merged_tiles.shx',check_size=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f16244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(shp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2393301",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_aop_files(dpID,site,year,laz_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810aed8c",
   "metadata": {},
   "source": [
    "download_aop_files(dpID,site,year,kml_path,'.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(os.path.join(shp_path,'2019_SERC_4_merged_tiles.shp'))\n",
    "gdf.plot();\n",
    "ax = plt.gca(); ax.ticklabel_format(style='plain') \n",
    "ax.set_title('AOP Coverage of ' + site + ' in ' + year);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f42783",
   "metadata": {},
   "source": [
    "Now that we can see the extent of the tiles, we'll pick a single tile in this area to download. For this example, I'll choose the tile \"544000_4976000\" towards the Eastern part of the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_aop_files('DP1.30003.001',site,year,laz_path,match_string='367000_4306000_classified_point_cloud_colorized.laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b928e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.listdir(laz_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "laz_data_file=os.path.join(laz_path,'NEON_D02_SERC_DP1_367000_4306000_classified_point_cloud_colorized.laz')\n",
    "point_cloud=laspy.read(laz_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8595fdc",
   "metadata": {},
   "source": [
    "Reading in the file with with laspy.read() reads in both the metadata and the raw point cloud data. We can print out the `point_cloud` variable to show some basic information about what we've read in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17107096",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3a616",
   "metadata": {},
   "source": [
    "`point_format.dimension_names` show us the available information stored in this LasData object format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(point_cloud.point_format.dimension_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03622c",
   "metadata": {},
   "source": [
    "In the next few cells, we can explore some of these variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33474e",
   "metadata": {},
   "source": [
    "set(list(point_cloud.classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074e30d",
   "metadata": {},
   "source": [
    "https://desktop.arcgis.com/en/arcmap/10.3/manage-data/las-dataset/lidar-point-classification.htm\n",
    "If you are working with LAS 1.1 - 1.4 specification, refer to the predefined classification schemes defined by the American Society for Photogrammetry and Remote Sensing (ASPRS) for the desired data category. The following table lists the LAS classification codes defined by ASPRS for these LAS versions:\n",
    "\n",
    "| Classification value | Meaning           |\n",
    "|---------------------|-------------------|\n",
    "| 0                   | Never classified  |\n",
    "| 1                   | Unassigned        |\n",
    "| 2                   | Ground            |\n",
    "| 3                   | Low Vegetation    |\n",
    "| 4                   | Medium Vegetation |\n",
    "| 5                   | High Vegetation   |\n",
    "| 6                   | Building          |\n",
    "| 7                   | Low Point         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud.xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec7415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = point_cloud.xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cffd09",
   "metadata": {},
   "source": [
    "There are 6.4 million lidar points in this single 1km x 1km tile! For the rest of this exercise, we'll just look at a random subset of these points, taking every 200th point (you can change this subset factor, but when we visualize the data in a few steps, subsetting by a larger factor will speed up the time it takes to make the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor=100\n",
    "points_dec = xyz[::factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fc3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(points_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = np.vstack((point_cloud.x, point_cloud.y, point_cloud.z)).transpose()\n",
    "colors = np.vstack((point_cloud.red, point_cloud.green, point_cloud.blue)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75f0e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_norm = (colors - np.min(colors))/np.ptp(colors)\n",
    "colors_dec = colors_norm[::factor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4b6eb",
   "metadata": {},
   "source": [
    "### 3D Point Cloud Visualization \n",
    "While Python arguably isn't the best way to visualize this 3D data, we can use matplotlib to see what this looks like. Other open-source tools such as https://plas.io/ are more interactive!\n",
    "\n",
    "https://www.neonscience.org/resources/learning-hub/tutorials/introduction-light-detection-and-ranging-lidar-explore-point#toggle-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "# from mpl_toolkits.mplot3d.axes3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facaf40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X,Y,Z\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(points_dec[:,0],points_dec[:,1],points_dec[:,2],color=colors_dec,s=4)\n",
    "ax.set_zlim3d(-10,90)\n",
    "# ax.set_zlim3d(1400,2200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(point_cloud.header)\n",
    "print(point_cloud.header.point_format)\n",
    "print(point_cloud.header.point_count)\n",
    "print(point_cloud.vlrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007c680",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "The laspy website has some nice examples you can follow (using NEON data) on the laspy website:\n",
    "https://laspy.readthedocs.io/en/latest/complete_tutorial.html\n",
    "\n",
    "### Other open-source tools for working with las (point cloud) data:\n",
    "LAStools - there is a free version\n",
    "PDAL (similar to GDAL but for Point clouds)\n",
    "lidR (R)\n",
    "GitHub examples!\n",
    "https://github.com/topics/point-cloud\n",
    "also lidar, lidar-point-cloud, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
