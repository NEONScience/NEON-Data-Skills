<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Linking NEON aquatic observational and instrument data to answer critical questions in aquatic ecology at the continental scale</title>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
section.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
</head>
<body>
<div class="frontmatter">
<div class="title"><h1>Linking NEON aquatic observational and instrument data to answer critical questions in aquatic ecology at the continental scale</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3></h3></div>
</div>
<div class="body">
<div id="ds-objectives" markdown="1"
<h2 id="objectives">Objectives</h2>
<p>After completing this activity, you will be able to:</p>
<ul>
<li>Download NEON AIS and AOS data using the <code>neonUtilities</code> package.</li>
<li>Understand downloaded data packages and load them into R for analyses.</li>
<li>Understand the similarities and linkages between different NEON data products.</li>
<li>Join data sets within and between data products by standardized variables.</li>
<li>Plot instrumented and observational data in the same plotting field.</li>
</ul>
<h2 id="things-you-ll-need-to-complete-this-tutorial">Things You’ll Need To Complete This Tutorial</h2>
<p>To complete this tutorial you will need R (version &gt;3.4) and,
preferably, RStudio loaded on your computer.</p>
<h3 id="install-r-packages">Install R Packages</h3>
<ul>
<li><strong>neonUtilities</strong>: Basic functions for accessing NEON data</li>
<li><strong>neonOS</strong>: Basic data wrangling for NEON Observational Data</li>
<li><strong>tidyverse</strong>: Collection of R packages designed for data science</li>
<li><strong>plotly</strong>: Tool for creating interactive, web-based visualizations</li>
<li><strong>vegan</strong>: Functions for analyzing ecological data</li>
<li><strong>base64enc</strong>: Tools for base64 encoding</li>
</ul>
<p>These packages are on CRAN and can be installed by
<code>install.packages()</code>.</p>
<h3 id="additional-resources">Additional Resources</h3>
<ul>
<li><a href="https://github.com/NEONScience/NEON-Utilities/neonUtilities" target="_blank">GitHub repository for neonUtilities</a></li>
<li><a href="https://github.com/NEONScience/NEON-OS-data-processing" target="_blank">GitHub repository for neonOS</a></li>
</ul>
</div>
<h2 id="introduction">Introduction</h2>
<h3 id="tutorial-overview">Tutorial Overview</h3>
<p>This tutorial covers downloading NEON Aquatic Instrument Subsystem (AIS) and
Aquatic Observation Subsystem (AOS) data products using the <code>neonUtilities</code> R
package, as well as basic instruction in beginning to explore and work with the
downloaded data. This includes navigating data packages documentation,
summarizing data for plotting and analysis, combining data within and between
data products, and visualizing AIS and AOS data separately and together.</p>
<h3 id="helpful-links">Helpful Links</h3>
<p>Getting started with NEON data: <a href="https://www.neonscience.org/resources/getting-started-neon-data-resources">https://www.neonscience.org/resources/getting-started-neon-data-resources</a></p>
<p>Contact us form: <a href="https://www.neonscience.org/about/contact-us">https://www.neonscience.org/about/contact-us</a></p>
<p>Teaching Modules: <a href="https://www.neonscience.org/resources/learning-hub/teaching-modules">https://www.neonscience.org/resources/learning-hub/teaching-modules</a> <br />
QUBES modules: <a href="https://qubeshub.org/community/groups/neon/educational_resources">https://qubeshub.org/community/groups/neon/educational_resources</a> <br />
EDDIE modules : <a href="https://serc.carleton.edu/eddie/macrosystems/index.html">https://serc.carleton.edu/eddie/macrosystems/index.html</a></p>
<p>Spatial data and maps: <a href="https://neon.maps.arcgis.com/home/index.html">https://neon.maps.arcgis.com/home/index.html</a></p>
<p>NEON data portal: <a href="https://data.neonscience.org/">https://data.neonscience.org/</a></p>
<p>NEONScience GitHub repo: <a href="https://github.com/NEONScience">https://github.com/NEONScience</a> <br />
SFS 2025 NEON Workshop GitHub repo:
<a href="https://github.com/NEONScience/WORKSHOP-SFS-2025">https://github.com/NEONScience/WORKSHOP-SFS-2025</a></p>
<h2 id="download-files-and-load-directly-to-r-loadbyproduct">Download Files and Load Directly to R: loadByProduct()</h2>
<p>The most popular function in <code>neonUtilities</code> is <code>loadByProduct()</code>.
This function downloads data from the NEON API, merges the site-by-month
files, and loads the resulting data tables into the R environment,
assigning each data type to the appropriate R class. This is a popular
choice because it ensures you’re always working with the most up-to-date data,
and it ends with ready-to-use tables in R. However, if you use it in
a workflow you run repeatedly, keep in mind it will re-download the
data every time.</p>
<p>Before we get the NEON data, we need to install (if not already done) and load
the neonUtilities R package, as well as other packages we will use in the
analysis.</p>
<pre><code># # Install neonUtilities package if you have not yet.

# install.packages(&quot;neonUtilities&quot;)

# install.packages(&quot;neonOS&quot;)

# install.packages(&quot;tidyverse&quot;)

# install.packages(&quot;plotly&quot;)

# install.packages(&quot;vegan&quot;)

# install.packages(&quot;base64enc&quot;)


# Set global option to NOT convert all character variables to factors

options(stringsAsFactors=F)



# Load required packages

library(neonUtilities)

library(neonOS)

library(tidyverse)

library(plotly)

library(vegan)

library(base64enc)
</code></pre>
<p>The inputs to <code>loadByProduct()</code> control which data to download and how
to manage the processing. The following are frequently used inputs:</p>
<ul>
<li><code>dpID</code>: the data product ID, e.g. DP1.20288.001</li>
<li><code>site</code>: defaults to “all”, meaning all sites with available data;
can be a vector of 4-letter NEON site codes, e.g.
<code>c(&quot;MART&quot;,&quot;ARIK&quot;,&quot;BARC&quot;)</code>.</li>
<li><code>startdate</code> and <code>enddate</code>: defaults to NA, meaning all dates
with available data; or a date in the form YYYY-MM, e.g.
2017-06. Since NEON data are provided in month packages, finer
scale querying is not available. Both start and end date are
inclusive.</li>
<li><code>package</code>: either basic or expanded data package. Expanded data
packages generally include additional information about data
quality, such as individual quality flag test results. Not every
NEON data product has an expanded package; if the expanded package
is requested but there isn’t one, the basic package will be
downloaded.</li>
<li><code>release</code>: The data release to be downloaded; either ‘current’
or the name of a release, e.g. ‘RELEASE-2021’. ‘current’ returns
provisional data in addition to the most recent release. To
download only provisional data, use release=‘PROVISIONAL’.
Defaults to ‘current’. See
<a href="https://www.neonscience.org/data-samples/data-management/data-revisions-releases">https://www.neonscience.org/data-samples/data-management/data-revisions-releases</a>
for more information.</li>
<li><code>include.provisional</code>: Should provisional data be included in the downloaded
files? Defaults to F.</li>
<li><code>timeIndex</code>: defaults to “all”, to download all data; or the
number of minutes in the averaging interval. See example below;
only applicable to IS data.</li>
<li><code>check.size</code>: T or F; should the function pause before downloading
data and warn you about the size of your download? Defaults to T; if
you are using this function within a script or batch process you
will want to set this to F.</li>
<li><code>token</code>: this allows you to input your NEON API token to obtain faster
downloads.
Learn more about NEON API tokens in the <a href="https//:www.neonscience.org/neon-api-tokens-tutorial" target="_blank"><strong>Using an API Token when Accessing NEON Data with neonUtilities</strong> tutorial</a>.</li>
</ul>
<p>There are additional inputs you can learn about in the
<a href="https//:www.neonscience.org/neonDataStackR" target="_blank"><strong>Use the neonUtilities R Package to Access NEON Data</strong> tutorial</a>.</p>
<p>The <code>dpID</code> is the data product identifier of the data you want to
download. The DPID can be found on the
<a href="http://data.neonscience.org/data-products/explore" target="_blank">
Explore Data Products page</a>.</p>
<p>It will be in the form DP#.#####.###. For this tutorial, we’ll use some data
products collected in NEON’s aquatics program:</p>
<ul>
<li>DP1.20120.001: Macroinvertebrate collection</li>
<li>DP4.00130.001: Continuous discharge</li>
</ul>
<p>Now it’s time to consider the NEON field site of interest. If not specified,
the default will download a data product from all sites. The following are
4-letter site codes for NEON’s 34 aquatics sites as of 2025:</p>
<ul>
<li>ARIK = Arikaree River CO</li>
<li>BARC = Barco Lake FL</li>
<li>BIGC = Upper Big Creek CA</li>
<li>BLDE = Black Deer Creek WY</li>
<li>BLUE = Blue River OK</li>
<li>BLWA = Black Warrior River AL</li>
<li>CARI = Caribou Creek AK</li>
<li>COMO = Como Creek CO</li>
<li>CRAM = Crampton Lake WI</li>
<li>CUPE = Rio Cupeyes PR</li>
<li>FLNT = Flint River GA</li>
<li>GUIL = Rio Yahuecas PR</li>
<li>HOPB = Lower Hop Brook MA</li>
<li>KING = Kings Creek KS</li>
<li>LECO = LeConte Creek TN</li>
<li>LEWI = Lewis Run VA</li>
<li>LIRO = Little Rock Lake WI</li>
<li>MART = Martha Creek WA</li>
<li>MAYF = Mayfield Creek AL</li>
<li>MCDI = McDiffett Creek KS</li>
<li>MCRA = McRae Creek OR</li>
<li>OKSR = Oksrukuyik Creek AK</li>
<li>POSE = Posey Creek VA</li>
<li>PRIN = Pringle Creek TX</li>
<li>PRLA = Prairie Lake ND</li>
<li>PRPO = Prairie Pothole ND</li>
<li>REDB = Red Butte Creek UT</li>
<li>SUGG = Suggs Lake FL</li>
<li>SYCA = Sycamore Creek AZ</li>
<li>TECR = Teakettle Creek CA</li>
<li>TOMB = Lower Tombigbee River AL</li>
<li>TOOK = Toolik Lake AK</li>
<li>WALK = Walker Branch TN</li>
<li>WLOU = West St Louis Creek CO</li>
</ul>
<p>In this exercise, we will pull data from NEON Atlantic Neotropical Domain (D04).
The aquatic sites in D04 are Rio Cupeyes (CUPE) and Rio Yahuecas (GUIL). Just
substitute the 4-letter site code for any other site at the end of the url.</p>
<ul>
<li><a href="https://www.neonscience.org/field-sites/cupe">Learn more about the Rio Cupeyes site (D04-CUPE)</a></li>
<li><a href="https://www.neonscience.org/field-sites/guil">Learn more about the Rio Yahuecas site (D04-GUIL)</a></li>
</ul>
<p>Now let us download our data. We will focus our exercise on data collected from
2021-10-01 through 2024-09-30 (water years 2022, 2023, 2024). If you are not
using a NEON token to download your data, neonUtilities will ignore the <code>token</code>
input. We set <code>check.size = F</code> so that the script runs well but remember you
always want to check your download size first. For this exercise, we will focus
on the following data products:</p>
<p><strong>AIS Data Products:</strong></p>
<ul>
<li>Continuous discharge (<a href="https://data.neonscience.org/data-products/DP4.00130.001">DP4.00130.001</a>)</li>
</ul>
<p><strong>AOS Data Products:</strong></p>
<ul>
<li>Macroinvertebrate collection (<a href="https://data.neonscience.org/data-products/DP1.20120.001">DP1.20120.001</a>)</li>
</ul>
<h2 id="download-aos-data-products">Download AOS Data Products</h2>
<pre><code># download data of interest - AOS - Macroinvertebrate collection

inv &lt;- neonUtilities::loadByProduct(dpID=&quot;DP1.20120.001&quot;,
                                    site=c(&quot;CUPE&quot;,&quot;GUIL&quot;), 
                                    startdate=&quot;2021-10&quot;,
                                    enddate=&quot;2024-09&quot;,
                                    package=&quot;basic&quot;,
                                    release= &quot;current&quot;,
                                    include.provisional = T,
                                    token = Sys.getenv(&quot;NEON_TOKEN&quot;),
                                    check.size = F)
</code></pre>
<h2 id="files-associated-with-downloads">Files Associated with Downloads</h2>
<p>The data we’ve downloaded comes as an object that is a named list of objects.
To work with each of them, select them from the list using the <code>$</code> operator.</p>
<pre><code># view all components of the list

names(inv)

##  [1] &quot;categoricalCodes_20120&quot;      &quot;citation_20120_PROVISIONAL&quot;  &quot;citation_20120_RELEASE-2025&quot; &quot;inv_fieldData&quot;              
##  [5] &quot;inv_persample&quot;               &quot;inv_taxonomyProcessed&quot;       &quot;issueLog_20120&quot;              &quot;readme_20120&quot;               
##  [9] &quot;validation_20120&quot;            &quot;variables_20120&quot;
</code></pre>
<p>We can see that there are 10 objects in the downloaded macroinvertebrate
collection data.</p>
<ul>
<li>Three dataframes of data:
<ul>
<li><code>inv_fieldData</code></li>
<li><code>inv_persample</code></li>
<li><code>inv_taxonomyProcessed</code></li>
</ul>
</li>
<li>Five metadata files:
<ul>
<li><code>categoricalCodes_20120</code></li>
<li><code>issueLog_20120</code></li>
<li><code>readme_20120</code></li>
<li><code>validation_20120</code></li>
<li><code>variables_20120</code></li>
</ul>
</li>
<li>Two data citations:
<ul>
<li><code>citation_20120_PROVISIONAL</code></li>
<li><code>citation_20120_RELEASE-2025</code></li>
</ul>
</li>
</ul>
<p>If you’d like you can use the <code>$</code> operator to assign an object from an item in
the list. If you prefer to extract each table from the list and work with it as
independent objects, which we will do, you can use the <code>list2env()</code> function.</p>
<pre><code># unlist the variables and add to the global environment

list2env(inv,envir = .GlobalEnv)

## &lt;environment: R_GlobalEnv&gt;
</code></pre>
<h3 id="explore-data-citations">Explore: Data Citations</h3>
<p>Citing sources correctly helps the NEON user community maintain transparency,
openness, and trust, while also providing a benefit of being able to track the
impact of NEON on scientific research. Thus, each download of NEON data comes
with proper citations custom to to the download that align with NEON’s
<a href="https://www.neonscience.org/data-samples/guidelines-policies/citing">data citation guidelines</a></p>
<pre><code># view formatted citations for DP1.20120.001 download

cat(citation_20120_PROVISIONAL)

## @misc{DP1.20120.001/provisional,
##   doi = {},
##   url = {https://data.neonscience.org/data-products/DP1.20120.001},
##   author = {{National Ecological Observatory Network (NEON)}},
##   language = {en},
##   title = {Macroinvertebrate collection (DP1.20120.001)},
##   publisher = {National Ecological Observatory Network (NEON)},
##   year = {2025}
## }

cat(`citation_20120_RELEASE-2025`)

## @misc{https://doi.org/10.48443/rmeq-8897,
##   doi = {10.48443/RMEQ-8897},
##   url = {https://data.neonscience.org/data-products/DP1.20120.001/RELEASE-2025},
##   author = {{National Ecological Observatory Network (NEON)}},
##   keywords = {diversity, taxonomy, community composition, species composition, population, aquatic, benthic, macroinvertebrates, invertebrates, abundance, streams, lakes, rivers, wadeable streams, material samples, archived samples, biodiversity},
##   language = {en},
##   title = {Macroinvertebrate collection (DP1.20120.001)},
##   publisher = {National Ecological Observatory Network (NEON)},
##   year = {2025}
## }
</code></pre>
<h3 id="explore-metadata">Explore: Metadata</h3>
<ul>
<li>
<p><strong>categoricalCodes_xxxxx</strong>: Some variables in the data tables are published as
strings and constrained to a standardized list of values (LOV). This file shows
all the LOV options for variables published in this data product.</p>
</li>
<li>
<p><strong>issueLog_xxxxx</strong>: Issues that may impact data quality, or changes to a data
product that affects all sites, are reported in this file.</p>
</li>
<li>
<p><strong>readme_xxxxx</strong>: The readme file provides important information relevant to
the data product and the specific instance of downloading the data.</p>
</li>
<li>
<p><strong>validation_xxxxx</strong>: If any fields require validation prior to publication,
those validation rules are reported in this table</p>
</li>
<li>
<p><strong>variables_xxxxx</strong>: This file contains all the variables found in the
associated data table(s). This includes full definitions, units, and other
important information.</p>
<h1 id="view-the-entire-dataframe-in-your-r-environment">view the entire dataframe in your R environment</h1>
<p>view(variables_20120)</p>
</li>
</ul>
<h3 id="explore-dataframes">Explore: Dataframes</h3>
<p>There will always be one or more dataframes that include the primary data of the
data product you downloaded. Multiple dataframes are available when there are
related datatables for a single data product.</p>
<pre><code># view the entire dataframe in your R environment

view(inv_fieldData)
</code></pre>
<h2 id="download-ais-data-products">Download AIS Data Products</h2>
<pre><code># download data of interest - AIS - Continuous discharge

csd &lt;- neonUtilities::loadByProduct(dpID=&quot;DP4.00130.001&quot;,
                                    site=c(&quot;CUPE&quot;,&quot;GUIL&quot;), 
                                    startdate=&quot;2021-10&quot;,
                                    enddate=&quot;2024-09&quot;,
                                    package=&quot;basic&quot;,
                                    release= &quot;current&quot;,
                                    include.provisional = T,
                                    token = Sys.getenv(&quot;NEON_TOKEN&quot;),
                                    check.size = F)
</code></pre>
<p>Let’s see what files are included with an AIS data product download</p>
<pre><code># view all components of the list

names(csd)

## [1] &quot;categoricalCodes_00130&quot;      &quot;citation_00130_PROVISIONAL&quot;  &quot;citation_00130_RELEASE-2025&quot; &quot;csd_continuousDischarge&quot;    
## [5] &quot;issueLog_00130&quot;              &quot;readme_00130&quot;                &quot;science_review_flags_00130&quot;  &quot;sensor_positions_00130&quot;     
## [9] &quot;variables_00130&quot;
</code></pre>
<p>This AIS data product contains 1 data table available in the basic package:</p>
<ul>
<li><code>csd_continuousDischarge</code>
<ul>
<li>Continuous discharge (streamflow) data at a 1 minute interval. Being a Level
4 data product, this data has been cleaned and gap-filled.</li>
</ul>
</li>
</ul>
<p>Additionally, there are a couple of metadata file types included in AIS data
product downloads that are not included in AOS data product downloads:</p>
<ul>
<li><strong>sensor_postions_xxxxx</strong>: This file contains information about the
coordinates of each sensor, relative to a reference location.</li>
<li><strong>science_review_flags_xxxxx</strong>: This file contains information on quality
flags added to the data following expert review for data that are determined to
be suspect due to known adverse conditions not captured by automated flagging.</li>
</ul>
<p>Let’s unpack the AIS data product to the environment:</p>
<pre><code># unlist the variables and add to the global environment

list2env(csd, .GlobalEnv)

## &lt;environment: R_GlobalEnv&gt;
</code></pre>
<h2 id="wrangling-aos-data">Wrangling AOS Data</h2>
<p>The <code>neonOS</code> R package was developed to aid in wrangling NEON Observational
Subsystem (OS) data products. Two functions used in this exercise are:</p>
<ul>
<li><code>removeDups()</code></li>
<li><code>joinTableNEON()</code></li>
</ul>
<h3 id="removing-duplicates-from-os-data">Removing Duplicates from OS Data</h3>
<p>Duplicates can arise in data, but the <code>neonOS::removeDups()</code> function identifies
duplicates in a data table based on primary key information reported in the
<code>variables_xxxxx</code> files included in each data download.</p>
<p>Let’s check for duplicates in macroinvertebrate collection data</p>
<pre><code># what are the primary keys in inv_fieldData?

message(&quot;Primary keys in inv_fieldData are: &quot;,
        paste(variables_20120$fieldName[
          variables_20120$table==&quot;inv_fieldData&quot;
          &amp;variables_20120$primaryKey==&quot;Y&quot;
        ],
        collapse = &quot;, &quot;)
        )

# identify duplicates in inv_fieldData

inv_fieldData_dups &lt;- neonOS::removeDups(inv_fieldData,
                                         variables_20120)



# what are the primary keys in inv_persample?

message(&quot;Primary keys in inv_persample are: &quot;,
        paste(variables_20120$fieldName[
          variables_20120$table==&quot;inv_persample&quot;
          &amp;variables_20120$primaryKey==&quot;Y&quot;
        ],
        collapse = &quot;, &quot;)
        )

# identify duplicates in inv_persample

inv_persample_dups &lt;- neonOS::removeDups(inv_persample,
                                         variables_20120)



# what are the primary keys in inv_taxonomyProcessed?

message(&quot;Primary keys in inv_taxonomyProcessed are: &quot;,
        paste(variables_20120$fieldName[
          variables_20120$table==&quot;inv_taxonomyProcessed&quot;
          &amp;variables_20120$primaryKey==&quot;Y&quot;
        ],
        collapse = &quot;, &quot;)
        )

# identify duplicates in inv_taxonomyProcessed

inv_taxonomyProcessed_dups &lt;- neonOS::removeDups(inv_taxonomyProcessed,
                                         variables_20120)
</code></pre>
<p>Thankfully, there are no duplicates in any of the AOS tables used in this
exercise!</p>
<h3 id="joining-os-data-tables">Joining OS Data Tables</h3>
<p>Every NEON data product comes with a Quick Start Guide (QSG). The QSGs contain
basic information to help users familiarize themselves with the data products,
including description of the data contents, data quality information, common
calculations or transformations, and, where relevant, algorithm description
and/or table joining instructions.</p>
<p>The QSG for Macroinvertebrate collection can be found on the data product
landing page: <a href="https://data.neonscience.org/data-products/DP1.20120.001">https://data.neonscience.org/data-products/DP1.20120.001</a></p>
<p>The <code>neonOS::joinTableNEON()</code> function uses the table joining information in the
QSG to quickly join two related NEON data tables from the same data product</p>
<pre><code># join inv_fieldData and inv_taxonomyProcessed

inv_fieldTaxJoined &lt;- neonOS::joinTableNEON(inv_fieldData,inv_taxonomyProcessed)
</code></pre>
<p>Now, with field and taxonomy data joined. Individual taxon identifications are
easily linked to field data such as collection latitude/longitude, habitat type,
sampler type, and substratum class.</p>
<h2 id="wrangling-ais-data">Wrangling AIS Data</h2>
<h3 id="data-from-different-sensor-locations-hor">Data from Different Sensor Locations (HOR)</h3>
<p>NEON often collects the same type of data from sensors in different locations.
These data are delivered together but you will frequently want to plot the data
separately or only include data from one sensor in your analysis. NEON uses the
<code>horizontalPosition</code> variable in the data tables to describe which sensor
data is collected from. The <code>horizontalPosition</code> is always a three digit number
for AIS data.</p>
<p>The Continuous discharge data product is derived from a single
<code>horizontalPosition</code>, which corresponds to the sensor co-located with the staff
gauge at the site. This is also the location at which all empirical discharge
measurements are taken.</p>
<p>Let’s see from which <code>horizontalPosition</code> the Continuous discharge data is
published.</p>
<pre><code># use dplyr from the tidyverse collection to get all unique horizontal positions

csd_hor &lt;- csd_continuousDischarge%&gt;%
  dplyr::distinct(siteID,stationHorizontalID)

print(csd_hor)

##   siteID stationHorizontalID
## 1   CUPE                 110
## 2   GUIL                 110
## 3   GUIL                 132

# GUIL has two horizontal positions because the location of the staff gauge

# changed sometime during this time period. At what date did that occur?

max(csd_continuousDischarge$endDate[
  csd_continuousDischarge$siteID==&quot;GUIL&quot;
  &amp;csd_continuousDischarge$stationHorizontalID==&quot;110&quot;
])

## [1] &quot;2022-12-12 23:58:00 GMT&quot;
</code></pre>
<p>At CUPE, the continuous discharge data are published from the 110 position, which
is defined as ‘water level sensors mounted to a staff gauge at stream sites’.</p>
<p>At GUIL, until 2022-12-12, the continuous discharge data were published from the
110 position. On 2022-12-12, the position changed to 132, which is defined as
‘stand-alone water level sensors at downstream (S2) locations at stream sites.’</p>
<h3 id="average-continuous-discharge-to-15-min-interval">Average continuous discharge to 15-min interval</h3>
<p>To make the continuous discharge data easier to work with for this exercise,
let’s use different packages from the <code>tidyverse</code> collection to create a 15-min
averaged table.</p>
<pre><code># 15-min average of continuous discharge data

CSD_15min &lt;- csd_continuousDischarge%&gt;%
  dplyr::mutate(roundDate=lubridate::round_date(endDate,&quot;15 min&quot;))%&gt;%
  dplyr::group_by(siteID,roundDate)%&gt;%
  dplyr::summarise(dischargeMean=mean(continuousDischarge,na.rm=T),
                   dischargeCountQF=sum(dischargeFinalQFSciRvw,na.rm = T))
</code></pre>
<p>Notice that we included a summation of the science review quality flag
(QFSciRvw; binary: 1 = flag, 0 = no flag) fields in the new table.</p>
<h2 id="plot-data">Plot Data</h2>
<p>Now that we have wrangled the data a bit to make it easier to work with, let’s
make some initial plots to see the AOS and AIS data separately before we begin
to investigate questions that involve integrating the data.</p>
<h3 id="aos-macroinvertebrate-abundance-and-richness">AOS Macroinvertebrate abundance and richness</h3>
<p>First, we remove the records collected outside of normal sampling bouts as
a grab sample. In cases where the NEON field ecologists see interesting
organisms that would not be captured using standard field sampling methods,
they can collect a grab sample to be identified by the expert taxonomists.</p>
<p>Next, we calculate macroinvertebrate abundance per square meter and taxon
richness per sampling bout. This allows us to compare macroinvertebrate
data among different samplerTypes and habitatTypes.</p>
<p>We use the <code>vegan</code> R package to calculate richness, evenness, and both the
Shannon and Simpson biodiversity indicies in this exercise. Though we only
focus on richness in the plots, users are encouraged to alter the variables
to view other indices. For a more detailed dive into NEON biodiversity analyses,
see the following NEON tutorial:</p>
<p><a href="https://www.neonscience.org/resources/learning-hub/tutorials/aquatic-diversity-macroinvertebrates">Explore and work with NEON biodiversity data from aquatic ecosystems</a></p>
<p>Sampler types (e.g., surber, hand corer, kicknet) are strongly associated with
habitat (i.e., riffle, run, pool) and substrata. At some NEON sites, like D04
CUPE, the same sampler is used in two habitat types (surber in riffle and run)
because all habitats at the site have the same cobble substrata. Data users
should look at the data to determine how they want to discriminate between
sampler or habitat type.</p>
<p>For this exercise, we split abundance and richness by <code>habitatType</code>. To split
instead by <code>samplerType</code>, simply do a find+replace of
‘habitatType’ -&gt; ‘samplerType’ throughout the code.</p>
<pre><code>### SHOW BREAKDOWN OF SAMPLER TYPE BY HABITAT TYPE AT EACH SITE ###



sampler_habitat_summ &lt;- inv_fieldTaxJoined%&gt;%
  dplyr::distinct(siteID,samplerType,habitatType)

sampler_habitat_summ  

##   siteID samplerType habitatType
## 1   CUPE      surber      riffle
## 2   CUPE      surber         run
## 3   GUIL        hess        pool
## 4   GUIL      surber      riffle
## 5   GUIL        hess         run

### PLOT ABUNDANCE ###



# using the `tidyverse` collection, we can clean the data in one piped function

inv_abundance_summ &lt;- inv_fieldTaxJoined%&gt;%
  # remove events when no samples were collected (samplingImpractical)
  # remove samples not associated with a bout
  dplyr::filter(is.na(samplingImpractical)
                &amp;!grepl(&quot;GRAB|BRYOZOAN&quot;,sampleID))%&gt;%
  
  # calculate abundance (individuals per m2^)
  dplyr::mutate(abun_M2=estimatedTotalCount/benthicArea)%&gt;%
  
  # clean `collectDate` column header
  dplyr::rename(collectDate=collectDate.x)%&gt;%
  
  # first, group including `sampleID` and calculate total abundance per sample
  dplyr::group_by(siteID,collectDate,eventID,sampleID,habitatType,boutNumber)%&gt;%
  dplyr::summarize(abun_M2_sum = sum(abun_M2, na.rm = TRUE))%&gt;%
  
  # second, group excluding `sampleID` to summarize by each bout (`eventID`)
  dplyr::group_by(siteID,collectDate,eventID,habitatType,boutNumber)%&gt;%
  
  # summarize to get mean (+/- se) abundance by bout and sampler type
  dplyr::summarise_each(funs(mean,sd,se=sd(.)/sqrt(n())))%&gt;%
  
  # get categorical variable to sort bouts chronologically
  dplyr::mutate(year=substr(eventID, 6,9),
                yearBout=paste(year,&quot;Bout&quot;,boutNumber, sep = &quot;.&quot;))



# produce stacked plot to show trends within and across sites

inv_abundance_summ%&gt;%
  ggplot2::ggplot(aes(fill=habitatType, color=habitatType, y=abun_M2_sum_mean, x=yearBout))+
  ggplot2::geom_point(position=position_dodge(0.5), size=2)+
  ggplot2::geom_errorbar(aes(ymin=abun_M2_sum_mean-abun_M2_sum_se, 
                             ymax=abun_M2_sum_mean+abun_M2_sum_se), 
                         width=0.4, alpha=3.0, linewidth=1,
                         position = position_dodge(0.5))+
  ggplot2::facet_wrap(~siteID,ncol = 1,scales=&quot;free_y&quot;)+
  ggplot2::theme(axis.text.x = element_text(size = 10, angle = 30, 
                                            hjust = 1, vjust = 1))+
  ggplot2::labs(title = &quot;Mean macroinvertebrates per square meter&quot;,
                y = &quot;Abundance Per Square Meter&quot;,
                x = &quot;Bout&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/aos-plot-1.png" alt=" " /></p>
<pre><code>### PLOT RICHNESS ###



inv_richness_clean &lt;- inv_fieldTaxJoined%&gt;%
  # remove events when no samples were collected (samplingImpractical)
  # remove samples not associated with a bout
  dplyr::filter(is.na(samplingImpractical)
                &amp;!grepl(&quot;GRAB|BRYOZOAN&quot;,sampleID))%&gt;%
  # clean `collectDate` column header
  dplyr::rename(collectDate=collectDate.x)



# extract sample metadata

inv_sample_info &lt;- inv_richness_clean%&gt;%
  dplyr::select(sampleID, domainID, siteID, namedLocation, 
                collectDate, eventID, boutNumber, 
                habitatType, samplerType, benthicArea)%&gt;%
  dplyr::distinct()



# filter out rare taxa: only observed 1 (singleton) or 2 (doubleton) times

inv_rare_taxa &lt;- inv_richness_clean%&gt;%
  dplyr::distinct(sampleID, acceptedTaxonID, scientificName)%&gt;%
  dplyr::group_by(scientificName)%&gt;%
  dplyr::summarize(occurrences = n())%&gt;%
  dplyr::filter(occurrences &gt; 2)



# filter richness table based on taxon list excluding singletons and doubletons

inv_richness_clean &lt;- inv_richness_clean %&gt;%
  dplyr::filter(scientificName%in%inv_rare_taxa$scientificName) 



# create a matrix of taxa by sampleID

inv_richness_clean_wide &lt;- inv_richness_clean %&gt;%
  # subset to unique combinations of `sampleID` and `scientificName`
  dplyr::distinct(sampleID,scientificName,.keep_all = T)%&gt;%
  
  # remove any records with no abundance data
  dplyr::mutate(abun_M2=estimatedTotalCount/benthicArea)%&gt;%
  filter(!is.na(abun_M2))%&gt;%
  
  # pivot to wide format, sum multiple counts per sampleID
  tidyr::pivot_wider(id_cols = sampleID, 
                     names_from = scientificName,
                     values_from = abun_M2,
                     values_fill = list(abun_M2 = 0),
                     values_fn = list(abun_M2 = sum)) %&gt;%
  tibble::column_to_rownames(var = &quot;sampleID&quot;) %&gt;%
  
  #round to integer so that vegan functions will run
  round()



# code check - check col and row sums

# mins should all be &gt; 0 for further analysis in vegan

if(colSums(inv_richness_clean_wide) %&gt;% min()==0){
  stop(&quot;Column sum is 0: do not proceed with richness analysis!&quot;)
}

if(rowSums(inv_richness_clean_wide) %&gt;% min()==0){
  stop(&quot;Row sum is 0: do not proceed with richness analysis!&quot;)
}



# use the `vegan` package to calculate diversity indices



# calculate richness

inv_richness &lt;- as.data.frame(
  vegan::specnumber(inv_richness_clean_wide)
  )

names(inv_richness) &lt;- &quot;richness&quot;



inv_richness_stats &lt;- vegan::estimateR(inv_richness_clean_wide)



# calculate evenness

inv_evenness &lt;- as.data.frame(
  vegan::diversity(inv_richness_clean_wide)/
    log(vegan::specnumber(inv_richness_clean_wide))
  )

names(inv_evenness) &lt;- &quot;evenness&quot;



# calculate shannon index

inv_shannon &lt;- as.data.frame(
  vegan::diversity(inv_richness_clean_wide, index = &quot;shannon&quot;)
  )

names(inv_shannon) &lt;- &quot;shannon&quot;



# calculate simpson index

inv_simpson &lt;- as.data.frame(
  vegan::diversity(inv_richness_clean_wide, index = &quot;simpson&quot;)
  )

names(inv_simpson) &lt;- &quot;simpson&quot;



# create a single data frame

inv_diversity_indices &lt;- cbind(inv_richness, inv_evenness, inv_shannon, inv_simpson)



# bring in the metadata table created earlier

inv_diversity_indices &lt;- dplyr::left_join(
  tibble::rownames_to_column(inv_diversity_indices),
  inv_sample_info,
  by = c(&quot;rowname&quot; = &quot;sampleID&quot;)) %&gt;%
  dplyr::rename(sampleID = rowname)



# create summary table for plotting

inv_diversity_summ &lt;- inv_diversity_indices%&gt;%
  tidyr::pivot_longer(c(richness,evenness,shannon,simpson),
                      names_to = &quot;indexName&quot;,
                      values_to = &quot;indexValue&quot;)%&gt;%
  group_by(siteID,collectDate,eventID,habitatType,boutNumber,indexName)%&gt;%
  dplyr::summarize(mean = mean(indexValue),
                   n=n(),
                   sd = sd(indexValue),
                   se=sd/sqrt(n))%&gt;%
  dplyr::mutate(year=substr(eventID, 6,9),
                yearBout=paste(year,&quot;Bout&quot;,boutNumber, sep = &quot;.&quot;))



# produce plot to show trends within and across sites

inv_diversity_summ%&gt;%
  dplyr::filter(indexName==&quot;richness&quot;)%&gt;%
  ggplot2::ggplot(aes(fill=habitatType, color=habitatType, y=mean, x=yearBout))+
  ggplot2::geom_point(position=position_dodge(0.5), size=2)+
  ggplot2::geom_errorbar(aes(ymin=mean-se, ymax=mean+se), 
                         width=0.4, alpha=3.0, linewidth=1,
                         position = position_dodge(0.5))+
  ggplot2::facet_wrap(~siteID,ncol=1)+
  ggplot2::theme(axis.text.x = element_text(size = 10, angle = 30, 
                                            hjust = 1, vjust = 1))+
  labs(title=&quot;Mean number of macroinvertebrate taxa per bout&quot;,
       y= &quot;Taxon Richness&quot;, x = &quot;Bout&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/aos-plot-2.png" alt=" " /></p>
<h3 id="ais-continuous-discharge-timseries">AIS Continuous discharge timseries</h3>
<p>Now, let’s visualize the cleaned and gap-filled continuous discharge timeseries
for the two NEON D04 sites.</p>
<pre><code>CSD_15min%&gt;%
  ggplot2::ggplot(aes(x=roundDate,y=dischargeMean))+
  ggplot2::geom_line()+
  ggplot2::facet_wrap(~siteID,ncol = 1)+
  # ggplot2::scale_y_log10()+ # Include to show discharge axis in log scale
  labs(title=&quot;Continuous Discharge for Water Years 2022-2024&quot;,
       y= &quot;Discharge (L/s)&quot;, x = &quot;Date&quot;)
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/csd-plot-1.png" alt=" " /></p>
<h2 id="visualize-aos-and-ais-data-together">Visualize AOS and AIS Data Together</h2>
<p>Next, we will use the R package <code>plotly</code> to make fun interactive plots allowing
us to view AOS and AIS data in the same plotting field. There is a
lot of code here to correctly format the plot in a way to provide as much info
and be as interactive as possible in a single plotting field.</p>
<p>The <code>plotly</code> package allows us to interact with the plots in the following ways:</p>
<ul>
<li>Zoom and pan along the x- and y-axes</li>
<li>Switch discharge timeseries between linear and log scale</li>
<li>Turn on/off traces in the plot by clicking the legend entries</li>
<li>Scroll long each individual y-axis</li>
</ul>
<h3 id="inv-abundance-and-richness-discharge-over-time">INV Abundance and Richness + Discharge Over Time</h3>
<p>Click on traces to display or hide them. (Note: INV traces defaulted to hidden)</p>
<pre><code># choose the site(s) you want to plot

siteToPlot &lt;- c(&quot;CUPE&quot;,&quot;GUIL&quot;)



for(s in 1:length(siteToPlot)){
  # begin the plot code
  AOS_AIS_plot &lt;- CSD_15min%&gt;%
    dplyr::filter(siteID==siteToPlot[s])%&gt;%
    plotly::plot_ly()%&gt;%
    # add trace for continuous discharge
    plotly::add_trace(x=~roundDate,y=~dischargeMean,
                      type=&quot;scatter&quot;,mode=&quot;line&quot;,
                      line=list(color = 'darkgray'),
                      name=&quot;Discharge&quot;)%&gt;%
    # add trace for INV abundance
    plotly::add_trace(data=inv_abundance_summ%&gt;%
                        dplyr::filter(siteID==siteToPlot[s]),
                      x=~collectDate,y=~abun_M2_sum_mean,
                      split=~paste0(&quot;INV Abundance: &quot;,habitatType),
                      yaxis=&quot;y2&quot;,type=&quot;scatter&quot;,mode=&quot;line&quot;,
                      error_y=~list(array=abun_M2_sum_se,
                                    color='darkorange'),
                      marker=list(color=&quot;darkorange&quot;),
                      line=list(color=&quot;darkorange&quot;),
                      visible=&quot;legendonly&quot;)%&gt;%
    # add trace for INV richness
    plotly::add_trace(data=inv_diversity_summ%&gt;%
                        dplyr::filter(siteID==siteToPlot[s]
                                      &amp;indexName==&quot;richness&quot;),
                      x=~collectDate,y=~mean,
                      split=~paste0(&quot;INV Richness: &quot;,habitatType),
                      yaxis=&quot;y3&quot;,type=&quot;scatter&quot;,mode=&quot;line&quot;,
                      error_y=~list(array=se,
                                    color='darkgreen'),
                      marker=list(color=&quot;darkgreen&quot;),
                      line=list(color=&quot;darkgreen&quot;),
                      visible=&quot;legendonly&quot;)%&gt;%
    # define the layout of the plot
    plotly::layout(
      title = paste0(siteToPlot[s],
                     &quot; Discharge w/ Macroinvertebrate Abundance &amp; Richness&quot;),
      # format x-axis
      xaxis=list(title=&quot;dateTime&quot;,
                 automargin=TRUE,
                 domain=c(0,0.9)),
      # format first y-axis
      yaxis=list(
        side='left',
        title='Discharge (L/s)',
        showgrid=FALSE,
        zeroline=FALSE,
        automargin=TRUE),
      # format second y-axis
      yaxis2=list(
        side='right',
        overlaying=&quot;y&quot;,
        title='INV Abundance',
        showgrid=FALSE,
        automargin=TRUE,
        zeroline=FALSE,
        tickfont=list(color = 'darkorange'),
        titlefont=list(color = 'darkorange')),
      # format third y-axis
      yaxis3=list(
        side='right',
        overlaying=&quot;y&quot;,
        anchor=&quot;free&quot;,
        title='INV Richness',
        showgrid=FALSE,
        zeroline=FALSE,
        automargin=TRUE,
        tickfont=list(color = 'darkgreen'),
        titlefont=list(color = 'darkgreen'),
        position=0.99),
      # format legend
      legend=list(xanchor = 'center',
                  yanchor = 'top',
                  orientation = 'h',
                  x=0.5,y=-0.2),
      # add button to switch discharge between linear and log
      updatemenus=list(
        list(
          type='buttons',
          buttons=list(
            list(label='linear',
              method='relayout',
              args=list(list(yaxis=list(type='linear')))),
            list(label='log',
              method='relayout',
              args=list(list(yaxis=list(type='log'))))))))
  
  assign(paste0(&quot;AOS_AIS_plot_&quot;,siteToPlot[s]),AOS_AIS_plot)
}



# show plot at CUPE

AOS_AIS_plot_CUPE
</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/aos-ais-plot-1.png" alt=" " width="100%" height="600px" />
<p class="caption"> </p>
</div>
<pre><code># show plot at GUIL

AOS_AIS_plot_GUIL
</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/aos-ais-plot-2.png" alt=" " width="100%" height="600px" />
<p class="caption"> </p>
</div>
<div class="figure" style="text-align: center">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/ais-aos/guil-discharge-macroinv-abundance-richness.html" alt=" "  />
<p class="GUIL Discharge Macroinvertebrate Abundance Interactive Plot"> </p>
</div>
<p>What kind of observations can be made when examining AIS discharge and AOS
macroinvertebrate data on the same plotting field at NEON’s two neotropical
aquatic sites?</p>
<p>The standardized spatiotemporal design of NEON’s aquatic data products allows
one to easily run the same analysis for any NEON site. Given that all of NEON’s
24 stream sites publish both AIS continuous discharge and AOS macroinvertebrate
collection data products, users can substitute any two NEON stream site IDs into
this exercise to assess the relationship between stream discharge and
macroinvertebrate abundance and richness.</p>
<p>Visit the <a href="https://www.neonscience.org/field-sites/explore-field-sites">Explore NEON Field Sites</a>
webpage to learn more about the different NEON aquatic sites. To run this
exercise on a different combination of two sites, use find+replace to change the
site IDs throughout the code.</p>
<h2 id="further-exploration">Further Exploration</h2>
<p>Now, we can take what we have learned about NEON AOS and AIS data and look at
other case studies using different NEON data products.</p>
<h3 id="case-study-1-examine-relationships-between-discharge-sediment-particle-size-distribution-and-macroinvertebrate-abundance-diversity-at-2-sites-impacted-by-hurricanes">Case Study 1: Examine relationships between discharge, sediment particle size distribution, and macroinvertebrate abundance/diversity at 2 sites impacted by hurricanes.</h3>
<p>In September 2022, Hurricane Fiona struck land in Puerto Rico as a Category 1
hurricane. Two NEON D04 aquatic sites were impacted. Here, we scale three data
products across time to get an integrated look at how Hurricane Fiona (red line)
affected the hydrology, morphology, and biology of two streams.</p>
<div class="figure" style="text-align: center">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/graphics/ais-aos/fionaNEON.png" alt=" "  />
<p class="Hurricane Fiona Impact Map"> </p>
</div>
<p>Total rainfall accumulation in Puerto Rico from Hurricane Fiona, overlaid with
approximate locations of the two NEON D04 aquatic sites: CUPE, GUIL.
Image source: <a href="https://www.nhc.noaa.gov/data/tcr/AL072022_Fiona.pdf">https://www.nhc.noaa.gov/data/tcr/AL072022_Fiona.pdf</a></p>
<p>For this case study, we will look again at the relationship between stream
discharge and macroinvertebrate abundance and richness with the hurricane event
highlighted. We will compare the effects of the hurricane on stream hydrology
and biology between the two sites.</p>
<p>We will also bring in a third NEON aquatic data product:</p>
<ul>
<li>Stream morphology maps (<a href="https://data.neonscience.org/data-products/DP4.00131.001">DP4.00131.001</a>)</li>
</ul>
<p>From the Stream morphology maps data product, we will examine the effect of
Hurricane Fiona on streambed particle size distribution, expanding our
exploration of NEON aquatic data to uncover linkages between the hydrology,
morphology, and biology of NEON streams.</p>
<p>According to NOAA, Hurricane Fiona traveled through Puerto Rico between 18-21
September, 2022. Let’s highlight that event in our combined AOS and AIS plots by
adding a red vertical dashed line on 2022-09-19.</p>
<pre><code># identify the date of Fiona

fionaDate &lt;- &quot;2022-09-19&quot;



# highlight Fiona at CUPE

AOS_AIS_plot_CUPE_Fiona &lt;- AOS_AIS_plot_CUPE%&gt;%
  # add dashed vertical line to plot created in previous exercise
  plotly::add_segments(x=as.POSIXct(fionaDate,tz=&quot;UTC&quot;),
                       xend=as.POSIXct(fionaDate,tz=&quot;UTC&quot;),
                       y=0,
                       yend=max(CSD_15min$dischargeMean[
                         CSD_15min$siteID==&quot;CUPE&quot;],
                         na.rm = T),
                       name=&quot;Fiona&quot;,
                       line=list(color='red',dash='dash'))



# highlight Fiona at GUIL

AOS_AIS_plot_GUIL_Fiona &lt;- AOS_AIS_plot_GUIL%&gt;%
  # add dashed vertical line to plot created in previous exercise
  plotly::add_segments(x=as.POSIXct(fionaDate,tz=&quot;UTC&quot;),
                       xend=as.POSIXct(fionaDate,tz=&quot;UTC&quot;),
                       y=0,
                       yend=max(CSD_15min$dischargeMean[
                         CSD_15min$siteID==&quot;CUPE&quot;],
                         na.rm = T),
                       name=&quot;Fiona&quot;,
                       line=list(color='red',dash='dash'))
</code></pre>
<p>Next, we will use the <code>neonUtilities</code> function <code>loadByProduct()</code> to load data
from the Stream morphology maps data product into R.</p>
<pre><code># download data of interest - AOS - Stream morphology maps

# the expanded download package is needed to read in the geo_pebbleCount table

geo &lt;- neonUtilities::loadByProduct(dpID=&quot;DP4.00131.001&quot;,
                                    site=c(&quot;CUPE&quot;,&quot;GUIL&quot;), 
                                    startdate=&quot;2021-10&quot;,
                                    enddate=&quot;2024-09&quot;,
                                    package=&quot;expanded&quot;,
                                    release= &quot;current&quot;,
                                    include.provisional = T,
                                    token = Sys.getenv(&quot;NEON_TOKEN&quot;),
                                    check.size = F)



# unlist the variables and add to the global environment

list2env(geo,envir = .GlobalEnv)
</code></pre>
<p>There are many data tables included in this Level 4 AOS download package,
but we are only interested in using one table for this exercise:</p>
<ul>
<li><code>geo_pebbleCount</code>
<ul>
<li>Sediment particle size data collected during pebble count sampling. Pebble
count surveys are conducted once per year, typically during periods of
baseflow at a given site.</li>
</ul>
</li>
</ul>
<p>Check for duplicates in geo_pebbleCount using <code>neonOS::removeDups()</code>.</p>
<pre><code># what are the primary keys in geo_pebbleCount?

message(&quot;Primary keys in geo_pebbleCount are: &quot;,
        paste(variables_00131$fieldName[
          variables_00131$table==&quot;geo_pebbleCount&quot;
          &amp;variables_00131$primaryKey==&quot;Y&quot;
        ],
        collapse = &quot;, &quot;)
        )

# identify duplicates in geo_pebbleCount

geo_pebbleCount_dups &lt;- neonOS::removeDups(geo_pebbleCount,
                                           variables_00131)
</code></pre>
<p>There are no duplicates! Let’s proceed.</p>
<p>Next, let’s wrangle the data and plot cumulative frequency curves to visualize
particle size distributions for NEON D04 aquatic sites across water years 2022,
2023, and 2024.</p>
<pre><code># we want to plot the frequency of `pebbleSize`

# `pebbleSize` is published as a categorical variable (range of size - mm)

# For plotting purposes, convert `pebbleSize` to numeric (lower number in range)

geo_pebbleCount$pebbleSize_num &lt;- NA

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;&lt; 2 mm: silt/clay&quot;
  ] &lt;- 0

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;&lt; 2 mm: sand&quot;
  ] &lt;- 0

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;2 - 2.8 mm: very coarse sand&quot;
  ] &lt;- 2

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;2.8 - 4 mm: very fine gravel&quot;
  ] &lt;-2.8

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;4 - 5.6 mm: fine gravel&quot;
  ] &lt;- 4

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;5.6 - 8 mm: fine gravel&quot;
  ] &lt;- 5.6

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;8 - 11 mm: medium gravel&quot;
  ] &lt;- 8

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;11 - 16 mm: medium gravel&quot;
  ] &lt;- 11

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;16 - 22.6 mm: coarse gravel&quot;
  ] &lt;- 16

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;22.6 - 32 mm: coarse gravel&quot;
  ] &lt;- 22.6

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;32 - 45 mm: very coarse gravel&quot;
  ] &lt;- 32

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;45 - 64 mm: very coarse gravel&quot;
  ] &lt;- 45

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;64 - 90 mm: small cobble&quot;
  ] &lt;- 64

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;90 - 128 mm: medium cobble&quot;
  ] &lt;- 90

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;128 - 180 mm: large cobble&quot;
  ] &lt;- 128

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;180 - 256 mm: large cobble&quot;
  ] &lt;- 180

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;&gt; 256 mm: boulder&quot;
  ] &lt;- 256

geo_pebbleCount$pebbleSize_num[
  geo_pebbleCount$pebbleSize==&quot;&gt; 256 mm: bedrock&quot;
  ] &lt;- 256



# each 'siteID' and 'surveyEndDate' represents a unique pebble count survey



# group by 'siteID' and 'surveyEndDate'` and calculate frequency

geo_pebbleCount_freq &lt;- geo_pebbleCount%&gt;%
  dplyr::group_by(siteID,surveyEndDate,eventID,pebbleSize_num)%&gt;%
  dplyr::summarise(frequency=n()/200)



# calculate a cumulative sum of frequency per event ID

for(e in 1:length(unique(geo_pebbleCount_freq$eventID))){
  eventID_freq &lt;- geo_pebbleCount_freq%&gt;%
    filter(eventID==unique(geo_pebbleCount$eventID)[e])
  eventID_freq$CumulativeFreq &lt;- cumsum(eventID_freq$frequency)*100
  if(e==1){
    geo_pebbleCount_freqCumm &lt;- eventID_freq
  }else{
    geo_pebbleCount_freqCumm &lt;- rbind(geo_pebbleCount_freqCumm,eventID_freq)
  }
}



# assign a year to each survey

geo_pebbleCount_freqCumm &lt;- geo_pebbleCount_freqCumm%&gt;%
  dplyr::mutate(year=format(surveyEndDate,&quot;%Y&quot;))



# create cumulative frequency curve plot using `geom_smooth`

geo_pebbleCount_freqCumm%&gt;%
  ggplot2::ggplot(aes(x = pebbleSize_num, y = CumulativeFreq, color = year)) +
  ggplot2::geom_smooth(method = &quot;loess&quot;, se = T, linewidth = 0.75) +
  ggplot2::labs(title=&quot;Cumulative Particle Size Distribution by Year&quot;,
       x = &quot;Particle Size (mm)&quot;, y = &quot;Cumulative Frequency (%)&quot;) +
  ggplot2::facet_wrap(~siteID)
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/wrangle-plot-geo-1.png" alt=" " /></p>
<p>To effectively view the particle size distribution data with the other two data
products, we will embed them as <code>ggplot</code> subplots in the larger <code>plotly</code> plot.</p>
<pre><code># generate small, simple subplots of each pebble count survey

# loop through each site and year to make plot and save to the working directory

# for(s in 1:length(unique(geo_pebbleCount_freqCumm$siteID))){

#   currSite &lt;- unique(geo_pebbleCount_freqCumm$siteID)[s]

#   for(y in 1:length(unique(geo_pebbleCount_freqCumm$year))){

#     currYear &lt;- unique(geo_pebbleCount_freqCumm$year)[y]

#     currPlot &lt;- geo_pebbleCount_freqCumm%&gt;%

#       dplyr::filter(siteID==currSite

#                     &amp;year==currYear)%&gt;%

#       ggplot2::ggplot(aes(x = pebbleSize_num, y = CumulativeFreq)) +

#       ggplot2::geom_smooth(method = &quot;loess&quot;, se = T, linewidth = 0.75) +

#       ggplot2::labs(x = NULL, y = NULL)+

#       ggplot2::scale_y_continuous(limits=c(0,105))+

#       ggplot2::scale_x_continuous(limits=c(0,260))+

#       ggplot2::theme_classic()+

#       ggplot2::theme(text=element_text(size=18))

#     ggplot2::ggsave(plot=currPlot,

#                     filename=paste0(&quot;images/psd_&quot;,currSite,currYear,&quot;.png&quot;),

#                     width = 4, height = 7, units = &quot;cm&quot;)

#   }

# }



# re-generate the CUPE plot with particle size distribution subplots added

AOS_AIS_plot_CUPE_Fiona%&gt;%
  layout(images=list(
    # show the CUPE 2022 pebble count survey, conducted 2022-04
    list(source=base64enc::dataURI(file=&quot;images/psd_CUPE2022.png&quot;),
         x = 0.05, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;),
    # show the CUPE 2023 pebble count survey, conducted 2022-05
    list(source=base64enc::dataURI(file=&quot;images/psd_CUPE2023.png&quot;),
         x = 0.4, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;),
    # show the CUPE 2024 pebble count survey, conducted 2022-05
    list(source=base64enc::dataURI(file=&quot;images/psd_CUPE2024.png&quot;),
         x = 0.7, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;)
    
    ))
</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/highlight-fiona-psd-1.png" alt=" " width="100%" height="800px" />
<p class="caption"> </p>
</div>
<pre><code># re-generate the GUIL plot with particle size distribution subplots added

AOS_AIS_plot_GUIL_Fiona%&gt;%
  layout(images=list(
    # show the GUIL 2022 pebble count survey, conducted 2022-04
      list(source=base64enc::dataURI(file=&quot;images/psd_GUIL2022.png&quot;),
         x = 0.05, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;),
    # show the GUIL 2023 pebble count survey, conducted 2023-03
    list(source=base64enc::dataURI(file=&quot;images/psd_GUIL2023.png&quot;),
         x = 0.35, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;),
    # show the GUIL 2024 pebble count survey, conducted 2024-07
    list(source=base64enc::dataURI(file=&quot;images/psd_GUIL2024.png&quot;),
         x = 0.75, y = 0.7, 
         sizex = 0.25, sizey = 0.25,
         xref = &quot;paper&quot;, yref = &quot;paper&quot;, 
         xanchor = &quot;left&quot;, yanchor = &quot;bottom&quot;)
    
    ))
</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/highlight-fiona-psd-2.png" alt=" " width="100%" height="800px" />
<p class="caption"> </p>
</div>
<p><strong>Discussion</strong>: With the three data products viewed together in relation to the
Hurricane Fiona event, there are several observations that can be made:</p>
<ul>
<li>
<p>Hydrology</p>
<ul>
<li>Both sites were hit with heavy rain, with CUPE discharge reaching nearly
20,000 L/s at its peak.</li>
<li>Sensor infrastructure at GUIL was temporarily compromised during the storm,
resulting in a data gap.</li>
</ul>
</li>
<li>
<p>Morphology</p>
<ul>
<li>The sediment particle size distribution data suggests that CUPE sediment
remained relatively stable pre- and post-storm, while GUIL showed heavier loss
of small sediment via scouring.</li>
</ul>
</li>
<li>
<p>Biology</p>
<ul>
<li>While both sites show a large decrease in macroinvertebrate abundance
post-storm, GUIL shows a more negative effect to macroinvertebrate diversity
relative to CUPE.</li>
<li>Both sites show a trend back to pre-storm abundance and diversity numbers by
the following spring bout.</li>
</ul>
</li>
</ul>
<p>By integrating data products across time, we observe disparate effects of
Hurricane Fiona on NEON D04 sites, with a potential relationship being revealed
between the stability of the streambed substrate and the loss of
macroinvertebrate diversity immediately following a major precipitation event.</p>
<h3 id="case-study-2-can-relationships-between-sensor-measurements-and-discrete-water-chemistry-data-be-used-to-expand-the-temporal-extent-of-ecologically-relevant-analytes">Case Study 2: Can relationships between sensor measurements and discrete water chemistry data be used to expand the temporal extent of ecologically-relevant analytes?</h3>
<p>We are going to switch gears to a different kind of integration between AOS and
AIS data. We evaluate the relationship between high-frequency fluorescent
dissolved organic matter (fDOM) AIS data and dissolved organic carbon (DOC) data
analyzed from AOS water chemistry grab samples to model a continuous DOC
timeseries at D04 CUPE.</p>
<p>The data products downloaded here are:</p>
<p><strong>AIS Data Products:</strong></p>
<ul>
<li>Water quality (<a href="https://data.neonscience.org/data-products/DP1.20288.001">DP1.20288.001</a>)</li>
</ul>
<p><strong>AOS Data Products:</strong></p>
<ul>
<li>Chemical properties of surface water (<a href="https://data.neonscience.org/data-products/DP1.20093.001">DP1.20093.001</a>)</li>
</ul>
<p>First, download AOS data, run the duplicate check, and plot the data. We will
stick with the 2021-10-01 to 2024-09-30 time range.</p>
<pre><code># download data of interest - AOS - Chemical properties of surface water

swc &lt;- neonUtilities::loadByProduct(dpID=&quot;DP1.20093.001&quot;,
                                    site=c(&quot;CUPE&quot;), 
                                    startdate=&quot;2021-10&quot;,
                                    enddate=&quot;2024-09&quot;,
                                    package=&quot;basic&quot;,
                                    release= &quot;current&quot;,
                                    include.provisional = T,
                                    token = Sys.getenv(&quot;NEON_TOKEN&quot;),
                                    check.size = F)



# unlist the variables and add to the global environment

list2env(swc,envir = .GlobalEnv)
</code></pre>
<p>The data table we are interested in here is <code>swc_externalLabDataByAnalyte</code>:
“Long-format results of chemical analysis of up to 28 unique analytes from
surface water and groundwater grab samples.”</p>
<pre><code># check if there are duplicate DOC records

# what are the primary keys in swc_externalLabDataByAnalyte?



message(&quot;Primary keys in swc_externalLabDataByAnalyte are: &quot;,
        paste(variables_20093$fieldName[
          variables_20093$table==&quot;swc_externalLabDataByAnalyte&quot;
          &amp;variables_20093$primaryKey==&quot;Y&quot;
        ],
        collapse = &quot;, &quot;)
        )



# identify duplicates in swc_externalLabDataByAnalyte

swc_externalLabDataByAnalyte_dups &lt;- neonOS::removeDups(
  swc_externalLabDataByAnalyte,
  variables_20093)



# no duplicates, great!



# lab data is published `long-format` with 28 analytes analyzed

# show all the analytes published in the lab data

print(unique(swc_externalLabDataByAnalyte$analyte))

##  [1] &quot;TDP&quot;                    &quot;SO4&quot;                    &quot;TP&quot;                     &quot;NH4 - N&quot;                &quot;Mg&quot;                    
##  [6] &quot;NO2 - N&quot;                &quot;F&quot;                      &quot;Si&quot;                     &quot;TDS&quot;                    &quot;UV Absorbance (254 nm)&quot;
## [11] &quot;Cl&quot;                     &quot;Ca&quot;                     &quot;TN&quot;                     &quot;UV Absorbance (280 nm)&quot; &quot;NO3+NO2 - N&quot;           
## [16] &quot;TSS&quot;                    &quot;TPC&quot;                    &quot;TDN&quot;                    &quot;Na&quot;                     &quot;Br&quot;                    
## [21] &quot;Mn&quot;                     &quot;Fe&quot;                     &quot;DOC&quot;                    &quot;DIC&quot;                    &quot;K&quot;                     
## [26] &quot;Ortho - P&quot;              &quot;TOC&quot;                    &quot;TPN&quot;

# for this exercise, subset lab data to only dissolved organic carbon (DOC)

DOC &lt;- swc_externalLabDataByAnalyte%&gt;%
  dplyr::filter(analyte==&quot;DOC&quot;)



# plot a timeseries of DOC

DOC_plot &lt;- DOC%&gt;%
  ggplot2::ggplot(aes(x=collectDate,y=analyteConcentration))+
  ggplot2::geom_point()+
  ggplot2::labs(title = &quot;Dissolved organic carbon (DOC) over time&quot;,
                y = &quot;DOC (mg/L)&quot;,
                x = &quot;Date&quot;)



DOC_plot
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/wrangle-plot-swc-1.png" alt=" " /></p>
<p>Next, download AIS data, subset to the appropriate <code>horizontalPosition</code>, wrangle
the data for analysis, and plot the data.</p>
<pre><code># download data of interest - AIS - Water quality

waq &lt;- neonUtilities::loadByProduct(dpID=&quot;DP1.20288.001&quot;,
                                    site=c(&quot;CUPE&quot;), 
                                    startdate=&quot;2021-10&quot;,
                                    enddate=&quot;2024-09&quot;,
                                    package=&quot;basic&quot;,
                                    release= &quot;current&quot;,
                                    include.provisional = T,
                                    token = Sys.getenv(&quot;NEON_TOKEN&quot;),
                                    check.size = F)



# unlist the variables and add to the global environment

list2env(waq,envir = .GlobalEnv)
</code></pre>
<p>The data table we are interested in here is <code>waq_instantaneous</code>: “Wide-format table
published many water quality metrics in wide-format, including fDOM, dissolved oxygen,
specific conductance, pH, chlorophyll, and turbidity.”</p>
<pre><code># `waq_instantaneous` table published many water quality metrics in wide-format

# other than fDOM, many other metrics are published in `waq_instantaneous`

# including: dissolved oxygen, specific conductance, pH, chlorophyll, turbidity



# according to the NEON AIS spatial design, fDOM is only measured at the 

# downstream sensor set (S2, HOR = 102); subset to HOR 102

WAQ_102 &lt;- waq_instantaneous%&gt;%
  dplyr::filter(horizontalPosition==102)



# `waq_instantaneous` is published at a 1 minute temporal resolution

# for ease of plotting, let's create a 15-minute average table

fDOM_15min &lt;- WAQ_102%&gt;%
  
  # remove NULL records
  dplyr::filter(!is.na(rawCalibratedfDOM))%&gt;%
  
  # remove records with a final QF
  dplyr::filter(fDOMFinalQF==0)%&gt;%
  
  # create 15-minute average of fDOM
  mutate(roundDate=lubridate::round_date(endDateTime,&quot;15 min&quot;))%&gt;%
  group_by(siteID,roundDate)%&gt;%
  summarize(mean_fDOM=mean(rawCalibratedfDOM))



# plot a timeseries of fDOM

fDOM_plot &lt;- fDOM_15min%&gt;%
  ggplot2::ggplot(aes(x=roundDate,y=mean_fDOM))+
  ggplot2::geom_line()+
  ggplot2::labs(title = &quot;fluorescent dissolved organic matter (fDOM) over time&quot;,
                y = &quot;fDOM (QSU)&quot;,
                x = &quot;Date&quot;)



fDOM_plot
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/wrangle-plot-waq-1.png" alt=" " /></p>
<p>Both data products are published in Coordinated Universal Time (UTC), as are all
AOS and AIS data, which makes joining across tables easy. Let’s join the AOS and
AIS data into a single data frame from which we will model the two variables.</p>
<pre><code># round DOC `collectDate` to the nearest 15 minute timestamp

DOC$roundDate &lt;- lubridate::round_date(DOC$collectDate,&quot;15 min&quot;)



# perform a left-join, which will join an AIS DOC record to every AIS fDOM 

# record based on matching timestamps

fDOM_DOC_join &lt;- dplyr::left_join(fDOM_15min,DOC,by=&quot;roundDate&quot;)
</code></pre>
<p>Create a linear regression to analyze the correlation of the two variables</p>
<pre><code># use `lm` function to create a linear regression: DOC~fDOM

model &lt;- lm(analyteConcentration~mean_fDOM,data=fDOM_DOC_join)



# view a summary of the regression model

print(summary(model))

## 
## Call:
## lm(formula = analyteConcentration ~ mean_fDOM, data = fDOM_DOC_join)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.0706 -0.1706 -0.0468  0.1403  0.9160 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.459889   0.078252   5.877 1.64e-07 ***
## mean_fDOM   0.045863   0.004593   9.986 1.12e-14 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3208 on 64 degrees of freedom
##   (81058 observations deleted due to missingness)
## Multiple R-squared:  0.6091,	Adjusted R-squared:  0.603 
## F-statistic: 99.71 on 1 and 64 DF,  p-value: 1.117e-14

# show a plot of the relationship with a linear trendline added

fDOM_DOC_plot &lt;- fDOM_DOC_join%&gt;%
  ggplot2::ggplot(aes(x=mean_fDOM,y=analyteConcentration))+
  ggplot2::geom_point()+
  ggplot2::geom_smooth(method=&quot;lm&quot;,se=T)+
  ggplot2::scale_x_continuous(limits=c(0,60))+
  ggplot2::labs(title = &quot;AOS-DOC vs. AIS-fDOM&quot;,
                y = &quot;DOC (mg/L)&quot;,
                x = &quot;fDOM (QSU)&quot;)



fDOM_DOC_plot
</code></pre>
<p><img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/linear-regression-1.png" alt=" " /></p>
<p>Given relatively high AIS data completeness and a correlative relationship
between AOS-DOC and AIS-fDOM, Let’s model DOC vs. fDOM from 2021-10-01 to
2024-09-30. We will add modelled continuous DOC as a column in the joined table.</p>
<pre><code># predict continuous doc based on the linear regression model coefficients

fDOM_DOC_join$fit &lt;- predict(model,
                             newdata = fDOM_DOC_join,
                             interval = &quot;confidence&quot;)[, &quot;fit&quot;]



# add two more columns with predicted 95% CI uncertainty around the modeled DOC

conf_int &lt;- predict(model, newdata = fDOM_DOC_join, interval = &quot;confidence&quot;)

fDOM_DOC_join$lwr &lt;- conf_int[, &quot;lwr&quot;]

fDOM_DOC_join$upr &lt;- conf_int[, &quot;upr&quot;]
</code></pre>
<p>With the modeled data added to our joined data table, let’s plot the resulting
modeled DOC w/ uncertainty on the same plotting field as the DOC measured from
water chemistry grab samples. We will make this plot using <code>plotly</code> so we can
zoom in to see how well the AOS-DOC and modeled continuous DOC match up.</p>
<pre><code># create plot

plotly::plot_ly(data=fDOM_DOC_join)%&gt;%
  
  # plot uncertainty as a ribbon
  plotly::add_trace(x=~roundDate,y=~upr,name=&quot;95% CI&quot;,
                    type='scatter',mode='line',
                    line=list(color='lightgray'),legendgroup=&quot;95CI&quot;,
                    showlegend=F)%&gt;%
  plotly::add_trace(x=~roundDate,y=~lwr,name=&quot;95% CI&quot;,
                    type='scatter',mode='none',fill = 'tonexty',
                    fillcolor = 'lightgray',legendgroup=&quot;95CI&quot;)%&gt;%
  
  # plot modeled DOC timeseries
  plotly::add_trace(x=~roundDate,y=~fit,name=&quot;Modeled DOC&quot;,
                    type='scatter',mode='line',
                    line=list(color='blue'))%&gt;%
  
  # plot grab sample DOC
  plotly::add_trace(x=~roundDate,y=~analyteConcentration,name=&quot;Grab Sample DOC&quot;,
                    type='scatter',mode='markers',
                    marker=list(color='darkorange'))%&gt;%
  
  # format title, axes, and legend
  plotly::layout(title=&quot;Dissolved Organic Carbon: Modelled &amp; Grab Sample&quot;,
                 xaxis=list(title=&quot;Date&quot;),
                 yaxis=list(title=&quot;DOC (mg/L)&quot;),
                 legend=list(xanchor = 'center',
                             yanchor = 'top',
                             orientation = 'h',
                             x=0.5,y=-0.2))
</code></pre>
<div class="figure">
<img src="https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/R/AIS-data/AIS-AOS-integration-tutorial/rfigs/plot-model-doc-1.png" alt=" " width="100%" height="600px" />
<p class="caption"> </p>
</div>
<p><strong>Discussion</strong>: This study shows the possibility of integrating AIS and AOS data
to expand the temporal scale of estimated DOC in stream sites. At CUPE,
estimated DOC matches well with grab sample DOC across mid-range values, with
uncertainty increasing at the low and high ends of the timeseries. The
relationship will continue to be expanded upon, following NEON’s flow-weighted
sampling design.</p>
<p>The standardized nature of NEON data products and site designs allow for this
and other analyses to be scaled across the observatory, revealing similarities
and differences in the relationship across sites, and allowing for more detailed
investigation of carbon dynamics in freshwater systems across the United States.</p>
<p>This analysis can be conducted for any of the 24 stream sites across the NEON
observatory simply by changing the <code>site</code> input variable in <code>loadByProduct()</code>.
Try out this analysis at your favorite site! What environmental factors could
contribute to the quality of this relationship at different NEON stream sites?</p>
</div>
</body>
</html>
