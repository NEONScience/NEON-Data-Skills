---
title: Content for veg structure & CHM tutorial
output: html_fragment
dateCreated: '2024-12-31'
---


This data tutorial provides instruction on working with two different NEON 
data products to estimate tree height: 

* **DP3.30015.001, Ecosystem structure**, aka Canopy Height Model (CHM) 
* **DP1.10098.001, Vegetation structure**

The <a href="https://data.neonscience.org/data-products/DP3.30015.001" target="_blank">CHM data</a> are derived from the Lidar point cloud data collected by the remote sensing platform. 
The <a href="https://data.neonscience.org/data-products/DP1.10098.001" target="_blank">vegetation structure data</a> are collected by by field staff on the ground. We will be using data from the Wind River Experimental Forest NEON field site located in Washington state. The 
predominant vegetation there are tall evergreen conifers. 

If you are coming to this exercise after following tutorials on data 
download and formatting, and therefore already have the needed data, 
skip ahead to section 4.

<div id="ds-objectives" markdown="1">

## Things Youâ€™ll Need To Complete This Tutorial
You will need the a recent version of R (4+) or Python (3.9+) loaded 
on your computer to complete this tutorial.

</div>

## 1. Setup {.tabset}

Start by installing and loading packages (if necessary) and setting 
options. Installation can be run once, then periodically to get 
package updates.

### R

One of the packages we'll be using, `geoNEON`, is only 
available via GitHub, so it's installed using the `devtools` package. 
The other packages can be installed directly from CRAN.

```{r install_packages, eval=FALSE}

install.packages("neonUtilities")
install.packages("neonOS")
install.packages("terra")
install.packages("devtools")
devtools::install_github("NEONScience/NEON-geolocation/geoNEON")

```

Now load packages. This needs to be done every time you run code. 
We'll also set a working directory for data downloads.

```{r load-packages, results="hide"}

library(terra)
library(neonUtilities)
library(neonOS)
library(geoNEON)

options(stringsAsFactors=F)

# set working directory
# adapt directory path for your system
wd <- "~/data"
setwd(wd)

```

### Python

There are a variety of spatial packages available in Python; 
we'll use `rasterio`. We'll also use several modules that 
are installed automatically with standard Python installations.

```{python p-install_packages, eval=FALSE}

pip install neonutilities
pip install rasterio

```

Now load packages.

```{python p-load-packages, results="hide"}

import neonutilities as nu
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import rasterio
import requests
import os

```

## {-}

## 2. Vegetation structure data {.tabset}

In this section we'll download the vegetation structure data, 
find the locations of the mapped trees, and join to the species 
and size data.

### R

Download the vegetation structure data using the `loadByProduct()` function in
the `neonUtilities` package. Inputs to the function are:

* `dpID`: data product ID; woody vegetation structure = DP1.10098.001
* `site`: (vector of) 4-letter site codes; Wind River = WREF
* `package`: basic or expanded; we'll download basic here
* `release`: which data release to download; we'll use RELEASE-2023
* `check.size`: should this function prompt the user with an estimated download size? Set to `FALSE` here for ease of processing as a script, but good to leave as default `TRUE` when downloading a dataset for the first time.

Refer to the <a href="https://www.neonscience.org/sites/default/files/cheat-sheet-neonUtilities.pdf" target="_blank">cheat sheet</a> 
for the `neonUtilities` package for more details and the complete index of 
possible function inputs.

```{r veglist, results="hide"}

veglist <- loadByProduct(dpID="DP1.10098.001", 
                         site="WREF", 
                         package="basic", 
                         release="RELEASE-2023",
                         check.size = FALSE)

```

### Python

Download the vegetation structure data using the `load_by_product()` function in
the `neonutilities` package. Inputs to the function are:

* `dpid`: data product ID; woody vegetation structure = DP1.10098.001
* `site`: (vector of) 4-letter site codes; Wind River = WREF
* `package`: basic or expanded; we'll download basic here
* `release`: which data release to download; we'll use RELEASE-2023
* `check_size`: should this function prompt the user with an estimated download size? Set to `False` here for ease of processing as a script, but good to leave as default `True` when downloading a dataset for the first time.

Refer to the <a href="https://www.neonscience.org/sites/default/files/cheat-sheet-neonUtilities.pdf" target="_blank">cheat sheet</a> 
for the `neonUtilities` package for more details and the complete index of 
possible function inputs. The cheat sheet is focused on the R package, but 
nearly all the inputs are the same.

```{python p-veglist, results="hide"}

veglist = nu.load_by_product(dpid="DP1.10098.001", 
                         site="WREF", 
                         package="basic", 
                         release="RELEASE-2023",
                         check_size = False)

```

## {-}

### Get tree locations {.tabset}

#### R

Use the `getLocTOS()` function in the `geoNEON` package to get 
precise locations for the tagged plants. Refer to the package 
documentation for more details.

```{r vegmap, results="hide"}

vegmap <- getLocTOS(veglist$vst_mappingandtagging, 
                          "vst_mappingandtagging")

```

#### Python

NEON doesn't currently offer a Python equivalent to the `geoNEON` R 
package, so we'll calculate the tree locations step-by-step. The trees 
are mapped as distance and azimuth from a reference location. The 
reference location data are accessible on the NEON API. The steps in 
this calculation are described in the <a href="https://data.neonscience.org/api/v0/documents/NEON_vegStructure_userGuide_vE.1" target="_blank">Data Product User Guide</a>.

First, get the names of the reference locations, and query the 
NEON API to retrieve their location data:

```{python p-vegmap}

vegmapall = veglist["vst_mappingandtagging"]
vegmap = vegmapall.loc[vegmapall["pointID"] != ""]
vegmap = vegmap.reindex()
vegmap["points"] = vegmap["namedLocation"] + "." + vegmap["pointID"]
vegpoints = list(set(list(vegmap["points"])))

easting = []
northing = []
coordinateUncertainty = []
elevationUncertainty = []
for i in vegpoints:
    vres = requests.get("https://data.neonscience.org/api/v0/locations/"+i)
    vreslist = vres.json()
    easting.append(vreslist["data"]["locationUtmEasting"])
    northing.append(vreslist["data"]["locationUtmNorthing"])
    props = pd.DataFrame.from_dict(vreslist["data"]["locationProperties"])
    coordinateUncertainty.append(props.loc[props["locationPropertyName"]==
                                         "Value for Coordinate uncertainty"]
                                 ["locationPropertyValue"])
    elevationUncertainty.append(props.loc[props["locationPropertyName"]==
                                         "Value for Elevation uncertainty"]
                                 ["locationPropertyValue"])

ptdct = dict(points=vegpoints, 
             easting=easting, 
             northing=northing,
             coordinateUncertainty=coordinateUncertainty,
             elevationUncertainty=elevationUncertainty)
ptfrm = pd.DataFrame.from_dict(ptdct)
ptfrm.set_index("points", inplace=True)

vegmap = vegmap.join(ptfrm, 
                     on="points", 
                     how="inner")

```

Next, use the distance and azimuth data to calculate the precise 
locations of individuals, relative to the reference locations.

```{python p-vegloc}

vegmap["adjEasting"] = (vegmap["easting"]
                        + vegmap["stemDistance"]
                        * np.sin(vegmap["stemAzimuth"]
                                   * np.pi / 180))

vegmap["adjNorthing"] = (vegmap["northing"]
                        + vegmap["stemDistance"]
                        * np.cos(vegmap["stemAzimuth"]
                                   * np.pi / 180))

```

Add to the uncertainty estimate to account for error in measurement 
from the reference location, as described in the User Guide.

```{python p-veglocunc}

vegmap["adjCoordinateUncertainty"] = vegmap["coordinateUncertainty"] + 0.6
vegmap["adjElevationUncertainty"] = vegmap["elevationUncertainty"] + 1

```

### {-}

### Combine location with tree traits {.tabset}

Now we have the mapped locations of individuals in the `vst_mappingandtagging` 
table, and the annual measurements of tree dimensions such as height and 
diameter in the `vst_apparentindividual` table. To bring these measurements 
together, join the two tables, using the `joinTableNEON()` function from the 
`neonOS` package. Refer to the <a href="https://data.neonscience.org/data-products/DP1.10098.001" target="_blank">Quick Start Guide</a> 
for Vegetation structure for more information about the data tables and the 
joining instructions `joinTableNEON()` is using.

#### R

```{r veg-merge}

veg <- joinTableNEON(veglist$vst_apparentindividual, 
                     vegmap, 
                     name1="vst_apparentindividual",
                     name2="vst_mappingandtagging")

```

#### Python

Like the `geoNEON` package, there is not currently a  Python 
equivalent to the `neonOS` package. Refer to the 
<a href="https://data.neonscience.org/data-products/DP1.10098.001" target="_blank">Quick Start Guide</a> for Vegetation structure to find the data field to use to 
join the two tables.

```{python p-veg-merge}

veglist["vst_apparentindividual"].set_index("individualID", inplace=True)
veg = vegmap.join(veglist["vst_apparentindividual"],
                  on="individualID",
                  how="inner",
                  lsuffix="_MAT",
                  rsuffix="_AI")

```

### {-}

### Make a stem map {.tabset}

Let's see what the data look like! Make a stem map of the plants in 
plot WREF_075. Each tree is mapped by a circle matching its size.

Note that in both languages the input to the "circle" function is a 
radius, but `stemDiameter` is just that, a diameter, so we will need to 
divide by two. And `stemDiameter` is in centimeters, but the mapping 
scale is in meters, so we also need to divide by 100 to get the scale 
right.

#### R

```{r plot-1}

symbols(veg$adjEasting[which(veg$plotID=="WREF_075")], 
        veg$adjNorthing[which(veg$plotID=="WREF_075")], 
        circles=veg$stemDiameter[which(veg$plotID=="WREF_075")]/100/2, 
        inches=F, xlab="Easting", ylab="Northing")

```

And now overlay the estimated uncertainty in the location of each stem, 
in blue:

```{r plot-2}

symbols(veg$adjEasting[which(veg$plotID=="WREF_075")], 
        veg$adjNorthing[which(veg$plotID=="WREF_075")], 
        circles=veg$stemDiameter[which(veg$plotID=="WREF_075")]/100/2, 
        inches=F, xlab="Easting", ylab="Northing")
symbols(veg$adjEasting[which(veg$plotID=="WREF_075")], 
        veg$adjNorthing[which(veg$plotID=="WREF_075")], 
        circles=veg$adjCoordinateUncertainty[which(veg$plotID=="WREF_075")], 
        inches=F, add=T, fg="lightblue")

```

#### Python

```{python p-plot-1}

veg75 = veg.loc[veg["plotID_AI"]=="WREF_075"]

fig, ax = plt.subplots()

xy = np.array(tuple(zip(veg75.adjEasting, veg75.adjNorthing)))
srad = veg75.stemDiameter/100/2
patches = [plt.Circle(center, size) for center, size in zip(xy, srad)]

coll = matplotlib.collections.PatchCollection(patches, facecolors="white", edgecolors="black")
ax.add_collection(coll)

ax.margins(0.1)
plt.show()

```

And now overlay the estimated uncertainty in the location of each stem, 
in blue:

```{python p-plot-2}

fig, ax = plt.subplots()

sunc = veg75.adjCoordinateUncertainty
patchunc = [plt.Circle(center, size) for center, size in zip(xy, sunc)]

coll = matplotlib.collections.PatchCollection(patches, facecolors="None", edgecolors="black")
collunc = matplotlib.collections.PatchCollection(patchunc, facecolors="None", edgecolors="lightblue")
ax.add_collection(coll)
ax.add_collection(collunc)

ax.margins(0.1)
plt.show()

```

### {-}

## 3. Canopy height model data {.tabset}

Now we'll download the CHM tile covering plot WREF_075. Several 
other plots are also covered by this tile. We could download all tiles 
that contain vegetation structure plots, but in this exercise we're 
sticking to one tile to limit download size and processing time.

The `tileByAOP()` function in the `neonUtilities` package allows for 
download of remote sensing tiles based on easting and northing 
coordinates, so we'll give it the coordinates of all the trees in 
plot WREF\_075 and the data product ID, DP3.30015.001 (note that if 
WREF\_075 crossed tile boundaries, this code would download all 
relevant tiles).

The download will include several metadata files as well as the data 
tile. Load the data tile into the environment using the `terra` package 
in R and the `rasterio` package in Python.

### R

```{r get-chm, results="hide"}

byTileAOP(dpID="DP3.30015.001", site="WREF", year="2017", 
          easting=veg$adjEasting[which(veg$plotID=="WREF_075")], 
          northing=veg$adjNorthing[which(veg$plotID=="WREF_075")],
          check.size=FALSE, savepath=wd)

chm <- rast(paste0(wd, "/DP3.30015.001/neon-aop-products/2017/FullSite/D16/2017_WREF_1/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D16_WREF_DP3_580000_5075000_CHM.tif"))

```

Let's view the tile.

```{r plot-chm}

plot(chm, col=topo.colors(5))

```

### Python

```{python p-get-chm, results="hide"}

nu.by_tile_aop(dpid="DP3.30015.001", site="WREF", year="2017", 
          easting=list(veg75.adjEasting), 
          northing=list(veg75.adjNorthing),
          check_size=False, savepath=os.getcwd())

chm = rasterio.open(os.getcwd() + "/DP3.30015.001/neon-aop-products/2017/FullSite/D16/2017_WREF_1/L3/DiscreteLidar/CanopyHeightModelGtif/NEON_D16_WREF_DP3_580000_5075000_CHM.tif")

```

Let's view the tile.

```{python p-plot-chm}

plt.imshow(chm.read(1))
plt.show()

```

## {-}

## 4. Comparing the two datasets

Now we have the heights of individual trees measured from the ground, and 
the height of the top surface of the canopy, measured from the air. There 
are many different ways to make a comparison between these two 
datasets! This section will walk through three different approaches.

### Subset the data {.tabset}

First, subset the vegetation structure data to only the trees that fall 
within this tile. This step isn't strictly necessary, but it will make 
the processing faster.

#### R

```{r vegsub}

vegsub <- veg[which(veg$adjEasting >= ext(chm)[1] &
                      veg$adjEasting <= ext(chm)[2] &
                      veg$adjNorthing >= ext(chm)[3] & 
                      veg$adjNorthing <= ext(chm)[4]),]

```

#### Python

```{python p-vegsub}

vegsub = veg.loc[(veg["adjEasting"] >= chm.bounds[0]) &
                 (veg["adjEasting"] <= chm.bounds[1]) &
                 (veg["adjNorthing"] >= chm.bounds[2]) & 
                 (veg["adjNorthing"] <= chm.bounds[3])]
vegsub = vegsub.reset_index(drop=True)

```

### {-}

### Canopy height at mapped tree locations {.tabset}

Starting with a very simple first pass: get the CHM value matching 
the coordinates of each mapped plant. Then make a scatter plot of 
each tree's height vs. the CHM value at its location.

#### R

The `extract()` function from the `terra` package gets the values 
from the tile at the given coordinates.

```{r no-buffer-chm}

valCHM <- extract(chm, 
                  cbind(vegsub$adjEasting,
                  vegsub$adjNorthing))

plot(valCHM$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegsub$height, pch=20, xlab="Height", 
     ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

How strong is the correlation between the ground and lidar 
measurements?

```{r corr-no-buffer}

cor(valCHM$NEON_D16_WREF_DP3_580000_5075000_CHM, 
    vegsub$height, use="complete")

```

#### Python

The `sample()` function from the `rasterio` package gets the values 
from the tile at the given coordinates.

```{python p-no-buffer-chm}

valCHM = list(chm.sample(tuple(zip(vegsub["adjEasting"], vegsub["adjNorthing"]))))

fig, ax = plt.subplots()

ax.plot((0,50), (0,50), linewidth=1, color="black")
ax.scatter(vegsub.height, valCHM, s=1)

ax.set_xlabel("Height")
ax.set_ylabel("Canopy height model")

plt.show()

```

How strong is the correlation between the ground and lidar 
measurements?

```{python p-corr-no-buffer}

CHMlist = np.array([c.tolist()[0] for c in valCHM])
idx = np.isfinite(vegsub.height) & np.isfinite(CHMlist)
np.corrcoef(vegsub.height[idx], CHMlist[idx])[0,1]

```

### {-}

### Canopy height within a buffer of mapped tree locations {.tabset}

Now we remember there is uncertainty in the location of each tree, so the 
precise pixel it corresponds to might not be the right one. Let's try 
adding a buffer to the extraction function, to get the tallest tree within 
the uncertainty of the location of each tree.

#### R

```{r buffer-chm}

valCHMbuff <- extract(chm, 
                  buffer(vect(cbind(vegsub$adjEasting,
                  vegsub$adjNorthing)),
                  width=vegsub$adjCoordinateUncertainty),
                  fun=max)

plot(valCHMbuff$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegsub$height, pch=20, xlab="Height", 
     ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

```{r corr-buffer}

cor(valCHMbuff$NEON_D16_WREF_DP3_580000_5075000_CHM, 
    vegsub$height, use="complete")

```

#### Python

```{python p-buffer-chm}

valCHMbuff <- extract(chm, 
                  buffer(vect(cbind(vegsub$adjEasting,
                  vegsub$adjNorthing)),
                  width=vegsub$adjCoordinateUncertainty),
                  fun=max)

plot(valCHMbuff$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegsub$height, pch=20, xlab="Height", 
     ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

```{python p-corr-buffer}

cor(valCHMbuff$NEON_D16_WREF_DP3_580000_5075000_CHM, 
    vegsub$height, use="complete")

```

### {-}

Adding the buffer has actually made our correlation slightly worse. Let's 
think about the data.

There are a lot of points clustered on the 1-1 line, but there is also a 
cloud of points above the line, where the measured height is lower than 
the canopy height model at the same coordinates. This makes sense, because 
the tree height data include the understory. There are many 
plants measured in the vegetation structure data that are not at the top 
of the canopy, and the CHM sees only the top surface of the canopy.

This also explains why the buffer didn't improve things. Finding the 
highest CHM value within the uncertainty of a tree should improve the fit 
for the tallest trees, but it's likely to make the fit worse for the 
understory trees.

How to exclude understory plants from this analysis? Again, there are many 
possible approaches. We'll try out two, one map-centric and one 
tree-centric.

Starting with the map-centric approach: select a pixel size, and aggregate 
both the vegetation structure data and the CHM data to find the tallest point 
in each pixel. Let's try this with 10m pixels.

Start by rounding the coordinates of the vegetation structure data, to create 
10m bins. Use `floor()` instead of `round()` so each tree ends up in the pixel 
with the same numbering as the raster pixels (the rasters/pixels are 
numbered by their southwest corners).

```{r round-x-y}

easting10 <- 10*floor(vegsub$adjEasting/10)
northing10 <- 10*floor(vegsub$adjNorthing/10)
vegsub <- cbind(vegsub, easting10, northing10)

```

Use the `aggregate()` function to get the tallest tree in each 10m bin.

```{r vegbin}

vegbin <- stats::aggregate(vegsub, 
                           by=list(vegsub$easting10, 
                                   vegsub$northing10), 
                           FUN=max)

```

To get the CHM values for the 10m bins, use the `terra` package version 
of the `aggregate()` function. Let's take a look at the lower-resolution 
image we get as a result.

```{r CHM-10}

CHM10 <- terra::aggregate(chm, fact=10, fun=max)
plot(CHM10, col=topo.colors(5))

```

Use the `extract()` function again to get the values from each pixel. 
Our grids are numbered by the corners, so add 5 to each tree 
coordinate to make sure it's in the correct pixel.

```{r adj-tree-coord}

vegbin$easting10 <- vegbin$easting10 + 5
vegbin$northing10 <- vegbin$northing10 + 5
binCHM <- extract(CHM10, cbind(vegbin$easting10, 
                               vegbin$northing10))
plot(binCHM$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegbin$height, pch=20, 
     xlab="Height", ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

```{r cor-2}

cor(binCHM$NEON_D16_WREF_DP3_580000_5075000_CHM, 
    vegbin$height, use="complete")

```

The understory points are thinned out substantially, but so are the rest. 
We've lost a lot of data by going to a lower resolution.

Let's try and see if we can identify the tallest trees by another approach, 
using the trees as the starting point instead of map area. Start by sorting 
the veg structure data by height.

```{r vegsub-2}

vegsub <- vegsub[order(vegsub$height, 
                       decreasing=T),]

```

Now, for each tree, let's estimate which nearby trees might be beneath 
its canopy, and discard those points. To do this:

1. Calculate the distance of each tree from the target tree.
2. Pick a reasonable estimate for canopy size, and discard shorter trees 
within that radius. The radius I used is 0.3 times the height, based on 
some rudimentary googling about Douglas fir allometry. It could definitely 
be improved on!
3. Iterate over all trees.

We'll use a simple `for` loop to do this:

```{r vegfil}

vegfil <- vegsub
for(i in 1:nrow(vegsub)) {
    if(is.na(vegfil$height[i]))
        next
    dist <- sqrt((vegsub$adjEasting[i]-vegsub$adjEasting)^2 + 
                (vegsub$adjNorthing[i]-vegsub$adjNorthing)^2)
    vegfil$height[which(dist<0.3*vegsub$height[i] & 
                        vegsub$height<vegsub$height[i])] <- NA
}

vegfil <- vegfil[which(!is.na(vegfil$height)),]

```

Now extract the raster values, as above.

```{r filter-chm}

filterCHM <- extract(chm, 
                     cbind(vegfil$adjEasting, 
                           vegfil$adjNorthing))
plot(filterCHM$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegfil$height, pch=20, 
     xlab="Height", ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

```{r cor-3}

cor(filterCHM$NEON_D16_WREF_DP3_580000_5075000_CHM,
    vegfil$height)

```

This is quite a bit better! There are still several understory points we 
failed to exclude, but we were able to filter out most of the understory 
without losing so many overstory points.

Let's try one last thing. The `plantStatus` field in the veg structure data 
indicates whether a plant is dead, broken, or otherwise damaged. In theory, 
a dead or broken tree can still be the tallest thing around, but it's less 
likely, and it's also less likely to get a good Lidar return. Exclude all 
trees that aren't alive:

```{r live-trees}

vegfil <- vegfil[which(vegfil$plantStatus=="Live"),]
filterCHM <- extract(chm, 
                     cbind(vegfil$adjEasting, 
                           vegfil$adjNorthing))
plot(filterCHM$NEON_D16_WREF_DP3_580000_5075000_CHM~
       vegfil$height, pch=20, 
     xlab="Height", ylab="Canopy height model")
lines(c(0,50), c(0,50), col="grey")

```

```{r cor-4}

cor(filterCHM$NEON_D16_WREF_DP3_580000_5075000_CHM,
    vegfil$height)

```

Nice!

One final note: however we slice the data, there is a noticeable bias 
even in the strongly correlated values. The CHM heights are generally a 
bit shorter than the ground-based estimates of tree height. There are 
two biases in the CHM data that contribute to this. (1) Lidar returns 
from short-statured vegetation are difficult to distinguish from the 
ground, so the "ground" estimated by Lidar is generally a bit higher 
than the true ground surface, and (2) the height estimate from Lidar 
represents the highest return, but the highest return may slightly 
miss the actual tallest point on a given tree. This is especially 
likely to happen with conifers, which are the top-of-canopy trees at 
Wind River.
