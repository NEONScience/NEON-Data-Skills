---
layout: post
title: "Lidar and Hyperspectral Data Product Fusion"
date:   2016-06-20
dateCreated:  2016-05-01
lastModified: `r format(Sys.time(), "%Y-%m-%d")`
authors: [Kyla Dahlin]
instructors: [Kyla, Leah]
time: "1:00"
contributors:
packagesLibraries: [rhdf5, raster, rgdal, rgeos, sp]
categories: [self-paced-tutorial]
mainTag: institute-day4
tags: [R, HDF5]
tutorialSeries: [institute-day4]
description: "Intro to data fusion"
code1: .R
image:
  feature: 
  credit: 
  creditlink:
permalink: /R/neon-data-fusion-R/
comments: false
---



First, let's load the required libraries.

```{r load-libraries, warning=FALSE, results='hide', message=FALSE}
# load libraries
library(raster)
library(rhdf5)
library(rgdal)

# setwd("C:/Users/kdahlin/Dropbox/NEON_WWDI_2016/20160602")
setwd("~/Documents/data/1_data-institute-2016")
```


The first thing that we can do is load the functions that we want to use into
our environment. This makes it easy to quickly access these functions without
having to retype the function code into our script. This also makes it easy to
maintain function code that we use regularly in ONE PLACE. 

```{r import-h5-functions }

# import NEON aop R package
library(devtools)
## install from github
install_github("lwasser/neon-aop-package/neonAOP")
library(neonAOP)

# your file will be in your working directory!
# this is also an R package!
#source("aop-data.R")
#source("/Users/lwasser/Documents/GitHub/neon-aop-package/neonAOP/R/aop-data.R")
```

## Import NEON Lidar Data Products

First, let's import several NEON lidar data products. 

# KYLA - Do we need the DSM and DTM now that we have a CHM pre-processed?
### I guess not but it might be interesting to look at, and for students' independent projects?

```{r import-lidar }

# import digital surface model (dsm) (top of the surface - includes trees and buildings)
dsm <- raster("NEONdata/D17-California/TEAK/2013/lidar/Teak_lidarDSM.tif")
# import  digital terrain model (dtm), elevation
dtm <- raster("NEONdata/D17-California/TEAK/2013/lidar/Teak_lidarDTM.tif") 

# import canopy height model (height of vegetation) 
chm <- raster("NEONdata/D17-California/TEAK/2013/lidar/Teak_lidarCHM.tif")

```


## Explore CHM 
Next, let's explore our CHM data.

```{r plot-chm}

# do the numbers look reasonable? 60 m is tall for a tree, but
# this is Ponderosa pine territory (I think), so not out of the question.
plot(chm,
     main="Canopy Height - Teakettle \nCalifornia") 

hist(chm,
     main="Distribution of Canopy Height - Teakettle \nCalifornia",
     xlab="Tree Height (m)", 
     col="springgreen")

```

## Valid Data Range

The valid range of data for a NEON CHM is >= 2m. This is because the lidar system
is not sensitive enough to distinguish objects that are closer than ~2m apart vertically.

## Explore Veg Height data

Have a close look at the veg height values. Do they seem reasonable?
### adding this to introduce cellStats early on.

```{r view-summary-stats}
# view chm mean and max
cellStats(chm, max)
cellStats(chm, mean)

```

## Create LiDAR Raster Brick

Next, we can stack the rasters together to create a brick.

```{r create-stack }

# for simplicity later let's stack these rasters together
lidar.brick <- brick(dsm, dtm, chm)

```

## Read Hyperspectral Data 

Next, let's read in HSI data.

We could use the NDVI data product however, let's calculate NDVI ourselves.
Note, that there are many bands in HSI data within the red and NIR region.
Thus simply selecting one band in each region is not always the most 
robust way to go. 


```{r read-hsi-data, eval=FALSE}

# first identify the file of interest
f <- "NEONdata/D17-California/TEAK/2013/spectrometer/reflectance/Subset3NIS1_20130614_100459_atmcor.h5"

# then id the projection code
# define the CRS definition by EPSG code
epsg <- 32611

# create a list of bands
bands <- c(60,83)

# Let's read in a few spectral bands as a stack using a function
ndvi.stack <- create_stack(f, bands = bands,
            epsg=epsg)

# calculate ndvi
ndvi <- (ndvi.stack[[2]]-ndvi.stack[[1]]) / (ndvi.stack[[2]]+ndvi.stack[[1]])
names(ndvi) <- "Teak_hsiNDVI"

# plot ndvi
plot(ndvi,
     main="NDVI Teakettle Field Site")

```



## Import NDVI data

We can import the NEON NDVI data product next to use in our analysis.

```{r import-NDVI }

# import NEON NDVI product
ndvi2 <- raster("NEONdata/D17-California/TEAK/2013/spectrometer/veg_index/NEON.D17.TEAK.DP2.20130614_100459_NDVI.tif")

# plot NDVI
### I just did this out of curiosity, but it's funny that our NDVI calc is different from the 'neon product' - could make a point here about uncertainty and why open data is good (even a standard measure like NDVI can be calculated in different ways) - I'm guessing here the NEON product has been averaged across several bands to match MODIS or LandSat band widths?

## HI KYLA -- YUP - you've got it. our product I believe will be a bit more robust
## because Dave took some time to consider the band component and associated distribution of reflectance across the bands in the red and NIR parts. i'll ask him to discuss that in his wednesday AM presentation
plot(ndvi - ndvi2,
     main="NDVI DIFFERENCE, TEAK Field Site")

```

## Create Brick of lidar and NDVI

```{r create-brick}

# Create a brick from the data 
all.data <- brick(ndvi, lidar.brick)

```

## Heterogeneous Data - Varying Extents

oops - why didn't the brick work?

```{r}

extent(chm)
extent(ndvi)
```

## Dealing with Different Extents

The extents are different. Let's write a if statment that checks the extents
and crops them in case they are different.

Note this could become a function that you use over and over! If you used
it that way you'd want to implement a crop of BOTH datasets just in case
neither are perfectly within the overlap region.

```{r check-extents}
# check the extents of the two raster layers -- if they are different
# crop the data 

if (extent(chm) == extent(ndvi)){
 } else {
 overlap <- intersect(extent(ndvi), extent(lidar.brick))
  # now let's crop the lidar data to the HSI data
 lidar.brick <- crop(lidar.brick, overlap)
 ndvi <- crop(ndvi, overlap)
 print("Extents are different, cropping data")
 }

```

Now let's try to create a brick again.

```{r create-raster-brick }
# Create a brick from the data 
all.data <- brick(ndvi, lidar.brick)
# make names nice!
all.names <- c("NDVI", "DSM", "DTM", "CHM" )
names(all.data) <- all.names

```


## Consider Slope & Aspect

Next, let's test a simple hypothesis. 

Because California is:

* dry and 
* In the northern hemisphere.

We may expect to find taller, greener vegetation on north facing slopes than on 
south facing slopes. To test this we need to 

1. Import the NEON aspect data product.
2. Isolate north and south facing slopes. 
3. Decide what we mean by 'tall' and 'green'.
4. Isolate tall, green pixels on north & south facing slopes. 
5. Examine the percent of pixels for tall green pixels on north vs south facing slopes.
6. Run a t-test to compare all pixels.

Let's get started.

### Step 1. Import Aspect data product

```{r import-aspect }

# 1. Import aspect data product (derived from the DTM)
aspect <- raster("NEONdata/D17-California/TEAK/2013/lidar/Teak_lidarAspect.tif")
# crop the data to the extent of the other rasters we are working with
aspect <- crop(aspect, extent(chm))

```


<div id="ds-dataTip" markdown="1">
<i class="fa fa-star"></i>**Data Tip:** You can create an aspect layer from a 
DEM / DTM using the terrain function: `terrain(all.data[[3]], opt = "aspect", unit = "degrees", neighbors = 8)`
</div>

### 2. Create Aspect Mask

Next we will create a mask using the aspect data product. Values are as follows:

* South Facing: 135-225 degrees
* North Facing: 315-360 and 0-45 degrees

We can do this by reclassifying the aspect data product using the `reclassify` 
function in the `raster` package. 

First we need to create MATRIX that has 3 columns. the first two columns
represent the data values within a range that we want to classify. The third column
contains the new value that we will assign that range of values to. For example:

0 to 45 degrees should be classified as 1 (North Facing)
135 to 225 degrees should be classified as 2 (South Facing)
Greater than 315 should be classified as 1 (North Facing)


```{r create-aspect-mask}

# Create a classified aspect intermediate output 
# first create a matrix of values that represent the classification ranges
# North face = 1
# South face = 2
class.m <- c(0, 45, 1, 
             45, 135, NA, 
             135, 225, 2,  
             225 , 315, NA, 
             315, 360, 1)
# reshape into a matrix
rcl.m <- matrix(class.m, 
                ncol=3, 
                byrow=TRUE)
rcl.m
# classify the aspect product using the classification matrix
asp.ns <- reclassify(aspect, rcl.m)
# set 0 values to NA
asp.ns[asp.ns==0] <- NA

```

## Plot aspect

```{r plot-aspect-product} 

# define the extetn of the map -
# this is used to place the legend on the plot.
ns.extent <- extent(asp.ns)

# plot data
plot(asp.ns, 
     col=c("blue","green"),
     axes=F,
     main="North and South Facing Slopes \nNEON Teakettle Field Site",
     bty="n",
     legend=F)

# allow legend to plot outside of bounds
par(xpd=TRUE)

legend((par()$usr[2] + 20), ns.extent@ymax-100, # set xy legend location
       legend = c("North", "South"),
       fill = c("blue", "green"), 
       bty="n") # turn off border

```

## North / South Facing Slopes

Next, we can create a north and south facing mask object. A mask is a layer where
the pixels that you want to EXCLUDE are set to NA. The pixels that you wish to 
include in your analysis have a value. In this case, that value is 1.

```{r ns-facing }

# create north facing mask object
north.facing <- asp.ns==1
north.facing[north.facing == 0] <- NA

# Create south facing mask object
south.facing <- asp.ns==2
south.facing[south.facing == 0] <- NA

```

## Export North South Aspect Geotiff

Before we go any further, let's export a geotiff. This could be useful for another
analysis. 

```{r export-gtif-ns, eval=FALSE}

# export geotiff 
writeRaster(asp.ns,
            filename="outputs/TEAK/Teak_nsAspect.tif",
            format="GTiff",
            options="COMPRESS=LZW",
            overwrite = TRUE,
            NAflag = -9999)

```

## 3. Identify Veg Metrics

Now we want to determine what defines "tall" and "green". We can explore histograms
of our data and use descriptive statistics to determine what values might make
the most sense. 

```{r id-veg-metrics }

# histogram of tree ht
hist(all.data[[4]],
     main="Distribution of Canopy Height Model (CHM) values \nNEON Teakettle Field Site",
     col="springgreen")


# get mean, min max stats for all layers
all.data.stats <- data.frame(t(summary(all.data, na.rm=T)))
all.data.stats$mean <- ht.mean <- cellStats(all.data, mean, na.rm=T)
all.data.stats$sd <- ht.mean <- cellStats(all.data, sd, na.rm=T)

row.names(all.data.stats) <- all.names

# view data.frame
all.data.stats
```

## Calculate Tall Trees Threshold

Note, that the data aren't normally distributed - something to consider
when you are determining what your thresholds are. 

Uncertainty discussion: selecting thresholds.

```{r calculate-tall-threshold }
# let's be semi-robust and call 'tall' trees those with mean + 1 sd
ht.threshold <- all.data.stats["CHM","mean"] + all.data.stats["CHM","sd"]
ht.threshold

```

Next, look at NDVI.


```{r explore-ndvi}
# now let's look at ndvi
hist(all.data[[1]],
     main="Distribution of NDVI values\n Teakettle",
     col="springgreen")

# this is a nice bimodal dataset, so let's just take the top 1/3 of the data
# or manually calculate the top third
green.range <- all.data.stats["NDVI","Max."] - all.data.stats["NDVI","Min."]
green.threshold <- all.data.stats["NDVI","Max."] - (green.range/3)

# or manually calculate mean + 1 sd
green.threshold <- all.data.stats["NDVI","mean"] + all.data.stats["NDVI","sd"]

```


## 4. Calculate Percent of tall and green pixels 

Next, let's calculate the percent of tall and green pixels that occur on 
north and south facing slopes. Our pixels are exactly 1 x 1 m in size, thus
we can use the % of pixels as a proxy for % area. 

Remember that 1 = North Facing and 2 = South Facing in our classified aspect
object `asp.ns`.

```{r calculate-percent}

# North = 1 and South facing = 2, calculate total pixels
north.count <- freq(asp.ns, value =1)
south.count <- freq(asp.ns, value =2)

# note there's  more south facing area in this image than north facing

# create a new layer with pixels that are north facing, above the green threshold and
# above the CHM height threshold
north.tall.green <- asp.ns == 1  & 
                    all.data[[1]] >= green.threshold & 
                    all.data[[4]] >= ht.threshold

# assign values of 0 to NA so this becomes a mask
north.tall.green[north.tall.green == 0] <- NA

# how many pixels fit the "north, tall green" criteria?
north.tall.green.count <- freq(north.tall.green, value =1)


# repeat the same steps for south facing slopes. Note
# we are repeating code - this could become a nice function!
south.tall.green <- asp.ns == 2 & 
                    all.data[[1]] >= green.threshold & 
                    all.data[[4]] >= ht.threshold

south.tall.green.count <- freq(south.tall.green, value=1)
south.tall.green[south.tall.green == 0] <- NA

# divide the number of pixels that are green by the total north facing pixels
north.tall.green.frac <- north.tall.green.count/freq(asp.ns, value=1)
south.tall.green.frac <- south.tall.green.count/freq(asp.ns, value=2)

# if we look at these fracs, >11% of the pixels on north facing slopes should
# meet our tall and green criteria, while <6% of the pixels on south facing
# slopes do. So that's reassuring. (using original dataset)

```

# Kyla - what's happening in this code is we are generating a lot of small r objects.
# green.def, thresholds, etc
# i'd probably create a data.frame with them all in there which will be much
# easier to keep track of. so maybe a dataframe with all of the pixel counts for
# north and south tall green and asp.ns would be nice. Then maybe a threshold data.frame
### fine with me! - you're the R expert :)

## Plot Color Infrared (CIR) Image

Next, let's have a look at the site that we are working with. We can use the 
Hyperspectral remote sensing data to plot a color infrared image. 

We will use the following bands:


| Color |Band Number   |Wavelength   |   |   |
|---|---|---|---|---|
|  Blue | 35  |~ 550nm   |   |   |
| Green| 60  | ~ 550nm  |   |   |
| Near-Infrared  | 83  |   ~ 550nm|   |   |

We can use the `create_stack` function that is a part of the NEON AOP R package
of functions to quickly import the three bands. Then we can use `plotRGB` to 
plot the bands as an RGB image. 

```{r view-cir }

f <- "NEONdata/D17-California/TEAK/2013/spectrometer/reflectance/Subset3NIS1_20130614_100459_atmcor.h5"

# define the CRS definition by EPSG code
epsg <- 32611

# create a list of bands
bands <- c(83, 60, 35)

# Let's read in a few spectral bands as a stack using a function
cir.stack <- create_stack(file=f,
                          bands = bands,
                          epsg=epsg)

# ignore reflectance values > 1
cir.stack[cir.stack > 1] <- NA

# plot cir image
plotRGB(cir.stack, 
        scale = 1, 
        stretch = "lin")

plot(north.tall.green, 
     col = "cyan", 
     add = T, 
     legend = F)
plot(south.tall.green, 
     col = "blue", 
     add = T, 
     legend = F)

```

# KYLA - i appreciate your comment below! Should we expand on this?
### hmmm... maybe I'll just include this in some of the uncertainty discussion? though I keep saying that and it's only 30 min...
# Note here that there are clusters where 'south facing' and 'north facing'
# pixels are very close together - this is due to the very fine resolution of the
# topo data. One might want to either smooth this data (low-pass filter) or
# use a larger kernel to calculate slope (not possible with the terrain fxn in
# the raster package)


```{r run-stats}
# (5) let's do some stats! t-test and boxplots of veg height and greenness 
# distributions in north versus south facing parts of scene.

# let's start with NDVI - isolate NDVI on north and south facing slopes
north.NDVI <- mask(all.data[[1]], north.facing)
south.NDVI <- mask(all.data[[1]], south.facing)

```

## Grab Values

```{r compare-aspect-NDVI }

## get values and coerce to north values to dataframe
north.ndvi.df <- na.omit(as.data.frame(getValues(north.NDVI)))
north.ndvi.df$aspect <- rep("north", length(north.ndvi.df[,1]))
names(north.ndvi.df) <- c("NDVI","aspect")

south.ndvi.df <- na.omit(as.data.frame(getValues(south.NDVI)))
south.ndvi.df$aspect <- rep("south", length(south.ndvi.df[,1]))
names(south.ndvi.df) <- c("NDVI","aspect")

ndvi.df <- rbind(north.ndvi.df, south.ndvi.df)
# convert aspect to factor - NOTE you don't have to do this
ndvi.df$aspect <- as.factor(ndvi.df$aspect)

boxplot(NDVI ~ aspect, 
        data = ndvi.df, 
        col = "cornflowerblue", 
        main = "NDVI on North versus South facing slopes")


# and now a t-test - note that since these aren't normally distributed, this
# might not be the best approach, but ok for a quick assessment.
NDVI.ttest <- t.test(north.ndvi.df$NDVI, 
                     south.ndvi.df$NDVI, 
                     alternative = "greater")

```

## Veg Height

Run the same analysis but use veg height!
Once again we are repeating code. This would make for a nice function! If it's a 
set of functions, we can change the methods in ONE PLACE and then re run the code!

<div id="ds-challenge" markdown="1">
## Challenge Activity

Your turn! Using the technique that we used above, run the same analysis
but this time, use **tree height** instead of NDVI as the variable of interest. 
Create a boxplot of treeheight compared to aspect. Then run a t-test.
Are the two variables related?

</div>


```{r veght-aspect-compare, echo=FALSE }
# mask tall pixels on north and south facing slopes 
north.veght <- mask(all.data[[4]], north.facing)
south.veght <- mask(all.data[[4]], south.facing)

## get values and coerce to north values to dataframe
north.veght.df <- na.omit(as.data.frame(getValues(north.veght)))
north.veght.df$aspect <- rep("north", length(north.veght.df[,1]))
names(north.veght.df) <- c("veght","aspect")

south.veght.df <- na.omit(as.data.frame(getValues(south.veght)))
south.veght.df$aspect <- rep("south", length(south.veght.df[,1]))
names(south.veght.df) <- c("veght","aspect")

veght.df <- rbind(north.veght.df, south.veght.df)
# convert aspect to factor - NOTE you don't have to do this
veght.df$aspect <- as.factor(veght.df$aspect)

boxplot(veght ~ aspect, 
        data = veght.df, 
        col = "cornflowerblue", 
        main = "veght on North versus South facing slopes")


# and now a t-test - note that since these aren't normally distributed, this
# might not be the best approach, but ok for a quick assessment.
veght.ttest <- t.test(north.veght.df$veght, south.veght.df$veght, alternative = "greater")

```


